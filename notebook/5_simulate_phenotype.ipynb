{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOM+Zv45N/aI7ELSkn3FBYF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnPMASVCvUOj","executionInfo":{"status":"ok","timestamp":1709543694016,"user_tz":480,"elapsed":4533,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"c5202924-78d0-43c3-b1d4-51be7d117fdd"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-04 09:14:49--  https://dougspeed.com/wp-content/uploads/ldak5.2.linux_.zip\n","Resolving dougspeed.com (dougspeed.com)... 35.214.77.229\n","Connecting to dougspeed.com (dougspeed.com)|35.214.77.229|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9265672 (8.8M) [application/zip]\n","Saving to: ‘ldak5.2.linux_.zip’\n","\n","ldak5.2.linux_.zip  100%[===================>]   8.84M  3.50MB/s    in 2.5s    \n","\n","2024-03-04 09:14:53 (3.50 MB/s) - ‘ldak5.2.linux_.zip’ saved [9265672/9265672]\n","\n","Archive:  ldak5.2.linux_.zip\n","  inflating: ldak5.2.linux           \n"]}],"source":["! wget https://dougspeed.com/wp-content/uploads/ldak5.2.linux_.zip\n","! unzip ldak5.2.linux_.zip"]},{"cell_type":"code","source":["! ./ldak5.2.linux"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MpNgL3B3vmn7","executionInfo":{"status":"ok","timestamp":1709543711791,"user_tz":480,"elapsed":840,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"cc5d5676-e777-4045-bacc-08f9246dd523"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 0 pairs of arguments:\n","\n","Error, each command requires a main argument; here is a list of main arguments\n","\n","Heritability analysis using individual-level data:\n","\n","--cut-weights <folder> - cut predictors into sections ready for calculating weightings\n","--calc-weights <folder> - calculate weightings for one section\n","--join-weights <folder> - join weightings across sections\n","--calc-weights-all <folder> - calculate weightings for all sections in one step\n","\n","--cut-kins <folder> - cut predictors into partitions ready for calculating kinships\n","--calc-kins <folder> - calculate kinship matrix for one partition\n","--join-kins <folder> - join kinship matrices across partitions\n","--calc-kins-direct <output> - calculate kinship matrix in one step\n","\n","--reml <output> - regress phenotype on kinships and/or regions\n","--calc-blups <output> - calculate BLUP effect size estimates (using results from --reml)\n","--he <output> - perform Haseman Elston Regression (an alternative to --reml)\n","--pcgc <output> - perform PCGC Regression (recommended instead of --reml for binary traits)\n","--fast-he <output> - perform fast (but approximate) Haseman Elston Regression\n","--fast-pcgc <output> - perform fast (but approximate) PCGC Regression\n","\n","Association testing:\n","\n","--linear <output> - perform standard or mixed-model linear regression\n","--logistic <output> - perform logistic regression\n","--solve-null <output> - perform two-part mixed-model linear regression (for complex models)\n","\n","--cut-genes <folder> - cut predictors into genes (or fixed-length chunks)\n","--calc-genes-kins <folder> - calculate kinships for each gene/chunk in one partition\n","--calc-genes-reml <folder> - calculate association test for each gene in one partition\n","--join-genes-reml <folder> - join association test results across partitions (also computes more accurate p-values)\n","\n","Heritability analysis using summary statistics:\n","\n","--calc-tagging <output> - calculate tagging file for use with --sum-hers or --sum-cors\n","--join-tagging <output> - join tagging files across predictors\n","--merge-tagging <output> - combine tagging files across categories\n","--reduce-tagging <output> - extract categories from a tagging file\n","\n","--sum-hers <output> - estimate heritabilities from summary statistics\n","--sum-cors <output> - estimate genetic correlations from summary statistics\n","--calc-exps <output> - calculate expected heritability tagged by predictors (using results from --sum-hers)\n","--calc-posts <output> - calculate posterior estimate of predictor effect sizes (using results from --calc-exps)\n","\n","Prediction:\n","\n","--ridge <output> - construct a ridge regression prediction model\n","--bolt <output> - construct a Bolt prediction model\n","--bayesr <output> -  construct a BayesR prediction model\n","--elastic <output> -  construct an elastic-net prediction model\n","\n","--calc-cors <output> - calculate predictor-predictor correlations for use with --mega-prs\n","--join-cors <output> - join correlations across predictors\n","--pseudo-summaries <output> - generate partial summary statistics (used to train MegaPRS prediction models)\n","--mega-prs <output> - construct lasso, ridge regression, Bolt and BayesR prediction models from summary statistics\n","\n","Other features:\n","\n","--thin <output> - prune predictors based on pairwise correlations\n","--thin-tops <output> - prune highly-associated predictors based on pairwise correlations\n","--find-tags <output> - search for the predictors most correlated with those in a scorefile\n","--remove-tags <output> - search for all predictors correlated with those in a target file\n","\n","--filter <output> - fiter samples based on relatedness\n","--add-grm <output> - combine kinship matrices\n","--sub-grm <output> - subtract from one kinship matrix the contributions of other kinship matrices\n","--convert-gz <output> - convert kinship matrix saved in gz (old GCTA) format\n","--convert-raw <output> - convert kinship matrix saved as a text file\n","--calc-sim-grm <output> - calculate correlations between pairs of kinship matrices\n","\n","--pca <output> - compute the principal component axes of a kinship matrix\n","--calc-pca-loads <output> - calculate the principal component predictor loadings (using results from --pca)\n","--decompose <output> - eigen-decompose a kinship matrix\n","--adjust-grm <output> - adjust a kinship matrix for covariates\n","--gxemm-iid / --gxemm-free <output> - calculate environmental kinship matrices\n","\n","--calc-stats <output> - calculate predictor allele frequencies, call-rates and possibly information scores\n","--calc-scores <output> - calculate one or more polygenic risk scores\n","--make-phenos <output> - simulate phenotypes\n","--make-snps <output> - simulate SNP data\n","\n","--jackknife <output> - measure prediction accuracy, obtaining standard deviations via block jackknifing\n","--cut-folds <output> - divide samples in preparation for performing K-fold cross-validation\n","--find-gaussian <output> - estimate the selection-related parameter alpha (using results from --sum-hers)\n","\n","--make-bed / --make-sp / --make-sped / --make-speed / --make-gen <outfile> - convert to bed / sp / sped / speed / gen format\n","--condense-bed / condense-sp / condense-sped / condense-speed <outfile> - condense to bed / sp / sped / speed format\n","--calc-sim-data <outfile> - calculate concordance between two datasets\n","\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLNcH5H7vvfx","executionInfo":{"status":"ok","timestamp":1709543759225,"user_tz":480,"elapsed":29574,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"9aa6e208-cb71-4e81-d521-bf8584f7a6b1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["sh = \"\"\"\n","\n","PREFIX=/content/drive/MyDrive/CSE-284-Final-Project/data\n","\n","BFILE=${PREFIX}/bed/ALL.chr1.phase3.genotypes\n","OUT=${PREFIX}/phen/ldak/chr1_para={power=-1,her=0.5,num-phenos=100,num-causals=1000}\n","\n","./ldak5.2.linux \\\n","    --make-phenos $OUT \\\n","    --bfile $BFILE \\\n","    --ignore-weights YES \\\n","    --power -1 \\\n","    --her 0.5 \\\n","    --num-phenos 100 \\\n","    --num-causals 1000\n","\n","\"\"\"\n","with open('script.sh', 'w') as file:\n","  file.write(sh)\n","\n","! bash script.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNYnANR6v50j","executionInfo":{"status":"ok","timestamp":1709545721854,"user_tz":480,"elapsed":45566,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"80660165-9249-4eb1-a2b0-c3deec356650"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos /content/drive/MyDrive/CSE-284-Final-Project/data/phen/ldak/chr1_para={power=-1,her=0.5,num-phenos=100,num-causals=1000}\n","--bfile /content/drive/MyDrive/CSE-284-Final-Project/data/bed/ALL.chr1.phase3.genotypes\n","--ignore-weights YES\n","--power -1\n","--her 0.5\n","--num-phenos 100\n","--num-causals 1000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from /content/drive/MyDrive/CSE-284-Final-Project/data/bed/ALL.chr1.phase3.genotypes.fam\n","\n","Reading details for 943768 predictors from /content/drive/MyDrive/CSE-284-Final-Project/data/bed/ALL.chr1.phase3.genotypes.bim\n","\n","Data contain 2504 samples and 943768 predictors\n","\n","Making phenotypes for Chunk 1 of 47\n","Making phenotypes for Chunk 2 of 47\n","Making phenotypes for Chunk 3 of 47\n","Making phenotypes for Chunk 4 of 47\n","Making phenotypes for Chunk 5 of 47\n","Making phenotypes for Chunk 6 of 47\n","Making phenotypes for Chunk 7 of 47\n","Making phenotypes for Chunk 8 of 47\n","Making phenotypes for Chunk 9 of 47\n","Making phenotypes for Chunk 10 of 47\n","Making phenotypes for Chunk 11 of 47\n","Making phenotypes for Chunk 12 of 47\n","Making phenotypes for Chunk 13 of 47\n","Making phenotypes for Chunk 14 of 47\n","Making phenotypes for Chunk 15 of 47\n","Making phenotypes for Chunk 16 of 47\n","Making phenotypes for Chunk 17 of 47\n","Making phenotypes for Chunk 18 of 47\n","Making phenotypes for Chunk 19 of 47\n","Making phenotypes for Chunk 20 of 47\n","Making phenotypes for Chunk 21 of 47\n","Making phenotypes for Chunk 22 of 47\n","Making phenotypes for Chunk 23 of 47\n","Making phenotypes for Chunk 24 of 47\n","Making phenotypes for Chunk 25 of 47\n","Making phenotypes for Chunk 26 of 47\n","Making phenotypes for Chunk 27 of 47\n","Making phenotypes for Chunk 28 of 47\n","Making phenotypes for Chunk 29 of 47\n","Making phenotypes for Chunk 30 of 47\n","Making phenotypes for Chunk 31 of 47\n","Making phenotypes for Chunk 32 of 47\n","Making phenotypes for Chunk 33 of 47\n","Making phenotypes for Chunk 34 of 47\n","Making phenotypes for Chunk 35 of 47\n","Making phenotypes for Chunk 36 of 47\n","Making phenotypes for Chunk 37 of 47\n","Making phenotypes for Chunk 38 of 47\n","Making phenotypes for Chunk 39 of 47\n","Making phenotypes for Chunk 40 of 47\n","Making phenotypes for Chunk 41 of 47\n","Making phenotypes for Chunk 42 of 47\n","Making phenotypes for Chunk 43 of 47\n","Making phenotypes for Chunk 44 of 47\n","Making phenotypes for Chunk 45 of 47\n","Making phenotypes for Chunk 46 of 47\n","Making phenotypes for Chunk 47 of 47\n","\n","Phenotypes saved in /content/drive/MyDrive/CSE-284-Final-Project/data/phen/ldak/chr1_para={power=-1,her=0.5,num-phenos=100,num-causals=1000}.pheno, with breeding values in /content/drive/MyDrive/CSE-284-Final-Project/data/phen/ldak/chr1_para={power=-1,her=0.5,num-phenos=100,num-causals=1000}.breed and effect sizes in /content/drive/MyDrive/CSE-284-Final-Project/data/phen/ldak/chr1_para={power=-1,her=0.5,num-phenos=100,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n"]}]}]}