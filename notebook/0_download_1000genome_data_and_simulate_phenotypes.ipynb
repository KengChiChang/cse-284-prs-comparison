{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nnzyjdqnCApT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709668274587,"user_tz":480,"elapsed":21413,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"0b61a180-dab9-4101-ceac-9a6dcdf7a4a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["! wget https://www.dropbox.com/s/y6ytfoybz48dc0u/all_phase3.pgen.zst\n","! wget https://www.dropbox.com/s/odlexvo8fummcvt/all_phase3.pvar.zst\n","! wget https://www.dropbox.com/s/6ppo144ikdzery5/phase3_corrected.psam"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1MWKFGbK2qu","executionInfo":{"status":"ok","timestamp":1709668418286,"user_tz":480,"elapsed":100270,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"f175b0a6-5190-4f9a-bbc4-b9a5445971e3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-05 19:51:58--  https://www.dropbox.com/s/y6ytfoybz48dc0u/all_phase3.pgen.zst\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /s/raw/y6ytfoybz48dc0u/all_phase3.pgen.zst [following]\n","--2024-03-05 19:51:58--  https://www.dropbox.com/s/raw/y6ytfoybz48dc0u/all_phase3.pgen.zst\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com/cd/0/inline/COgX-GWLNXlTfW-DkFikEqMj_INmyaGvhEn9XAtEjrpp8Gsz4ZFSuEuBsYQjUqtRT2apwbXidCvnfgYXDI6JCC7HlNcWpMvIbB3t6tefjDwbNRzaJ2OaRxc3wWPfOu277A4/file# [following]\n","--2024-03-05 19:51:58--  https://uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com/cd/0/inline/COgX-GWLNXlTfW-DkFikEqMj_INmyaGvhEn9XAtEjrpp8Gsz4ZFSuEuBsYQjUqtRT2apwbXidCvnfgYXDI6JCC7HlNcWpMvIbB3t6tefjDwbNRzaJ2OaRxc3wWPfOu277A4/file\n","Resolving uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com (uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6019:15::a27d:40f\n","Connecting to uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com (uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/COgDlB6zw7yveSKbmxFuvDPQRkSJCVXTKxLbslyTR2igeaElBUOo5OhnIlRchBS7uUMmarp5Tp6eWInBS4S58hvxfddWU_FAeOUgf1Qm9GsyQt_bo96W5qXCo-pldFcszZ4aA4lz_XwZAyCA-AthzOnJrZ15S1NvQQFDYB-RN3_Tg458RXBBwpfL4P-XUlkaNmTxkNcLiEakVxXCtn1KzYAFrrcBkU1JOvtNpIBfGV5I1HTuhpMEBAPdX15zBbsJHl6M_5zCMr-gKYe_SysCY_A5lTCrCiWsvs8AzajKz3umROXU3A94mDBe4frluPo3DcfOdM47bsgvFJ2HGfTmFeE0i7j-m-yGGSdIzEZdWHCaLQ/file [following]\n","--2024-03-05 19:51:59--  https://uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com/cd/0/inline2/COgDlB6zw7yveSKbmxFuvDPQRkSJCVXTKxLbslyTR2igeaElBUOo5OhnIlRchBS7uUMmarp5Tp6eWInBS4S58hvxfddWU_FAeOUgf1Qm9GsyQt_bo96W5qXCo-pldFcszZ4aA4lz_XwZAyCA-AthzOnJrZ15S1NvQQFDYB-RN3_Tg458RXBBwpfL4P-XUlkaNmTxkNcLiEakVxXCtn1KzYAFrrcBkU1JOvtNpIBfGV5I1HTuhpMEBAPdX15zBbsJHl6M_5zCMr-gKYe_SysCY_A5lTCrCiWsvs8AzajKz3umROXU3A94mDBe4frluPo3DcfOdM47bsgvFJ2HGfTmFeE0i7j-m-yGGSdIzEZdWHCaLQ/file\n","Reusing existing connection to uce9aa5238421668ce0715579ffa.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2414715690 (2.2G) [application/octet-stream]\n","Saving to: ‘all_phase3.pgen.zst’\n","\n","all_phase3.pgen.zst 100%[===================>]   2.25G  51.9MB/s    in 82s     \n","\n","2024-03-05 19:53:22 (28.1 MB/s) - ‘all_phase3.pgen.zst’ saved [2414715690/2414715690]\n","\n","--2024-03-05 19:53:22--  https://www.dropbox.com/s/odlexvo8fummcvt/all_phase3.pvar.zst\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /s/raw/odlexvo8fummcvt/all_phase3.pvar.zst [following]\n","--2024-03-05 19:53:22--  https://www.dropbox.com/s/raw/odlexvo8fummcvt/all_phase3.pvar.zst\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com/cd/0/inline/COhOGPAyzdrcjrtwskKViXPo5qcaGAA5FRzvck2WH2Dn6DWMM-s5WDvZjKfY7jPbyyTTFBNy_EjvA-uAA_B6pyJcqO1uzChS3CbZBpZhurjg9sHXYxJbMDOLC4rtE2Dx_4w/file# [following]\n","--2024-03-05 19:53:22--  https://uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com/cd/0/inline/COhOGPAyzdrcjrtwskKViXPo5qcaGAA5FRzvck2WH2Dn6DWMM-s5WDvZjKfY7jPbyyTTFBNy_EjvA-uAA_B6pyJcqO1uzChS3CbZBpZhurjg9sHXYxJbMDOLC4rtE2Dx_4w/file\n","Resolving uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com (uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n","Connecting to uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com (uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/COjqAWQ7mP_74DhLxjiuxUqLS2bgy7t2GxBnfrLnS-qTXEWOAh0R1KPqTT2hAEqZB0TB2pWSqA8N2ihSBlaydlyg0HKkRbCiOYZKl0S5LTTry7r0yiGcncTOWwPToOQbGGZTkhnwXJlkipXsGVrEvk0YGWA37YexfKe-It0VirqWvAP_woHjywxHEc-itH9H5joYBnSZuYeLsiG7k9z29yO4AxirizyeM6XRYbrAOcqkW93Z_4ghbcbzA7SgOIwva9XUofFebFUycTGSzPmpctvlN7NHYLT8zaYFUecFOIS7fYuY5JJvHYSe3wfWpfPO__eu4aY595Md-Cni1b-Cu4xBxJFWDYSHCl9-IBBET0c-YQ/file [following]\n","--2024-03-05 19:53:23--  https://uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com/cd/0/inline2/COjqAWQ7mP_74DhLxjiuxUqLS2bgy7t2GxBnfrLnS-qTXEWOAh0R1KPqTT2hAEqZB0TB2pWSqA8N2ihSBlaydlyg0HKkRbCiOYZKl0S5LTTry7r0yiGcncTOWwPToOQbGGZTkhnwXJlkipXsGVrEvk0YGWA37YexfKe-It0VirqWvAP_woHjywxHEc-itH9H5joYBnSZuYeLsiG7k9z29yO4AxirizyeM6XRYbrAOcqkW93Z_4ghbcbzA7SgOIwva9XUofFebFUycTGSzPmpctvlN7NHYLT8zaYFUecFOIS7fYuY5JJvHYSe3wfWpfPO__eu4aY595Md-Cni1b-Cu4xBxJFWDYSHCl9-IBBET0c-YQ/file\n","Reusing existing connection to uc666a5269aa3124b9cbf0d73eed.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1350604833 (1.3G) [application/octet-stream]\n","Saving to: ‘all_phase3.pvar.zst’\n","\n","all_phase3.pvar.zst 100%[===================>]   1.26G   118MB/s    in 13s     \n","\n","2024-03-05 19:53:37 (101 MB/s) - ‘all_phase3.pvar.zst’ saved [1350604833/1350604833]\n","\n","--2024-03-05 19:53:37--  https://www.dropbox.com/s/6ppo144ikdzery5/phase3_corrected.psam\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /s/raw/6ppo144ikdzery5/phase3_corrected.psam [following]\n","--2024-03-05 19:53:37--  https://www.dropbox.com/s/raw/6ppo144ikdzery5/phase3_corrected.psam\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uce0ce5c24e9aa9cde13a2955122.dl.dropboxusercontent.com/cd/0/inline/COiRuJoo4Cisk2BPNjZ7W_XY4OruNWVz3OQG-Gaf7zw2Uy24fAjTVrxj7VR_Vrjuy-uxh7AO43edZMEXd64gG00w6nQ9Y_LRFghp4WK5J9_Lb2JuEkRKis9lJYh035uuqpU/file# [following]\n","--2024-03-05 19:53:37--  https://uce0ce5c24e9aa9cde13a2955122.dl.dropboxusercontent.com/cd/0/inline/COiRuJoo4Cisk2BPNjZ7W_XY4OruNWVz3OQG-Gaf7zw2Uy24fAjTVrxj7VR_Vrjuy-uxh7AO43edZMEXd64gG00w6nQ9Y_LRFghp4WK5J9_Lb2JuEkRKis9lJYh035uuqpU/file\n","Resolving uce0ce5c24e9aa9cde13a2955122.dl.dropboxusercontent.com (uce0ce5c24e9aa9cde13a2955122.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6019:15::a27d:40f\n","Connecting to uce0ce5c24e9aa9cde13a2955122.dl.dropboxusercontent.com (uce0ce5c24e9aa9cde13a2955122.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 55173 (54K) [text/plain]\n","Saving to: ‘phase3_corrected.psam’\n","\n","phase3_corrected.ps 100%[===================>]  53.88K  --.-KB/s    in 0.01s   \n","\n","2024-03-05 19:53:37 (5.27 MB/s) - ‘phase3_corrected.psam’ saved [55173/55173]\n","\n"]}]},{"cell_type":"code","source":["! wget https://s3.amazonaws.com/plink2-assets/alpha5/plink2_linux_x86_64_20240105.zip\n","! unzip plink2_linux_x86_64_20240105.zip\n","! ./plink2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIu2cIejLOBY","executionInfo":{"status":"ok","timestamp":1709668419244,"user_tz":480,"elapsed":961,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"62fe8adb-42fc-4581-dc8c-00cf01c85bad"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-05 19:53:38--  https://s3.amazonaws.com/plink2-assets/alpha5/plink2_linux_x86_64_20240105.zip\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.83.102, 52.217.43.54, 54.231.139.208, ...\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.83.102|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9266484 (8.8M) [application/zip]\n","Saving to: ‘plink2_linux_x86_64_20240105.zip’\n","\n","plink2_linux_x86_64 100%[===================>]   8.84M  58.7MB/s    in 0.2s    \n","\n","2024-03-05 19:53:38 (58.7 MB/s) - ‘plink2_linux_x86_64_20240105.zip’ saved [9266484/9266484]\n","\n","Archive:  plink2_linux_x86_64_20240105.zip\n","  inflating: plink2                  \n","PLINK v2.00a5.10LM 64-bit Intel (5 Jan 2024)   www.cog-genomics.org/plink/2.0/\n","(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n","\n","  plink2 <input flag(s)...> [command flag(s)...] [other flag(s)...]\n","  plink2 --help [flag name(s)...]\n","\n","Commands include --rm-dup list, --make-bpgen, --export, --freq, --geno-counts,\n","--sample-counts, --missing, --hardy, --het, --fst, --indep-pairwise, --ld,\n","--sample-diff, --make-king, --king-cutoff, --pmerge, --pgen-diff,\n","--write-samples, --write-snplist, --make-grm-list, --pca, --glm, --adjust-file,\n","--gwas-ssf, --clump, --score, --variant-score, --genotyping-rate, --pgen-info,\n","--validate, and --zst-decompress.\n","\n","\"plink2 --help | more\" describes all functions.\n"]}]},{"cell_type":"code","source":["! ./plink2 --zst-decompress all_phase3.pgen.zst > all_phase3.pgen\n","! ./plink2 --zst-decompress all_phase3.pvar.zst > all_phase3.pvar"],"metadata":{"id":"E2Mp3lWDLVwB","executionInfo":{"status":"ok","timestamp":1709668574807,"user_tz":480,"elapsed":138763,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["! echo \".\" > exclude.snps\n","! ./plink2 --make-bed --out raw --pgen all_phase3.pgen --pvar all_phase3.pvar --psam phase3_corrected.psam --maf 0.01 --autosome --snps-only just-acgt --max-alleles 2 --rm-dup exclude-all --exclude exclude.snps"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dlh8shuLvZW","executionInfo":{"status":"ok","timestamp":1709668860205,"user_tz":480,"elapsed":285006,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"fc3ae1ea-341f-4ef6-8809-addcc7ba891d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["PLINK v2.00a5.10LM 64-bit Intel (5 Jan 2024)   www.cog-genomics.org/plink/2.0/\n","(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n","Logging to raw.log.\n","Options in effect:\n","  --autosome\n","  --exclude exclude.snps\n","  --maf 0.01\n","  --make-bed\n","  --max-alleles 2\n","  --out raw\n","  --pgen all_phase3.pgen\n","  --psam phase3_corrected.psam\n","  --pvar all_phase3.pvar\n","  --rm-dup exclude-all\n","  --snps-only just-acgt\n","\n","Start time: Tue Mar  5 19:56:15 2024\n","12978 MiB RAM detected, ~11957 available; reserving 6489 MiB for main\n","workspace.\n","Using up to 2 compute threads.\n","2504 samples (1270 females, 1234 males; 2497 founders) loaded from\n","phase3_corrected.psam.\n","77818345 out of 84805772 variants loaded from all_phase3.pvar.\n","2 categorical phenotypes loaded.\n","--exclude: 77818101 variants remaining.\n","--rm-dup: 191 duplicated IDs, 382 variants removed.\n","Calculating allele frequencies... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\bdone.\n","65694238 variants removed due to allele frequency threshold(s)\n","(--maf/--max-maf/--mac/--max-mac).\n","12123481 variants remaining after main filters.\n","Writing raw.fam ... done.\n","Writing raw.bim ... done.\n","Writing raw.bed ... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\bdone.\n","End time: Tue Mar  5 20:00:58 2024\n"]}]},{"cell_type":"code","source":["! awk '(NR==FNR){arr[$1]=$5\"_\"$6;ars[$1]=$4;next}{$1=$2;$2=arr[$1];$5=ars[$1];print $0}' phase3_corrected.psam raw.fam > clean.fam\n","! awk < raw.bim '{$2=$1\":\"$4;print $0}' > clean.bim\n","! awk < raw.bim '{print $1\":\"$4, $2}' > 1000g.names\n","! cp raw.bed clean.bed"],"metadata":{"id":"F45DFVFbL-k5","executionInfo":{"status":"ok","timestamp":1709668946992,"user_tz":480,"elapsed":86790,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["! wget https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20231211.zip\n","! unzip plink_linux_x86_64_20231211.zip\n","! ./plink"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANMGwE7mMcEB","executionInfo":{"status":"ok","timestamp":1709669107124,"user_tz":480,"elapsed":959,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"d6cd3497-e7a6-473c-839b-da9ba2fe691a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-05 20:05:06--  https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20231211.zip\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.44.88, 52.216.92.165, 52.216.207.181, ...\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.44.88|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8953953 (8.5M) [application/zip]\n","Saving to: ‘plink_linux_x86_64_20231211.zip’\n","\n","plink_linux_x86_64_ 100%[===================>]   8.54M  45.4MB/s    in 0.2s    \n","\n","2024-03-05 20:05:06 (45.4 MB/s) - ‘plink_linux_x86_64_20231211.zip’ saved [8953953/8953953]\n","\n","Archive:  plink_linux_x86_64_20231211.zip\n","  inflating: plink                   \n","  inflating: LICENSE                 \n","  inflating: toy.ped                 \n","  inflating: toy.map                 \n","  inflating: prettify                \n","PLINK v1.90b7.2 64-bit (11 Dec 2023)           www.cog-genomics.org/plink/1.9/\n","(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n","\n","  plink <input flag(s)...> [command flag(s)...] [other flag(s)...]\n","  plink --help [flag name(s)...]\n","\n","Commands include --make-bed, --recode, --flip-scan, --merge-list,\n","--write-snplist, --list-duplicate-vars, --freqx, --missing, --test-mishap,\n","--hardy, --mendel, --ibc, --impute-sex, --indep-pairphase, --r2, --show-tags,\n","--blocks, --distance, --genome, --homozyg, --make-rel, --make-grm-gz,\n","--rel-cutoff, --cluster, --pca, --neighbour, --ibs-test, --regress-distance,\n","--model, --bd, --gxe, --logistic, --dosage, --lasso, --test-missing,\n","--make-perm-pheno, --tdt, --qfam, --annotate, --clump, --gene-report,\n","--meta-analysis, --epistasis, --fast-epistasis, and --score.\n","\n","\"plink --help | more\" describes all functions (warning: long).\n"]}]},{"cell_type":"code","source":["! wget https://www.dropbox.com/s/slchsd0uyd4hii8/genetic_map_b37.zip\n","! unzip genetic_map_b37.zip\n","! ./plink --bfile clean --cm-map genetic_map_b37/genetic_map_chr@_combined_b37.txt --make-bed --out 1000g"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0f6HcocMCNs","executionInfo":{"status":"ok","timestamp":1709669279297,"user_tz":480,"elapsed":156045,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"6b0e35f6-72d5-4747-c23c-bd7c39934d84"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-05 20:05:23--  https://www.dropbox.com/s/slchsd0uyd4hii8/genetic_map_b37.zip\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /s/raw/slchsd0uyd4hii8/genetic_map_b37.zip [following]\n","--2024-03-05 20:05:23--  https://www.dropbox.com/s/raw/slchsd0uyd4hii8/genetic_map_b37.zip\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com/cd/0/inline/COhHXu5OGLBuf8UCr76nsA_AB7HxsyGDiVoJ9HObC1qB5Wm_QQWQlLBd9asqYr4GA_KqSnPeltTOlYZETR_I2aUcpnc9E99vEMOgd3l_EgZbdfTKTw700I3UAGB_1A3phVs/file# [following]\n","--2024-03-05 20:05:24--  https://uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com/cd/0/inline/COhHXu5OGLBuf8UCr76nsA_AB7HxsyGDiVoJ9HObC1qB5Wm_QQWQlLBd9asqYr4GA_KqSnPeltTOlYZETR_I2aUcpnc9E99vEMOgd3l_EgZbdfTKTw700I3UAGB_1A3phVs/file\n","Resolving uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com (uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n","Connecting to uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com (uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/COjHwsCnqGs_qve8Zd3uP4N7hQ3p7XWuj36Rq2uvGNc4hsKCjwVlLIpAHQh2kC68kjrmeUWU6majskC8UJHrHNSN-sSgmNVP4T1QNiAQL-PaJjPGLN8sm6jgNK3uVVUgwpbX_zyunoeSt6XYpM9XX3C8715eFcui6dSiSn6aUytYXtIIunDKv4eke27PytiSXR37xeoUCb3qR9kswN-Fji6Hlr1-DN6IGOLCF2g6ZJO0mW7DBMjcODWHMuTJihfPGM-ewVGrq8q2RBlyo59tlbc0S0jGv6xKETI0nVVe6nGINNf9BHqUn7tl7QAobCgqzwf7oqTbeG2WhXh84Nrv9N6LsaSfPbKGERknOxBo-VvFfQ/file [following]\n","--2024-03-05 20:05:25--  https://uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com/cd/0/inline2/COjHwsCnqGs_qve8Zd3uP4N7hQ3p7XWuj36Rq2uvGNc4hsKCjwVlLIpAHQh2kC68kjrmeUWU6majskC8UJHrHNSN-sSgmNVP4T1QNiAQL-PaJjPGLN8sm6jgNK3uVVUgwpbX_zyunoeSt6XYpM9XX3C8715eFcui6dSiSn6aUytYXtIIunDKv4eke27PytiSXR37xeoUCb3qR9kswN-Fji6Hlr1-DN6IGOLCF2g6ZJO0mW7DBMjcODWHMuTJihfPGM-ewVGrq8q2RBlyo59tlbc0S0jGv6xKETI0nVVe6nGINNf9BHqUn7tl7QAobCgqzwf7oqTbeG2WhXh84Nrv9N6LsaSfPbKGERknOxBo-VvFfQ/file\n","Reusing existing connection to uc8c19cce5e5ea22f83f79812242.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 50554370 (48M) [application/zip]\n","Saving to: ‘genetic_map_b37.zip’\n","\n","genetic_map_b37.zip 100%[===================>]  48.21M  13.7MB/s    in 3.5s    \n","\n","2024-03-05 20:05:29 (13.7 MB/s) - ‘genetic_map_b37.zip’ saved [50554370/50554370]\n","\n","Archive:  genetic_map_b37.zip\n","  inflating: genetic_map_b37/genetic_map_chr10_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr11_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr12_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr13_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr14_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr15_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr16_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr17_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr18_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr19_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr1_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr20_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr21_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr22_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr2_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr3_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr4_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr5_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr6_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr7_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr8_combined_b37.txt  \n","  inflating: genetic_map_b37/genetic_map_chr9_combined_b37.txt  \n","PLINK v1.90b7.2 64-bit (11 Dec 2023)           www.cog-genomics.org/plink/1.9/\n","(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n","Logging to 1000g.log.\n","Options in effect:\n","  --bfile clean\n","  --cm-map genetic_map_b37/genetic_map_chr@_combined_b37.txt\n","  --make-bed\n","  --out 1000g\n","\n","12978 MB RAM detected; reserving 6489 MB for main workspace.\n","12123481 variants loaded from .bim file.\n","2504 people (1234 males, 1270 females) loaded from .fam.\n","--cm-map: 22 chromosomes updated.\n","Using 1 thread (no multithreaded calculations invoked).\n","Before main variant filters, 2497 founders and 7 nonfounders present.\n","Calculating allele frequencies... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\b\b done.\n","Total genotyping rate is exactly 1.\n","12123481 variants and 2504 people pass filters and QC.\n","Note: No phenotypes present.\n","--make-bed to 1000g.bed + 1000g.bim + 1000g.fam ... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\bdone.\n"]}]},{"cell_type":"code","source":["! cp all_phase3.pgen.zst all_phase3.pvar.zst phase3* raw.* clean.* /content/drive/MyDrive/CSE-284-Final-Project/data/1000g_raw_combined\n","! cp 1000g* /content/drive/MyDrive/CSE-284-Final-Project/data/1000g_combined\n"],"metadata":{"id":"1QIPn8lqLhMR","executionInfo":{"status":"ok","timestamp":1709669828814,"user_tz":480,"elapsed":500504,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["! rm raw* all*"],"metadata":{"id":"XQ71i3-xRQ_J","executionInfo":{"status":"ok","timestamp":1709670033375,"user_tz":480,"elapsed":365,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["! wget https://dougspeed.com/wp-content/uploads/ldak5.2.linux_.zip\n","! unzip ldak5.2.linux_.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4xloSn7RR9L","executionInfo":{"status":"ok","timestamp":1709669986097,"user_tz":480,"elapsed":2706,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"88dea27d-51d2-46e9-a3a7-a8127765ddad"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-05 20:19:43--  https://dougspeed.com/wp-content/uploads/ldak5.2.linux_.zip\n","Resolving dougspeed.com (dougspeed.com)... 35.214.77.229\n","Connecting to dougspeed.com (dougspeed.com)|35.214.77.229|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9265672 (8.8M) [application/zip]\n","Saving to: ‘ldak5.2.linux_.zip’\n","\n","ldak5.2.linux_.zip  100%[===================>]   8.84M  7.34MB/s    in 1.2s    \n","\n","2024-03-05 20:19:45 (7.34 MB/s) - ‘ldak5.2.linux_.zip’ saved [9265672/9265672]\n","\n","Archive:  ldak5.2.linux_.zip\n","  inflating: ldak5.2.linux           \n"]}]},{"cell_type":"code","source":["! ./ldak5.2.linux"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sATCzei_RqBg","executionInfo":{"status":"ok","timestamp":1709670057227,"user_tz":480,"elapsed":205,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"6d7f7e83-d80b-4bc4-ad51-aaaddebeeb16"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 0 pairs of arguments:\n","\n","Error, each command requires a main argument; here is a list of main arguments\n","\n","Heritability analysis using individual-level data:\n","\n","--cut-weights <folder> - cut predictors into sections ready for calculating weightings\n","--calc-weights <folder> - calculate weightings for one section\n","--join-weights <folder> - join weightings across sections\n","--calc-weights-all <folder> - calculate weightings for all sections in one step\n","\n","--cut-kins <folder> - cut predictors into partitions ready for calculating kinships\n","--calc-kins <folder> - calculate kinship matrix for one partition\n","--join-kins <folder> - join kinship matrices across partitions\n","--calc-kins-direct <output> - calculate kinship matrix in one step\n","\n","--reml <output> - regress phenotype on kinships and/or regions\n","--calc-blups <output> - calculate BLUP effect size estimates (using results from --reml)\n","--he <output> - perform Haseman Elston Regression (an alternative to --reml)\n","--pcgc <output> - perform PCGC Regression (recommended instead of --reml for binary traits)\n","--fast-he <output> - perform fast (but approximate) Haseman Elston Regression\n","--fast-pcgc <output> - perform fast (but approximate) PCGC Regression\n","\n","Association testing:\n","\n","--linear <output> - perform standard or mixed-model linear regression\n","--logistic <output> - perform logistic regression\n","--solve-null <output> - perform two-part mixed-model linear regression (for complex models)\n","\n","--cut-genes <folder> - cut predictors into genes (or fixed-length chunks)\n","--calc-genes-kins <folder> - calculate kinships for each gene/chunk in one partition\n","--calc-genes-reml <folder> - calculate association test for each gene in one partition\n","--join-genes-reml <folder> - join association test results across partitions (also computes more accurate p-values)\n","\n","Heritability analysis using summary statistics:\n","\n","--calc-tagging <output> - calculate tagging file for use with --sum-hers or --sum-cors\n","--join-tagging <output> - join tagging files across predictors\n","--merge-tagging <output> - combine tagging files across categories\n","--reduce-tagging <output> - extract categories from a tagging file\n","\n","--sum-hers <output> - estimate heritabilities from summary statistics\n","--sum-cors <output> - estimate genetic correlations from summary statistics\n","--calc-exps <output> - calculate expected heritability tagged by predictors (using results from --sum-hers)\n","--calc-posts <output> - calculate posterior estimate of predictor effect sizes (using results from --calc-exps)\n","\n","Prediction:\n","\n","--ridge <output> - construct a ridge regression prediction model\n","--bolt <output> - construct a Bolt prediction model\n","--bayesr <output> -  construct a BayesR prediction model\n","--elastic <output> -  construct an elastic-net prediction model\n","\n","--calc-cors <output> - calculate predictor-predictor correlations for use with --mega-prs\n","--join-cors <output> - join correlations across predictors\n","--pseudo-summaries <output> - generate partial summary statistics (used to train MegaPRS prediction models)\n","--mega-prs <output> - construct lasso, ridge regression, Bolt and BayesR prediction models from summary statistics\n","\n","Other features:\n","\n","--thin <output> - prune predictors based on pairwise correlations\n","--thin-tops <output> - prune highly-associated predictors based on pairwise correlations\n","--find-tags <output> - search for the predictors most correlated with those in a scorefile\n","--remove-tags <output> - search for all predictors correlated with those in a target file\n","\n","--filter <output> - fiter samples based on relatedness\n","--add-grm <output> - combine kinship matrices\n","--sub-grm <output> - subtract from one kinship matrix the contributions of other kinship matrices\n","--convert-gz <output> - convert kinship matrix saved in gz (old GCTA) format\n","--convert-raw <output> - convert kinship matrix saved as a text file\n","--calc-sim-grm <output> - calculate correlations between pairs of kinship matrices\n","\n","--pca <output> - compute the principal component axes of a kinship matrix\n","--calc-pca-loads <output> - calculate the principal component predictor loadings (using results from --pca)\n","--decompose <output> - eigen-decompose a kinship matrix\n","--adjust-grm <output> - adjust a kinship matrix for covariates\n","--gxemm-iid / --gxemm-free <output> - calculate environmental kinship matrices\n","\n","--calc-stats <output> - calculate predictor allele frequencies, call-rates and possibly information scores\n","--calc-scores <output> - calculate one or more polygenic risk scores\n","--make-phenos <output> - simulate phenotypes\n","--make-snps <output> - simulate SNP data\n","\n","--jackknife <output> - measure prediction accuracy, obtaining standard deviations via block jackknifing\n","--cut-folds <output> - divide samples in preparation for performing K-fold cross-validation\n","--find-gaussian <output> - estimate the selection-related parameter alpha (using results from --sum-hers)\n","\n","--make-bed / --make-sp / --make-sped / --make-speed / --make-gen <outfile> - convert to bed / sp / sped / speed / gen format\n","--condense-bed / condense-sp / condense-sped / condense-speed <outfile> - condense to bed / sp / sped / speed format\n","--calc-sim-data <outfile> - calculate concordance between two datasets\n","\n"]}]},{"cell_type":"code","source":["sh = \"\"\"\n","\n","BFILE=1000g\n","\n","for HER in {0.1,0.3,0.5,0.7,0.9}\n","\n","do\n","    for NUM in {1,10,100,1000,10000}\n","\n","    do\n","\n","        OUT=HumDef_params={her=$HER,num-causals=$NUM}\n","\n","        ./ldak5.2.linux \\\n","            --make-phenos $OUT \\\n","            --bfile $BFILE \\\n","            --power -.25 \\\n","            --num-phenos 100 \\\n","            --her $HER \\\n","            --num-causals $NUM\n","\n","    done\n","\n","done\n","\n","\"\"\"\n","with open('script.sh', 'w') as file:\n","  file.write(sh)\n","\n","! bash script.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjwDZgSVRSwS","executionInfo":{"status":"ok","timestamp":1709676210522,"user_tz":480,"elapsed":982751,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"a4498277-c372-4200-b525-e9cf576531b4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.1,num-causals=1}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.1\n","--num-causals 1\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.1,num-causals=1}.pheno, with breeding values in HumDef_params={her=0.1,num-causals=1}.breed and effect sizes in HumDef_params={her=0.1,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.1,num-causals=10}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.1\n","--num-causals 10\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.1,num-causals=10}.pheno, with breeding values in HumDef_params={her=0.1,num-causals=10}.breed and effect sizes in HumDef_params={her=0.1,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.1,num-causals=100}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.1\n","--num-causals 100\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in HumDef_params={her=0.1,num-causals=100}.pheno, with breeding values in HumDef_params={her=0.1,num-causals=100}.breed and effect sizes in HumDef_params={her=0.1,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.1,num-causals=1000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.1\n","--num-causals 1000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in HumDef_params={her=0.1,num-causals=1000}.pheno, with breeding values in HumDef_params={her=0.1,num-causals=1000}.breed and effect sizes in HumDef_params={her=0.1,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.1,num-causals=10000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.1\n","--num-causals 10000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 469\n","Making phenotypes for Chunk 2 of 469\n","Making phenotypes for Chunk 3 of 469\n","Making phenotypes for Chunk 4 of 469\n","Making phenotypes for Chunk 5 of 469\n","Making phenotypes for Chunk 6 of 469\n","Making phenotypes for Chunk 7 of 469\n","Making phenotypes for Chunk 8 of 469\n","Making phenotypes for Chunk 9 of 469\n","Making phenotypes for Chunk 10 of 469\n","Making phenotypes for Chunk 11 of 469\n","Making phenotypes for Chunk 12 of 469\n","Making phenotypes for Chunk 13 of 469\n","Making phenotypes for Chunk 14 of 469\n","Making phenotypes for Chunk 15 of 469\n","Making phenotypes for Chunk 16 of 469\n","Making phenotypes for Chunk 17 of 469\n","Making phenotypes for Chunk 18 of 469\n","Making phenotypes for Chunk 19 of 469\n","Making phenotypes for Chunk 20 of 469\n","Making phenotypes for Chunk 21 of 469\n","Making phenotypes for Chunk 22 of 469\n","Making phenotypes for Chunk 23 of 469\n","Making phenotypes for Chunk 24 of 469\n","Making phenotypes for Chunk 25 of 469\n","Making phenotypes for Chunk 26 of 469\n","Making phenotypes for Chunk 27 of 469\n","Making phenotypes for Chunk 28 of 469\n","Making phenotypes for Chunk 29 of 469\n","Making phenotypes for Chunk 30 of 469\n","Making phenotypes for Chunk 31 of 469\n","Making phenotypes for Chunk 32 of 469\n","Making phenotypes for Chunk 33 of 469\n","Making phenotypes for Chunk 34 of 469\n","Making phenotypes for Chunk 35 of 469\n","Making phenotypes for Chunk 36 of 469\n","Making phenotypes for Chunk 37 of 469\n","Making phenotypes for Chunk 38 of 469\n","Making phenotypes for Chunk 39 of 469\n","Making phenotypes for Chunk 40 of 469\n","Making phenotypes for Chunk 41 of 469\n","Making phenotypes for Chunk 42 of 469\n","Making phenotypes for Chunk 43 of 469\n","Making phenotypes for Chunk 44 of 469\n","Making phenotypes for Chunk 45 of 469\n","Making phenotypes for Chunk 46 of 469\n","Making phenotypes for Chunk 47 of 469\n","Making phenotypes for Chunk 48 of 469\n","Making phenotypes for Chunk 49 of 469\n","Making phenotypes for Chunk 50 of 469\n","Making phenotypes for Chunk 51 of 469\n","Making phenotypes for Chunk 52 of 469\n","Making phenotypes for Chunk 53 of 469\n","Making phenotypes for Chunk 54 of 469\n","Making phenotypes for Chunk 55 of 469\n","Making phenotypes for Chunk 56 of 469\n","Making phenotypes for Chunk 57 of 469\n","Making phenotypes for Chunk 58 of 469\n","Making phenotypes for Chunk 59 of 469\n","Making phenotypes for Chunk 60 of 469\n","Making phenotypes for Chunk 61 of 469\n","Making phenotypes for Chunk 62 of 469\n","Making phenotypes for Chunk 63 of 469\n","Making phenotypes for Chunk 64 of 469\n","Making phenotypes for Chunk 65 of 469\n","Making phenotypes for Chunk 66 of 469\n","Making phenotypes for Chunk 67 of 469\n","Making phenotypes for Chunk 68 of 469\n","Making phenotypes for Chunk 69 of 469\n","Making phenotypes for Chunk 70 of 469\n","Making phenotypes for Chunk 71 of 469\n","Making phenotypes for Chunk 72 of 469\n","Making phenotypes for Chunk 73 of 469\n","Making phenotypes for Chunk 74 of 469\n","Making phenotypes for Chunk 75 of 469\n","Making phenotypes for Chunk 76 of 469\n","Making phenotypes for Chunk 77 of 469\n","Making phenotypes for Chunk 78 of 469\n","Making phenotypes for Chunk 79 of 469\n","Making phenotypes for Chunk 80 of 469\n","Making phenotypes for Chunk 81 of 469\n","Making phenotypes for Chunk 82 of 469\n","Making phenotypes for Chunk 83 of 469\n","Making phenotypes for Chunk 84 of 469\n","Making phenotypes for Chunk 85 of 469\n","Making phenotypes for Chunk 86 of 469\n","Making phenotypes for Chunk 87 of 469\n","Making phenotypes for Chunk 88 of 469\n","Making phenotypes for Chunk 89 of 469\n","Making phenotypes for Chunk 90 of 469\n","Making phenotypes for Chunk 91 of 469\n","Making phenotypes for Chunk 92 of 469\n","Making phenotypes for Chunk 93 of 469\n","Making phenotypes for Chunk 94 of 469\n","Making phenotypes for Chunk 95 of 469\n","Making phenotypes for Chunk 96 of 469\n","Making phenotypes for Chunk 97 of 469\n","Making phenotypes for Chunk 98 of 469\n","Making phenotypes for Chunk 99 of 469\n","Making phenotypes for Chunk 100 of 469\n","Making phenotypes for Chunk 101 of 469\n","Making phenotypes for Chunk 102 of 469\n","Making phenotypes for Chunk 103 of 469\n","Making phenotypes for Chunk 104 of 469\n","Making phenotypes for Chunk 105 of 469\n","Making phenotypes for Chunk 106 of 469\n","Making phenotypes for Chunk 107 of 469\n","Making phenotypes for Chunk 108 of 469\n","Making phenotypes for Chunk 109 of 469\n","Making phenotypes for Chunk 110 of 469\n","Making phenotypes for Chunk 111 of 469\n","Making phenotypes for Chunk 112 of 469\n","Making phenotypes for Chunk 113 of 469\n","Making phenotypes for Chunk 114 of 469\n","Making phenotypes for Chunk 115 of 469\n","Making phenotypes for Chunk 116 of 469\n","Making phenotypes for Chunk 117 of 469\n","Making phenotypes for Chunk 118 of 469\n","Making phenotypes for Chunk 119 of 469\n","Making phenotypes for Chunk 120 of 469\n","Making phenotypes for Chunk 121 of 469\n","Making phenotypes for Chunk 122 of 469\n","Making phenotypes for Chunk 123 of 469\n","Making phenotypes for Chunk 124 of 469\n","Making phenotypes for Chunk 125 of 469\n","Making phenotypes for Chunk 126 of 469\n","Making phenotypes for Chunk 127 of 469\n","Making phenotypes for Chunk 128 of 469\n","Making phenotypes for Chunk 129 of 469\n","Making phenotypes for Chunk 130 of 469\n","Making phenotypes for Chunk 131 of 469\n","Making phenotypes for Chunk 132 of 469\n","Making phenotypes for Chunk 133 of 469\n","Making phenotypes for Chunk 134 of 469\n","Making phenotypes for Chunk 135 of 469\n","Making phenotypes for Chunk 136 of 469\n","Making phenotypes for Chunk 137 of 469\n","Making phenotypes for Chunk 138 of 469\n","Making phenotypes for Chunk 139 of 469\n","Making phenotypes for Chunk 140 of 469\n","Making phenotypes for Chunk 141 of 469\n","Making phenotypes for Chunk 142 of 469\n","Making phenotypes for Chunk 143 of 469\n","Making phenotypes for Chunk 144 of 469\n","Making phenotypes for Chunk 145 of 469\n","Making phenotypes for Chunk 146 of 469\n","Making phenotypes for Chunk 147 of 469\n","Making phenotypes for Chunk 148 of 469\n","Making phenotypes for Chunk 149 of 469\n","Making phenotypes for Chunk 150 of 469\n","Making phenotypes for Chunk 151 of 469\n","Making phenotypes for Chunk 152 of 469\n","Making phenotypes for Chunk 153 of 469\n","Making phenotypes for Chunk 154 of 469\n","Making phenotypes for Chunk 155 of 469\n","Making phenotypes for Chunk 156 of 469\n","Making phenotypes for Chunk 157 of 469\n","Making phenotypes for Chunk 158 of 469\n","Making phenotypes for Chunk 159 of 469\n","Making phenotypes for Chunk 160 of 469\n","Making phenotypes for Chunk 161 of 469\n","Making phenotypes for Chunk 162 of 469\n","Making phenotypes for Chunk 163 of 469\n","Making phenotypes for Chunk 164 of 469\n","Making phenotypes for Chunk 165 of 469\n","Making phenotypes for Chunk 166 of 469\n","Making phenotypes for Chunk 167 of 469\n","Making phenotypes for Chunk 168 of 469\n","Making phenotypes for Chunk 169 of 469\n","Making phenotypes for Chunk 170 of 469\n","Making phenotypes for Chunk 171 of 469\n","Making phenotypes for Chunk 172 of 469\n","Making phenotypes for Chunk 173 of 469\n","Making phenotypes for Chunk 174 of 469\n","Making phenotypes for Chunk 175 of 469\n","Making phenotypes for Chunk 176 of 469\n","Making phenotypes for Chunk 177 of 469\n","Making phenotypes for Chunk 178 of 469\n","Making phenotypes for Chunk 179 of 469\n","Making phenotypes for Chunk 180 of 469\n","Making phenotypes for Chunk 181 of 469\n","Making phenotypes for Chunk 182 of 469\n","Making phenotypes for Chunk 183 of 469\n","Making phenotypes for Chunk 184 of 469\n","Making phenotypes for Chunk 185 of 469\n","Making phenotypes for Chunk 186 of 469\n","Making phenotypes for Chunk 187 of 469\n","Making phenotypes for Chunk 188 of 469\n","Making phenotypes for Chunk 189 of 469\n","Making phenotypes for Chunk 190 of 469\n","Making phenotypes for Chunk 191 of 469\n","Making phenotypes for Chunk 192 of 469\n","Making phenotypes for Chunk 193 of 469\n","Making phenotypes for Chunk 194 of 469\n","Making phenotypes for Chunk 195 of 469\n","Making phenotypes for Chunk 196 of 469\n","Making phenotypes for Chunk 197 of 469\n","Making phenotypes for Chunk 198 of 469\n","Making phenotypes for Chunk 199 of 469\n","Making phenotypes for Chunk 200 of 469\n","Making phenotypes for Chunk 201 of 469\n","Making phenotypes for Chunk 202 of 469\n","Making phenotypes for Chunk 203 of 469\n","Making phenotypes for Chunk 204 of 469\n","Making phenotypes for Chunk 205 of 469\n","Making phenotypes for Chunk 206 of 469\n","Making phenotypes for Chunk 207 of 469\n","Making phenotypes for Chunk 208 of 469\n","Making phenotypes for Chunk 209 of 469\n","Making phenotypes for Chunk 210 of 469\n","Making phenotypes for Chunk 211 of 469\n","Making phenotypes for Chunk 212 of 469\n","Making phenotypes for Chunk 213 of 469\n","Making phenotypes for Chunk 214 of 469\n","Making phenotypes for Chunk 215 of 469\n","Making phenotypes for Chunk 216 of 469\n","Making phenotypes for Chunk 217 of 469\n","Making phenotypes for Chunk 218 of 469\n","Making phenotypes for Chunk 219 of 469\n","Making phenotypes for Chunk 220 of 469\n","Making phenotypes for Chunk 221 of 469\n","Making phenotypes for Chunk 222 of 469\n","Making phenotypes for Chunk 223 of 469\n","Making phenotypes for Chunk 224 of 469\n","Making phenotypes for Chunk 225 of 469\n","Making phenotypes for Chunk 226 of 469\n","Making phenotypes for Chunk 227 of 469\n","Making phenotypes for Chunk 228 of 469\n","Making phenotypes for Chunk 229 of 469\n","Making phenotypes for Chunk 230 of 469\n","Making phenotypes for Chunk 231 of 469\n","Making phenotypes for Chunk 232 of 469\n","Making phenotypes for Chunk 233 of 469\n","Making phenotypes for Chunk 234 of 469\n","Making phenotypes for Chunk 235 of 469\n","Making phenotypes for Chunk 236 of 469\n","Making phenotypes for Chunk 237 of 469\n","Making phenotypes for Chunk 238 of 469\n","Making phenotypes for Chunk 239 of 469\n","Making phenotypes for Chunk 240 of 469\n","Making phenotypes for Chunk 241 of 469\n","Making phenotypes for Chunk 242 of 469\n","Making phenotypes for Chunk 243 of 469\n","Making phenotypes for Chunk 244 of 469\n","Making phenotypes for Chunk 245 of 469\n","Making phenotypes for Chunk 246 of 469\n","Making phenotypes for Chunk 247 of 469\n","Making phenotypes for Chunk 248 of 469\n","Making phenotypes for Chunk 249 of 469\n","Making phenotypes for Chunk 250 of 469\n","Making phenotypes for Chunk 251 of 469\n","Making phenotypes for Chunk 252 of 469\n","Making phenotypes for Chunk 253 of 469\n","Making phenotypes for Chunk 254 of 469\n","Making phenotypes for Chunk 255 of 469\n","Making phenotypes for Chunk 256 of 469\n","Making phenotypes for Chunk 257 of 469\n","Making phenotypes for Chunk 258 of 469\n","Making phenotypes for Chunk 259 of 469\n","Making phenotypes for Chunk 260 of 469\n","Making phenotypes for Chunk 261 of 469\n","Making phenotypes for Chunk 262 of 469\n","Making phenotypes for Chunk 263 of 469\n","Making phenotypes for Chunk 264 of 469\n","Making phenotypes for Chunk 265 of 469\n","Making phenotypes for Chunk 266 of 469\n","Making phenotypes for Chunk 267 of 469\n","Making phenotypes for Chunk 268 of 469\n","Making phenotypes for Chunk 269 of 469\n","Making phenotypes for Chunk 270 of 469\n","Making phenotypes for Chunk 271 of 469\n","Making phenotypes for Chunk 272 of 469\n","Making phenotypes for Chunk 273 of 469\n","Making phenotypes for Chunk 274 of 469\n","Making phenotypes for Chunk 275 of 469\n","Making phenotypes for Chunk 276 of 469\n","Making phenotypes for Chunk 277 of 469\n","Making phenotypes for Chunk 278 of 469\n","Making phenotypes for Chunk 279 of 469\n","Making phenotypes for Chunk 280 of 469\n","Making phenotypes for Chunk 281 of 469\n","Making phenotypes for Chunk 282 of 469\n","Making phenotypes for Chunk 283 of 469\n","Making phenotypes for Chunk 284 of 469\n","Making phenotypes for Chunk 285 of 469\n","Making phenotypes for Chunk 286 of 469\n","Making phenotypes for Chunk 287 of 469\n","Making phenotypes for Chunk 288 of 469\n","Making phenotypes for Chunk 289 of 469\n","Making phenotypes for Chunk 290 of 469\n","Making phenotypes for Chunk 291 of 469\n","Making phenotypes for Chunk 292 of 469\n","Making phenotypes for Chunk 293 of 469\n","Making phenotypes for Chunk 294 of 469\n","Making phenotypes for Chunk 295 of 469\n","Making phenotypes for Chunk 296 of 469\n","Making phenotypes for Chunk 297 of 469\n","Making phenotypes for Chunk 298 of 469\n","Making phenotypes for Chunk 299 of 469\n","Making phenotypes for Chunk 300 of 469\n","Making phenotypes for Chunk 301 of 469\n","Making phenotypes for Chunk 302 of 469\n","Making phenotypes for Chunk 303 of 469\n","Making phenotypes for Chunk 304 of 469\n","Making phenotypes for Chunk 305 of 469\n","Making phenotypes for Chunk 306 of 469\n","Making phenotypes for Chunk 307 of 469\n","Making phenotypes for Chunk 308 of 469\n","Making phenotypes for Chunk 309 of 469\n","Making phenotypes for Chunk 310 of 469\n","Making phenotypes for Chunk 311 of 469\n","Making phenotypes for Chunk 312 of 469\n","Making phenotypes for Chunk 313 of 469\n","Making phenotypes for Chunk 314 of 469\n","Making phenotypes for Chunk 315 of 469\n","Making phenotypes for Chunk 316 of 469\n","Making phenotypes for Chunk 317 of 469\n","Making phenotypes for Chunk 318 of 469\n","Making phenotypes for Chunk 319 of 469\n","Making phenotypes for Chunk 320 of 469\n","Making phenotypes for Chunk 321 of 469\n","Making phenotypes for Chunk 322 of 469\n","Making phenotypes for Chunk 323 of 469\n","Making phenotypes for Chunk 324 of 469\n","Making phenotypes for Chunk 325 of 469\n","Making phenotypes for Chunk 326 of 469\n","Making phenotypes for Chunk 327 of 469\n","Making phenotypes for Chunk 328 of 469\n","Making phenotypes for Chunk 329 of 469\n","Making phenotypes for Chunk 330 of 469\n","Making phenotypes for Chunk 331 of 469\n","Making phenotypes for Chunk 332 of 469\n","Making phenotypes for Chunk 333 of 469\n","Making phenotypes for Chunk 334 of 469\n","Making phenotypes for Chunk 335 of 469\n","Making phenotypes for Chunk 336 of 469\n","Making phenotypes for Chunk 337 of 469\n","Making phenotypes for Chunk 338 of 469\n","Making phenotypes for Chunk 339 of 469\n","Making phenotypes for Chunk 340 of 469\n","Making phenotypes for Chunk 341 of 469\n","Making phenotypes for Chunk 342 of 469\n","Making phenotypes for Chunk 343 of 469\n","Making phenotypes for Chunk 344 of 469\n","Making phenotypes for Chunk 345 of 469\n","Making phenotypes for Chunk 346 of 469\n","Making phenotypes for Chunk 347 of 469\n","Making phenotypes for Chunk 348 of 469\n","Making phenotypes for Chunk 349 of 469\n","Making phenotypes for Chunk 350 of 469\n","Making phenotypes for Chunk 351 of 469\n","Making phenotypes for Chunk 352 of 469\n","Making phenotypes for Chunk 353 of 469\n","Making phenotypes for Chunk 354 of 469\n","Making phenotypes for Chunk 355 of 469\n","Making phenotypes for Chunk 356 of 469\n","Making phenotypes for Chunk 357 of 469\n","Making phenotypes for Chunk 358 of 469\n","Making phenotypes for Chunk 359 of 469\n","Making phenotypes for Chunk 360 of 469\n","Making phenotypes for Chunk 361 of 469\n","Making phenotypes for Chunk 362 of 469\n","Making phenotypes for Chunk 363 of 469\n","Making phenotypes for Chunk 364 of 469\n","Making phenotypes for Chunk 365 of 469\n","Making phenotypes for Chunk 366 of 469\n","Making phenotypes for Chunk 367 of 469\n","Making phenotypes for Chunk 368 of 469\n","Making phenotypes for Chunk 369 of 469\n","Making phenotypes for Chunk 370 of 469\n","Making phenotypes for Chunk 371 of 469\n","Making phenotypes for Chunk 372 of 469\n","Making phenotypes for Chunk 373 of 469\n","Making phenotypes for Chunk 374 of 469\n","Making phenotypes for Chunk 375 of 469\n","Making phenotypes for Chunk 376 of 469\n","Making phenotypes for Chunk 377 of 469\n","Making phenotypes for Chunk 378 of 469\n","Making phenotypes for Chunk 379 of 469\n","Making phenotypes for Chunk 380 of 469\n","Making phenotypes for Chunk 381 of 469\n","Making phenotypes for Chunk 382 of 469\n","Making phenotypes for Chunk 383 of 469\n","Making phenotypes for Chunk 384 of 469\n","Making phenotypes for Chunk 385 of 469\n","Making phenotypes for Chunk 386 of 469\n","Making phenotypes for Chunk 387 of 469\n","Making phenotypes for Chunk 388 of 469\n","Making phenotypes for Chunk 389 of 469\n","Making phenotypes for Chunk 390 of 469\n","Making phenotypes for Chunk 391 of 469\n","Making phenotypes for Chunk 392 of 469\n","Making phenotypes for Chunk 393 of 469\n","Making phenotypes for Chunk 394 of 469\n","Making phenotypes for Chunk 395 of 469\n","Making phenotypes for Chunk 396 of 469\n","Making phenotypes for Chunk 397 of 469\n","Making phenotypes for Chunk 398 of 469\n","Making phenotypes for Chunk 399 of 469\n","Making phenotypes for Chunk 400 of 469\n","Making phenotypes for Chunk 401 of 469\n","Making phenotypes for Chunk 402 of 469\n","Making phenotypes for Chunk 403 of 469\n","Making phenotypes for Chunk 404 of 469\n","Making phenotypes for Chunk 405 of 469\n","Making phenotypes for Chunk 406 of 469\n","Making phenotypes for Chunk 407 of 469\n","Making phenotypes for Chunk 408 of 469\n","Making phenotypes for Chunk 409 of 469\n","Making phenotypes for Chunk 410 of 469\n","Making phenotypes for Chunk 411 of 469\n","Making phenotypes for Chunk 412 of 469\n","Making phenotypes for Chunk 413 of 469\n","Making phenotypes for Chunk 414 of 469\n","Making phenotypes for Chunk 415 of 469\n","Making phenotypes for Chunk 416 of 469\n","Making phenotypes for Chunk 417 of 469\n","Making phenotypes for Chunk 418 of 469\n","Making phenotypes for Chunk 419 of 469\n","Making phenotypes for Chunk 420 of 469\n","Making phenotypes for Chunk 421 of 469\n","Making phenotypes for Chunk 422 of 469\n","Making phenotypes for Chunk 423 of 469\n","Making phenotypes for Chunk 424 of 469\n","Making phenotypes for Chunk 425 of 469\n","Making phenotypes for Chunk 426 of 469\n","Making phenotypes for Chunk 427 of 469\n","Making phenotypes for Chunk 428 of 469\n","Making phenotypes for Chunk 429 of 469\n","Making phenotypes for Chunk 430 of 469\n","Making phenotypes for Chunk 431 of 469\n","Making phenotypes for Chunk 432 of 469\n","Making phenotypes for Chunk 433 of 469\n","Making phenotypes for Chunk 434 of 469\n","Making phenotypes for Chunk 435 of 469\n","Making phenotypes for Chunk 436 of 469\n","Making phenotypes for Chunk 437 of 469\n","Making phenotypes for Chunk 438 of 469\n","Making phenotypes for Chunk 439 of 469\n","Making phenotypes for Chunk 440 of 469\n","Making phenotypes for Chunk 441 of 469\n","Making phenotypes for Chunk 442 of 469\n","Making phenotypes for Chunk 443 of 469\n","Making phenotypes for Chunk 444 of 469\n","Making phenotypes for Chunk 445 of 469\n","Making phenotypes for Chunk 446 of 469\n","Making phenotypes for Chunk 447 of 469\n","Making phenotypes for Chunk 448 of 469\n","Making phenotypes for Chunk 449 of 469\n","Making phenotypes for Chunk 450 of 469\n","Making phenotypes for Chunk 451 of 469\n","Making phenotypes for Chunk 452 of 469\n","Making phenotypes for Chunk 453 of 469\n","Making phenotypes for Chunk 454 of 469\n","Making phenotypes for Chunk 455 of 469\n","Making phenotypes for Chunk 456 of 469\n","Making phenotypes for Chunk 457 of 469\n","Making phenotypes for Chunk 458 of 469\n","Making phenotypes for Chunk 459 of 469\n","Making phenotypes for Chunk 460 of 469\n","Making phenotypes for Chunk 461 of 469\n","Making phenotypes for Chunk 462 of 469\n","Making phenotypes for Chunk 463 of 469\n","Making phenotypes for Chunk 464 of 469\n","Making phenotypes for Chunk 465 of 469\n","Making phenotypes for Chunk 466 of 469\n","Making phenotypes for Chunk 467 of 469\n","Making phenotypes for Chunk 468 of 469\n","Making phenotypes for Chunk 469 of 469\n","\n","Phenotypes saved in HumDef_params={her=0.1,num-causals=10000}.pheno, with breeding values in HumDef_params={her=0.1,num-causals=10000}.breed and effect sizes in HumDef_params={her=0.1,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.3,num-causals=1}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.3\n","--num-causals 1\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.3,num-causals=1}.pheno, with breeding values in HumDef_params={her=0.3,num-causals=1}.breed and effect sizes in HumDef_params={her=0.3,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.3,num-causals=10}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.3\n","--num-causals 10\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.3,num-causals=10}.pheno, with breeding values in HumDef_params={her=0.3,num-causals=10}.breed and effect sizes in HumDef_params={her=0.3,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.3,num-causals=100}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.3\n","--num-causals 100\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in HumDef_params={her=0.3,num-causals=100}.pheno, with breeding values in HumDef_params={her=0.3,num-causals=100}.breed and effect sizes in HumDef_params={her=0.3,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.3,num-causals=1000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.3\n","--num-causals 1000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in HumDef_params={her=0.3,num-causals=1000}.pheno, with breeding values in HumDef_params={her=0.3,num-causals=1000}.breed and effect sizes in HumDef_params={her=0.3,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.3,num-causals=10000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.3\n","--num-causals 10000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 469\n","Making phenotypes for Chunk 2 of 469\n","Making phenotypes for Chunk 3 of 469\n","Making phenotypes for Chunk 4 of 469\n","Making phenotypes for Chunk 5 of 469\n","Making phenotypes for Chunk 6 of 469\n","Making phenotypes for Chunk 7 of 469\n","Making phenotypes for Chunk 8 of 469\n","Making phenotypes for Chunk 9 of 469\n","Making phenotypes for Chunk 10 of 469\n","Making phenotypes for Chunk 11 of 469\n","Making phenotypes for Chunk 12 of 469\n","Making phenotypes for Chunk 13 of 469\n","Making phenotypes for Chunk 14 of 469\n","Making phenotypes for Chunk 15 of 469\n","Making phenotypes for Chunk 16 of 469\n","Making phenotypes for Chunk 17 of 469\n","Making phenotypes for Chunk 18 of 469\n","Making phenotypes for Chunk 19 of 469\n","Making phenotypes for Chunk 20 of 469\n","Making phenotypes for Chunk 21 of 469\n","Making phenotypes for Chunk 22 of 469\n","Making phenotypes for Chunk 23 of 469\n","Making phenotypes for Chunk 24 of 469\n","Making phenotypes for Chunk 25 of 469\n","Making phenotypes for Chunk 26 of 469\n","Making phenotypes for Chunk 27 of 469\n","Making phenotypes for Chunk 28 of 469\n","Making phenotypes for Chunk 29 of 469\n","Making phenotypes for Chunk 30 of 469\n","Making phenotypes for Chunk 31 of 469\n","Making phenotypes for Chunk 32 of 469\n","Making phenotypes for Chunk 33 of 469\n","Making phenotypes for Chunk 34 of 469\n","Making phenotypes for Chunk 35 of 469\n","Making phenotypes for Chunk 36 of 469\n","Making phenotypes for Chunk 37 of 469\n","Making phenotypes for Chunk 38 of 469\n","Making phenotypes for Chunk 39 of 469\n","Making phenotypes for Chunk 40 of 469\n","Making phenotypes for Chunk 41 of 469\n","Making phenotypes for Chunk 42 of 469\n","Making phenotypes for Chunk 43 of 469\n","Making phenotypes for Chunk 44 of 469\n","Making phenotypes for Chunk 45 of 469\n","Making phenotypes for Chunk 46 of 469\n","Making phenotypes for Chunk 47 of 469\n","Making phenotypes for Chunk 48 of 469\n","Making phenotypes for Chunk 49 of 469\n","Making phenotypes for Chunk 50 of 469\n","Making phenotypes for Chunk 51 of 469\n","Making phenotypes for Chunk 52 of 469\n","Making phenotypes for Chunk 53 of 469\n","Making phenotypes for Chunk 54 of 469\n","Making phenotypes for Chunk 55 of 469\n","Making phenotypes for Chunk 56 of 469\n","Making phenotypes for Chunk 57 of 469\n","Making phenotypes for Chunk 58 of 469\n","Making phenotypes for Chunk 59 of 469\n","Making phenotypes for Chunk 60 of 469\n","Making phenotypes for Chunk 61 of 469\n","Making phenotypes for Chunk 62 of 469\n","Making phenotypes for Chunk 63 of 469\n","Making phenotypes for Chunk 64 of 469\n","Making phenotypes for Chunk 65 of 469\n","Making phenotypes for Chunk 66 of 469\n","Making phenotypes for Chunk 67 of 469\n","Making phenotypes for Chunk 68 of 469\n","Making phenotypes for Chunk 69 of 469\n","Making phenotypes for Chunk 70 of 469\n","Making phenotypes for Chunk 71 of 469\n","Making phenotypes for Chunk 72 of 469\n","Making phenotypes for Chunk 73 of 469\n","Making phenotypes for Chunk 74 of 469\n","Making phenotypes for Chunk 75 of 469\n","Making phenotypes for Chunk 76 of 469\n","Making phenotypes for Chunk 77 of 469\n","Making phenotypes for Chunk 78 of 469\n","Making phenotypes for Chunk 79 of 469\n","Making phenotypes for Chunk 80 of 469\n","Making phenotypes for Chunk 81 of 469\n","Making phenotypes for Chunk 82 of 469\n","Making phenotypes for Chunk 83 of 469\n","Making phenotypes for Chunk 84 of 469\n","Making phenotypes for Chunk 85 of 469\n","Making phenotypes for Chunk 86 of 469\n","Making phenotypes for Chunk 87 of 469\n","Making phenotypes for Chunk 88 of 469\n","Making phenotypes for Chunk 89 of 469\n","Making phenotypes for Chunk 90 of 469\n","Making phenotypes for Chunk 91 of 469\n","Making phenotypes for Chunk 92 of 469\n","Making phenotypes for Chunk 93 of 469\n","Making phenotypes for Chunk 94 of 469\n","Making phenotypes for Chunk 95 of 469\n","Making phenotypes for Chunk 96 of 469\n","Making phenotypes for Chunk 97 of 469\n","Making phenotypes for Chunk 98 of 469\n","Making phenotypes for Chunk 99 of 469\n","Making phenotypes for Chunk 100 of 469\n","Making phenotypes for Chunk 101 of 469\n","Making phenotypes for Chunk 102 of 469\n","Making phenotypes for Chunk 103 of 469\n","Making phenotypes for Chunk 104 of 469\n","Making phenotypes for Chunk 105 of 469\n","Making phenotypes for Chunk 106 of 469\n","Making phenotypes for Chunk 107 of 469\n","Making phenotypes for Chunk 108 of 469\n","Making phenotypes for Chunk 109 of 469\n","Making phenotypes for Chunk 110 of 469\n","Making phenotypes for Chunk 111 of 469\n","Making phenotypes for Chunk 112 of 469\n","Making phenotypes for Chunk 113 of 469\n","Making phenotypes for Chunk 114 of 469\n","Making phenotypes for Chunk 115 of 469\n","Making phenotypes for Chunk 116 of 469\n","Making phenotypes for Chunk 117 of 469\n","Making phenotypes for Chunk 118 of 469\n","Making phenotypes for Chunk 119 of 469\n","Making phenotypes for Chunk 120 of 469\n","Making phenotypes for Chunk 121 of 469\n","Making phenotypes for Chunk 122 of 469\n","Making phenotypes for Chunk 123 of 469\n","Making phenotypes for Chunk 124 of 469\n","Making phenotypes for Chunk 125 of 469\n","Making phenotypes for Chunk 126 of 469\n","Making phenotypes for Chunk 127 of 469\n","Making phenotypes for Chunk 128 of 469\n","Making phenotypes for Chunk 129 of 469\n","Making phenotypes for Chunk 130 of 469\n","Making phenotypes for Chunk 131 of 469\n","Making phenotypes for Chunk 132 of 469\n","Making phenotypes for Chunk 133 of 469\n","Making phenotypes for Chunk 134 of 469\n","Making phenotypes for Chunk 135 of 469\n","Making phenotypes for Chunk 136 of 469\n","Making phenotypes for Chunk 137 of 469\n","Making phenotypes for Chunk 138 of 469\n","Making phenotypes for Chunk 139 of 469\n","Making phenotypes for Chunk 140 of 469\n","Making phenotypes for Chunk 141 of 469\n","Making phenotypes for Chunk 142 of 469\n","Making phenotypes for Chunk 143 of 469\n","Making phenotypes for Chunk 144 of 469\n","Making phenotypes for Chunk 145 of 469\n","Making phenotypes for Chunk 146 of 469\n","Making phenotypes for Chunk 147 of 469\n","Making phenotypes for Chunk 148 of 469\n","Making phenotypes for Chunk 149 of 469\n","Making phenotypes for Chunk 150 of 469\n","Making phenotypes for Chunk 151 of 469\n","Making phenotypes for Chunk 152 of 469\n","Making phenotypes for Chunk 153 of 469\n","Making phenotypes for Chunk 154 of 469\n","Making phenotypes for Chunk 155 of 469\n","Making phenotypes for Chunk 156 of 469\n","Making phenotypes for Chunk 157 of 469\n","Making phenotypes for Chunk 158 of 469\n","Making phenotypes for Chunk 159 of 469\n","Making phenotypes for Chunk 160 of 469\n","Making phenotypes for Chunk 161 of 469\n","Making phenotypes for Chunk 162 of 469\n","Making phenotypes for Chunk 163 of 469\n","Making phenotypes for Chunk 164 of 469\n","Making phenotypes for Chunk 165 of 469\n","Making phenotypes for Chunk 166 of 469\n","Making phenotypes for Chunk 167 of 469\n","Making phenotypes for Chunk 168 of 469\n","Making phenotypes for Chunk 169 of 469\n","Making phenotypes for Chunk 170 of 469\n","Making phenotypes for Chunk 171 of 469\n","Making phenotypes for Chunk 172 of 469\n","Making phenotypes for Chunk 173 of 469\n","Making phenotypes for Chunk 174 of 469\n","Making phenotypes for Chunk 175 of 469\n","Making phenotypes for Chunk 176 of 469\n","Making phenotypes for Chunk 177 of 469\n","Making phenotypes for Chunk 178 of 469\n","Making phenotypes for Chunk 179 of 469\n","Making phenotypes for Chunk 180 of 469\n","Making phenotypes for Chunk 181 of 469\n","Making phenotypes for Chunk 182 of 469\n","Making phenotypes for Chunk 183 of 469\n","Making phenotypes for Chunk 184 of 469\n","Making phenotypes for Chunk 185 of 469\n","Making phenotypes for Chunk 186 of 469\n","Making phenotypes for Chunk 187 of 469\n","Making phenotypes for Chunk 188 of 469\n","Making phenotypes for Chunk 189 of 469\n","Making phenotypes for Chunk 190 of 469\n","Making phenotypes for Chunk 191 of 469\n","Making phenotypes for Chunk 192 of 469\n","Making phenotypes for Chunk 193 of 469\n","Making phenotypes for Chunk 194 of 469\n","Making phenotypes for Chunk 195 of 469\n","Making phenotypes for Chunk 196 of 469\n","Making phenotypes for Chunk 197 of 469\n","Making phenotypes for Chunk 198 of 469\n","Making phenotypes for Chunk 199 of 469\n","Making phenotypes for Chunk 200 of 469\n","Making phenotypes for Chunk 201 of 469\n","Making phenotypes for Chunk 202 of 469\n","Making phenotypes for Chunk 203 of 469\n","Making phenotypes for Chunk 204 of 469\n","Making phenotypes for Chunk 205 of 469\n","Making phenotypes for Chunk 206 of 469\n","Making phenotypes for Chunk 207 of 469\n","Making phenotypes for Chunk 208 of 469\n","Making phenotypes for Chunk 209 of 469\n","Making phenotypes for Chunk 210 of 469\n","Making phenotypes for Chunk 211 of 469\n","Making phenotypes for Chunk 212 of 469\n","Making phenotypes for Chunk 213 of 469\n","Making phenotypes for Chunk 214 of 469\n","Making phenotypes for Chunk 215 of 469\n","Making phenotypes for Chunk 216 of 469\n","Making phenotypes for Chunk 217 of 469\n","Making phenotypes for Chunk 218 of 469\n","Making phenotypes for Chunk 219 of 469\n","Making phenotypes for Chunk 220 of 469\n","Making phenotypes for Chunk 221 of 469\n","Making phenotypes for Chunk 222 of 469\n","Making phenotypes for Chunk 223 of 469\n","Making phenotypes for Chunk 224 of 469\n","Making phenotypes for Chunk 225 of 469\n","Making phenotypes for Chunk 226 of 469\n","Making phenotypes for Chunk 227 of 469\n","Making phenotypes for Chunk 228 of 469\n","Making phenotypes for Chunk 229 of 469\n","Making phenotypes for Chunk 230 of 469\n","Making phenotypes for Chunk 231 of 469\n","Making phenotypes for Chunk 232 of 469\n","Making phenotypes for Chunk 233 of 469\n","Making phenotypes for Chunk 234 of 469\n","Making phenotypes for Chunk 235 of 469\n","Making phenotypes for Chunk 236 of 469\n","Making phenotypes for Chunk 237 of 469\n","Making phenotypes for Chunk 238 of 469\n","Making phenotypes for Chunk 239 of 469\n","Making phenotypes for Chunk 240 of 469\n","Making phenotypes for Chunk 241 of 469\n","Making phenotypes for Chunk 242 of 469\n","Making phenotypes for Chunk 243 of 469\n","Making phenotypes for Chunk 244 of 469\n","Making phenotypes for Chunk 245 of 469\n","Making phenotypes for Chunk 246 of 469\n","Making phenotypes for Chunk 247 of 469\n","Making phenotypes for Chunk 248 of 469\n","Making phenotypes for Chunk 249 of 469\n","Making phenotypes for Chunk 250 of 469\n","Making phenotypes for Chunk 251 of 469\n","Making phenotypes for Chunk 252 of 469\n","Making phenotypes for Chunk 253 of 469\n","Making phenotypes for Chunk 254 of 469\n","Making phenotypes for Chunk 255 of 469\n","Making phenotypes for Chunk 256 of 469\n","Making phenotypes for Chunk 257 of 469\n","Making phenotypes for Chunk 258 of 469\n","Making phenotypes for Chunk 259 of 469\n","Making phenotypes for Chunk 260 of 469\n","Making phenotypes for Chunk 261 of 469\n","Making phenotypes for Chunk 262 of 469\n","Making phenotypes for Chunk 263 of 469\n","Making phenotypes for Chunk 264 of 469\n","Making phenotypes for Chunk 265 of 469\n","Making phenotypes for Chunk 266 of 469\n","Making phenotypes for Chunk 267 of 469\n","Making phenotypes for Chunk 268 of 469\n","Making phenotypes for Chunk 269 of 469\n","Making phenotypes for Chunk 270 of 469\n","Making phenotypes for Chunk 271 of 469\n","Making phenotypes for Chunk 272 of 469\n","Making phenotypes for Chunk 273 of 469\n","Making phenotypes for Chunk 274 of 469\n","Making phenotypes for Chunk 275 of 469\n","Making phenotypes for Chunk 276 of 469\n","Making phenotypes for Chunk 277 of 469\n","Making phenotypes for Chunk 278 of 469\n","Making phenotypes for Chunk 279 of 469\n","Making phenotypes for Chunk 280 of 469\n","Making phenotypes for Chunk 281 of 469\n","Making phenotypes for Chunk 282 of 469\n","Making phenotypes for Chunk 283 of 469\n","Making phenotypes for Chunk 284 of 469\n","Making phenotypes for Chunk 285 of 469\n","Making phenotypes for Chunk 286 of 469\n","Making phenotypes for Chunk 287 of 469\n","Making phenotypes for Chunk 288 of 469\n","Making phenotypes for Chunk 289 of 469\n","Making phenotypes for Chunk 290 of 469\n","Making phenotypes for Chunk 291 of 469\n","Making phenotypes for Chunk 292 of 469\n","Making phenotypes for Chunk 293 of 469\n","Making phenotypes for Chunk 294 of 469\n","Making phenotypes for Chunk 295 of 469\n","Making phenotypes for Chunk 296 of 469\n","Making phenotypes for Chunk 297 of 469\n","Making phenotypes for Chunk 298 of 469\n","Making phenotypes for Chunk 299 of 469\n","Making phenotypes for Chunk 300 of 469\n","Making phenotypes for Chunk 301 of 469\n","Making phenotypes for Chunk 302 of 469\n","Making phenotypes for Chunk 303 of 469\n","Making phenotypes for Chunk 304 of 469\n","Making phenotypes for Chunk 305 of 469\n","Making phenotypes for Chunk 306 of 469\n","Making phenotypes for Chunk 307 of 469\n","Making phenotypes for Chunk 308 of 469\n","Making phenotypes for Chunk 309 of 469\n","Making phenotypes for Chunk 310 of 469\n","Making phenotypes for Chunk 311 of 469\n","Making phenotypes for Chunk 312 of 469\n","Making phenotypes for Chunk 313 of 469\n","Making phenotypes for Chunk 314 of 469\n","Making phenotypes for Chunk 315 of 469\n","Making phenotypes for Chunk 316 of 469\n","Making phenotypes for Chunk 317 of 469\n","Making phenotypes for Chunk 318 of 469\n","Making phenotypes for Chunk 319 of 469\n","Making phenotypes for Chunk 320 of 469\n","Making phenotypes for Chunk 321 of 469\n","Making phenotypes for Chunk 322 of 469\n","Making phenotypes for Chunk 323 of 469\n","Making phenotypes for Chunk 324 of 469\n","Making phenotypes for Chunk 325 of 469\n","Making phenotypes for Chunk 326 of 469\n","Making phenotypes for Chunk 327 of 469\n","Making phenotypes for Chunk 328 of 469\n","Making phenotypes for Chunk 329 of 469\n","Making phenotypes for Chunk 330 of 469\n","Making phenotypes for Chunk 331 of 469\n","Making phenotypes for Chunk 332 of 469\n","Making phenotypes for Chunk 333 of 469\n","Making phenotypes for Chunk 334 of 469\n","Making phenotypes for Chunk 335 of 469\n","Making phenotypes for Chunk 336 of 469\n","Making phenotypes for Chunk 337 of 469\n","Making phenotypes for Chunk 338 of 469\n","Making phenotypes for Chunk 339 of 469\n","Making phenotypes for Chunk 340 of 469\n","Making phenotypes for Chunk 341 of 469\n","Making phenotypes for Chunk 342 of 469\n","Making phenotypes for Chunk 343 of 469\n","Making phenotypes for Chunk 344 of 469\n","Making phenotypes for Chunk 345 of 469\n","Making phenotypes for Chunk 346 of 469\n","Making phenotypes for Chunk 347 of 469\n","Making phenotypes for Chunk 348 of 469\n","Making phenotypes for Chunk 349 of 469\n","Making phenotypes for Chunk 350 of 469\n","Making phenotypes for Chunk 351 of 469\n","Making phenotypes for Chunk 352 of 469\n","Making phenotypes for Chunk 353 of 469\n","Making phenotypes for Chunk 354 of 469\n","Making phenotypes for Chunk 355 of 469\n","Making phenotypes for Chunk 356 of 469\n","Making phenotypes for Chunk 357 of 469\n","Making phenotypes for Chunk 358 of 469\n","Making phenotypes for Chunk 359 of 469\n","Making phenotypes for Chunk 360 of 469\n","Making phenotypes for Chunk 361 of 469\n","Making phenotypes for Chunk 362 of 469\n","Making phenotypes for Chunk 363 of 469\n","Making phenotypes for Chunk 364 of 469\n","Making phenotypes for Chunk 365 of 469\n","Making phenotypes for Chunk 366 of 469\n","Making phenotypes for Chunk 367 of 469\n","Making phenotypes for Chunk 368 of 469\n","Making phenotypes for Chunk 369 of 469\n","Making phenotypes for Chunk 370 of 469\n","Making phenotypes for Chunk 371 of 469\n","Making phenotypes for Chunk 372 of 469\n","Making phenotypes for Chunk 373 of 469\n","Making phenotypes for Chunk 374 of 469\n","Making phenotypes for Chunk 375 of 469\n","Making phenotypes for Chunk 376 of 469\n","Making phenotypes for Chunk 377 of 469\n","Making phenotypes for Chunk 378 of 469\n","Making phenotypes for Chunk 379 of 469\n","Making phenotypes for Chunk 380 of 469\n","Making phenotypes for Chunk 381 of 469\n","Making phenotypes for Chunk 382 of 469\n","Making phenotypes for Chunk 383 of 469\n","Making phenotypes for Chunk 384 of 469\n","Making phenotypes for Chunk 385 of 469\n","Making phenotypes for Chunk 386 of 469\n","Making phenotypes for Chunk 387 of 469\n","Making phenotypes for Chunk 388 of 469\n","Making phenotypes for Chunk 389 of 469\n","Making phenotypes for Chunk 390 of 469\n","Making phenotypes for Chunk 391 of 469\n","Making phenotypes for Chunk 392 of 469\n","Making phenotypes for Chunk 393 of 469\n","Making phenotypes for Chunk 394 of 469\n","Making phenotypes for Chunk 395 of 469\n","Making phenotypes for Chunk 396 of 469\n","Making phenotypes for Chunk 397 of 469\n","Making phenotypes for Chunk 398 of 469\n","Making phenotypes for Chunk 399 of 469\n","Making phenotypes for Chunk 400 of 469\n","Making phenotypes for Chunk 401 of 469\n","Making phenotypes for Chunk 402 of 469\n","Making phenotypes for Chunk 403 of 469\n","Making phenotypes for Chunk 404 of 469\n","Making phenotypes for Chunk 405 of 469\n","Making phenotypes for Chunk 406 of 469\n","Making phenotypes for Chunk 407 of 469\n","Making phenotypes for Chunk 408 of 469\n","Making phenotypes for Chunk 409 of 469\n","Making phenotypes for Chunk 410 of 469\n","Making phenotypes for Chunk 411 of 469\n","Making phenotypes for Chunk 412 of 469\n","Making phenotypes for Chunk 413 of 469\n","Making phenotypes for Chunk 414 of 469\n","Making phenotypes for Chunk 415 of 469\n","Making phenotypes for Chunk 416 of 469\n","Making phenotypes for Chunk 417 of 469\n","Making phenotypes for Chunk 418 of 469\n","Making phenotypes for Chunk 419 of 469\n","Making phenotypes for Chunk 420 of 469\n","Making phenotypes for Chunk 421 of 469\n","Making phenotypes for Chunk 422 of 469\n","Making phenotypes for Chunk 423 of 469\n","Making phenotypes for Chunk 424 of 469\n","Making phenotypes for Chunk 425 of 469\n","Making phenotypes for Chunk 426 of 469\n","Making phenotypes for Chunk 427 of 469\n","Making phenotypes for Chunk 428 of 469\n","Making phenotypes for Chunk 429 of 469\n","Making phenotypes for Chunk 430 of 469\n","Making phenotypes for Chunk 431 of 469\n","Making phenotypes for Chunk 432 of 469\n","Making phenotypes for Chunk 433 of 469\n","Making phenotypes for Chunk 434 of 469\n","Making phenotypes for Chunk 435 of 469\n","Making phenotypes for Chunk 436 of 469\n","Making phenotypes for Chunk 437 of 469\n","Making phenotypes for Chunk 438 of 469\n","Making phenotypes for Chunk 439 of 469\n","Making phenotypes for Chunk 440 of 469\n","Making phenotypes for Chunk 441 of 469\n","Making phenotypes for Chunk 442 of 469\n","Making phenotypes for Chunk 443 of 469\n","Making phenotypes for Chunk 444 of 469\n","Making phenotypes for Chunk 445 of 469\n","Making phenotypes for Chunk 446 of 469\n","Making phenotypes for Chunk 447 of 469\n","Making phenotypes for Chunk 448 of 469\n","Making phenotypes for Chunk 449 of 469\n","Making phenotypes for Chunk 450 of 469\n","Making phenotypes for Chunk 451 of 469\n","Making phenotypes for Chunk 452 of 469\n","Making phenotypes for Chunk 453 of 469\n","Making phenotypes for Chunk 454 of 469\n","Making phenotypes for Chunk 455 of 469\n","Making phenotypes for Chunk 456 of 469\n","Making phenotypes for Chunk 457 of 469\n","Making phenotypes for Chunk 458 of 469\n","Making phenotypes for Chunk 459 of 469\n","Making phenotypes for Chunk 460 of 469\n","Making phenotypes for Chunk 461 of 469\n","Making phenotypes for Chunk 462 of 469\n","Making phenotypes for Chunk 463 of 469\n","Making phenotypes for Chunk 464 of 469\n","Making phenotypes for Chunk 465 of 469\n","Making phenotypes for Chunk 466 of 469\n","Making phenotypes for Chunk 467 of 469\n","Making phenotypes for Chunk 468 of 469\n","Making phenotypes for Chunk 469 of 469\n","\n","Phenotypes saved in HumDef_params={her=0.3,num-causals=10000}.pheno, with breeding values in HumDef_params={her=0.3,num-causals=10000}.breed and effect sizes in HumDef_params={her=0.3,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.5,num-causals=1}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.5\n","--num-causals 1\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.5,num-causals=1}.pheno, with breeding values in HumDef_params={her=0.5,num-causals=1}.breed and effect sizes in HumDef_params={her=0.5,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.5,num-causals=10}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.5\n","--num-causals 10\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.5,num-causals=10}.pheno, with breeding values in HumDef_params={her=0.5,num-causals=10}.breed and effect sizes in HumDef_params={her=0.5,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.5,num-causals=100}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.5\n","--num-causals 100\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in HumDef_params={her=0.5,num-causals=100}.pheno, with breeding values in HumDef_params={her=0.5,num-causals=100}.breed and effect sizes in HumDef_params={her=0.5,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.5,num-causals=1000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.5\n","--num-causals 1000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in HumDef_params={her=0.5,num-causals=1000}.pheno, with breeding values in HumDef_params={her=0.5,num-causals=1000}.breed and effect sizes in HumDef_params={her=0.5,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.5,num-causals=10000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.5\n","--num-causals 10000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 469\n","Making phenotypes for Chunk 2 of 469\n","Making phenotypes for Chunk 3 of 469\n","Making phenotypes for Chunk 4 of 469\n","Making phenotypes for Chunk 5 of 469\n","Making phenotypes for Chunk 6 of 469\n","Making phenotypes for Chunk 7 of 469\n","Making phenotypes for Chunk 8 of 469\n","Making phenotypes for Chunk 9 of 469\n","Making phenotypes for Chunk 10 of 469\n","Making phenotypes for Chunk 11 of 469\n","Making phenotypes for Chunk 12 of 469\n","Making phenotypes for Chunk 13 of 469\n","Making phenotypes for Chunk 14 of 469\n","Making phenotypes for Chunk 15 of 469\n","Making phenotypes for Chunk 16 of 469\n","Making phenotypes for Chunk 17 of 469\n","Making phenotypes for Chunk 18 of 469\n","Making phenotypes for Chunk 19 of 469\n","Making phenotypes for Chunk 20 of 469\n","Making phenotypes for Chunk 21 of 469\n","Making phenotypes for Chunk 22 of 469\n","Making phenotypes for Chunk 23 of 469\n","Making phenotypes for Chunk 24 of 469\n","Making phenotypes for Chunk 25 of 469\n","Making phenotypes for Chunk 26 of 469\n","Making phenotypes for Chunk 27 of 469\n","Making phenotypes for Chunk 28 of 469\n","Making phenotypes for Chunk 29 of 469\n","Making phenotypes for Chunk 30 of 469\n","Making phenotypes for Chunk 31 of 469\n","Making phenotypes for Chunk 32 of 469\n","Making phenotypes for Chunk 33 of 469\n","Making phenotypes for Chunk 34 of 469\n","Making phenotypes for Chunk 35 of 469\n","Making phenotypes for Chunk 36 of 469\n","Making phenotypes for Chunk 37 of 469\n","Making phenotypes for Chunk 38 of 469\n","Making phenotypes for Chunk 39 of 469\n","Making phenotypes for Chunk 40 of 469\n","Making phenotypes for Chunk 41 of 469\n","Making phenotypes for Chunk 42 of 469\n","Making phenotypes for Chunk 43 of 469\n","Making phenotypes for Chunk 44 of 469\n","Making phenotypes for Chunk 45 of 469\n","Making phenotypes for Chunk 46 of 469\n","Making phenotypes for Chunk 47 of 469\n","Making phenotypes for Chunk 48 of 469\n","Making phenotypes for Chunk 49 of 469\n","Making phenotypes for Chunk 50 of 469\n","Making phenotypes for Chunk 51 of 469\n","Making phenotypes for Chunk 52 of 469\n","Making phenotypes for Chunk 53 of 469\n","Making phenotypes for Chunk 54 of 469\n","Making phenotypes for Chunk 55 of 469\n","Making phenotypes for Chunk 56 of 469\n","Making phenotypes for Chunk 57 of 469\n","Making phenotypes for Chunk 58 of 469\n","Making phenotypes for Chunk 59 of 469\n","Making phenotypes for Chunk 60 of 469\n","Making phenotypes for Chunk 61 of 469\n","Making phenotypes for Chunk 62 of 469\n","Making phenotypes for Chunk 63 of 469\n","Making phenotypes for Chunk 64 of 469\n","Making phenotypes for Chunk 65 of 469\n","Making phenotypes for Chunk 66 of 469\n","Making phenotypes for Chunk 67 of 469\n","Making phenotypes for Chunk 68 of 469\n","Making phenotypes for Chunk 69 of 469\n","Making phenotypes for Chunk 70 of 469\n","Making phenotypes for Chunk 71 of 469\n","Making phenotypes for Chunk 72 of 469\n","Making phenotypes for Chunk 73 of 469\n","Making phenotypes for Chunk 74 of 469\n","Making phenotypes for Chunk 75 of 469\n","Making phenotypes for Chunk 76 of 469\n","Making phenotypes for Chunk 77 of 469\n","Making phenotypes for Chunk 78 of 469\n","Making phenotypes for Chunk 79 of 469\n","Making phenotypes for Chunk 80 of 469\n","Making phenotypes for Chunk 81 of 469\n","Making phenotypes for Chunk 82 of 469\n","Making phenotypes for Chunk 83 of 469\n","Making phenotypes for Chunk 84 of 469\n","Making phenotypes for Chunk 85 of 469\n","Making phenotypes for Chunk 86 of 469\n","Making phenotypes for Chunk 87 of 469\n","Making phenotypes for Chunk 88 of 469\n","Making phenotypes for Chunk 89 of 469\n","Making phenotypes for Chunk 90 of 469\n","Making phenotypes for Chunk 91 of 469\n","Making phenotypes for Chunk 92 of 469\n","Making phenotypes for Chunk 93 of 469\n","Making phenotypes for Chunk 94 of 469\n","Making phenotypes for Chunk 95 of 469\n","Making phenotypes for Chunk 96 of 469\n","Making phenotypes for Chunk 97 of 469\n","Making phenotypes for Chunk 98 of 469\n","Making phenotypes for Chunk 99 of 469\n","Making phenotypes for Chunk 100 of 469\n","Making phenotypes for Chunk 101 of 469\n","Making phenotypes for Chunk 102 of 469\n","Making phenotypes for Chunk 103 of 469\n","Making phenotypes for Chunk 104 of 469\n","Making phenotypes for Chunk 105 of 469\n","Making phenotypes for Chunk 106 of 469\n","Making phenotypes for Chunk 107 of 469\n","Making phenotypes for Chunk 108 of 469\n","Making phenotypes for Chunk 109 of 469\n","Making phenotypes for Chunk 110 of 469\n","Making phenotypes for Chunk 111 of 469\n","Making phenotypes for Chunk 112 of 469\n","Making phenotypes for Chunk 113 of 469\n","Making phenotypes for Chunk 114 of 469\n","Making phenotypes for Chunk 115 of 469\n","Making phenotypes for Chunk 116 of 469\n","Making phenotypes for Chunk 117 of 469\n","Making phenotypes for Chunk 118 of 469\n","Making phenotypes for Chunk 119 of 469\n","Making phenotypes for Chunk 120 of 469\n","Making phenotypes for Chunk 121 of 469\n","Making phenotypes for Chunk 122 of 469\n","Making phenotypes for Chunk 123 of 469\n","Making phenotypes for Chunk 124 of 469\n","Making phenotypes for Chunk 125 of 469\n","Making phenotypes for Chunk 126 of 469\n","Making phenotypes for Chunk 127 of 469\n","Making phenotypes for Chunk 128 of 469\n","Making phenotypes for Chunk 129 of 469\n","Making phenotypes for Chunk 130 of 469\n","Making phenotypes for Chunk 131 of 469\n","Making phenotypes for Chunk 132 of 469\n","Making phenotypes for Chunk 133 of 469\n","Making phenotypes for Chunk 134 of 469\n","Making phenotypes for Chunk 135 of 469\n","Making phenotypes for Chunk 136 of 469\n","Making phenotypes for Chunk 137 of 469\n","Making phenotypes for Chunk 138 of 469\n","Making phenotypes for Chunk 139 of 469\n","Making phenotypes for Chunk 140 of 469\n","Making phenotypes for Chunk 141 of 469\n","Making phenotypes for Chunk 142 of 469\n","Making phenotypes for Chunk 143 of 469\n","Making phenotypes for Chunk 144 of 469\n","Making phenotypes for Chunk 145 of 469\n","Making phenotypes for Chunk 146 of 469\n","Making phenotypes for Chunk 147 of 469\n","Making phenotypes for Chunk 148 of 469\n","Making phenotypes for Chunk 149 of 469\n","Making phenotypes for Chunk 150 of 469\n","Making phenotypes for Chunk 151 of 469\n","Making phenotypes for Chunk 152 of 469\n","Making phenotypes for Chunk 153 of 469\n","Making phenotypes for Chunk 154 of 469\n","Making phenotypes for Chunk 155 of 469\n","Making phenotypes for Chunk 156 of 469\n","Making phenotypes for Chunk 157 of 469\n","Making phenotypes for Chunk 158 of 469\n","Making phenotypes for Chunk 159 of 469\n","Making phenotypes for Chunk 160 of 469\n","Making phenotypes for Chunk 161 of 469\n","Making phenotypes for Chunk 162 of 469\n","Making phenotypes for Chunk 163 of 469\n","Making phenotypes for Chunk 164 of 469\n","Making phenotypes for Chunk 165 of 469\n","Making phenotypes for Chunk 166 of 469\n","Making phenotypes for Chunk 167 of 469\n","Making phenotypes for Chunk 168 of 469\n","Making phenotypes for Chunk 169 of 469\n","Making phenotypes for Chunk 170 of 469\n","Making phenotypes for Chunk 171 of 469\n","Making phenotypes for Chunk 172 of 469\n","Making phenotypes for Chunk 173 of 469\n","Making phenotypes for Chunk 174 of 469\n","Making phenotypes for Chunk 175 of 469\n","Making phenotypes for Chunk 176 of 469\n","Making phenotypes for Chunk 177 of 469\n","Making phenotypes for Chunk 178 of 469\n","Making phenotypes for Chunk 179 of 469\n","Making phenotypes for Chunk 180 of 469\n","Making phenotypes for Chunk 181 of 469\n","Making phenotypes for Chunk 182 of 469\n","Making phenotypes for Chunk 183 of 469\n","Making phenotypes for Chunk 184 of 469\n","Making phenotypes for Chunk 185 of 469\n","Making phenotypes for Chunk 186 of 469\n","Making phenotypes for Chunk 187 of 469\n","Making phenotypes for Chunk 188 of 469\n","Making phenotypes for Chunk 189 of 469\n","Making phenotypes for Chunk 190 of 469\n","Making phenotypes for Chunk 191 of 469\n","Making phenotypes for Chunk 192 of 469\n","Making phenotypes for Chunk 193 of 469\n","Making phenotypes for Chunk 194 of 469\n","Making phenotypes for Chunk 195 of 469\n","Making phenotypes for Chunk 196 of 469\n","Making phenotypes for Chunk 197 of 469\n","Making phenotypes for Chunk 198 of 469\n","Making phenotypes for Chunk 199 of 469\n","Making phenotypes for Chunk 200 of 469\n","Making phenotypes for Chunk 201 of 469\n","Making phenotypes for Chunk 202 of 469\n","Making phenotypes for Chunk 203 of 469\n","Making phenotypes for Chunk 204 of 469\n","Making phenotypes for Chunk 205 of 469\n","Making phenotypes for Chunk 206 of 469\n","Making phenotypes for Chunk 207 of 469\n","Making phenotypes for Chunk 208 of 469\n","Making phenotypes for Chunk 209 of 469\n","Making phenotypes for Chunk 210 of 469\n","Making phenotypes for Chunk 211 of 469\n","Making phenotypes for Chunk 212 of 469\n","Making phenotypes for Chunk 213 of 469\n","Making phenotypes for Chunk 214 of 469\n","Making phenotypes for Chunk 215 of 469\n","Making phenotypes for Chunk 216 of 469\n","Making phenotypes for Chunk 217 of 469\n","Making phenotypes for Chunk 218 of 469\n","Making phenotypes for Chunk 219 of 469\n","Making phenotypes for Chunk 220 of 469\n","Making phenotypes for Chunk 221 of 469\n","Making phenotypes for Chunk 222 of 469\n","Making phenotypes for Chunk 223 of 469\n","Making phenotypes for Chunk 224 of 469\n","Making phenotypes for Chunk 225 of 469\n","Making phenotypes for Chunk 226 of 469\n","Making phenotypes for Chunk 227 of 469\n","Making phenotypes for Chunk 228 of 469\n","Making phenotypes for Chunk 229 of 469\n","Making phenotypes for Chunk 230 of 469\n","Making phenotypes for Chunk 231 of 469\n","Making phenotypes for Chunk 232 of 469\n","Making phenotypes for Chunk 233 of 469\n","Making phenotypes for Chunk 234 of 469\n","Making phenotypes for Chunk 235 of 469\n","Making phenotypes for Chunk 236 of 469\n","Making phenotypes for Chunk 237 of 469\n","Making phenotypes for Chunk 238 of 469\n","Making phenotypes for Chunk 239 of 469\n","Making phenotypes for Chunk 240 of 469\n","Making phenotypes for Chunk 241 of 469\n","Making phenotypes for Chunk 242 of 469\n","Making phenotypes for Chunk 243 of 469\n","Making phenotypes for Chunk 244 of 469\n","Making phenotypes for Chunk 245 of 469\n","Making phenotypes for Chunk 246 of 469\n","Making phenotypes for Chunk 247 of 469\n","Making phenotypes for Chunk 248 of 469\n","Making phenotypes for Chunk 249 of 469\n","Making phenotypes for Chunk 250 of 469\n","Making phenotypes for Chunk 251 of 469\n","Making phenotypes for Chunk 252 of 469\n","Making phenotypes for Chunk 253 of 469\n","Making phenotypes for Chunk 254 of 469\n","Making phenotypes for Chunk 255 of 469\n","Making phenotypes for Chunk 256 of 469\n","Making phenotypes for Chunk 257 of 469\n","Making phenotypes for Chunk 258 of 469\n","Making phenotypes for Chunk 259 of 469\n","Making phenotypes for Chunk 260 of 469\n","Making phenotypes for Chunk 261 of 469\n","Making phenotypes for Chunk 262 of 469\n","Making phenotypes for Chunk 263 of 469\n","Making phenotypes for Chunk 264 of 469\n","Making phenotypes for Chunk 265 of 469\n","Making phenotypes for Chunk 266 of 469\n","Making phenotypes for Chunk 267 of 469\n","Making phenotypes for Chunk 268 of 469\n","Making phenotypes for Chunk 269 of 469\n","Making phenotypes for Chunk 270 of 469\n","Making phenotypes for Chunk 271 of 469\n","Making phenotypes for Chunk 272 of 469\n","Making phenotypes for Chunk 273 of 469\n","Making phenotypes for Chunk 274 of 469\n","Making phenotypes for Chunk 275 of 469\n","Making phenotypes for Chunk 276 of 469\n","Making phenotypes for Chunk 277 of 469\n","Making phenotypes for Chunk 278 of 469\n","Making phenotypes for Chunk 279 of 469\n","Making phenotypes for Chunk 280 of 469\n","Making phenotypes for Chunk 281 of 469\n","Making phenotypes for Chunk 282 of 469\n","Making phenotypes for Chunk 283 of 469\n","Making phenotypes for Chunk 284 of 469\n","Making phenotypes for Chunk 285 of 469\n","Making phenotypes for Chunk 286 of 469\n","Making phenotypes for Chunk 287 of 469\n","Making phenotypes for Chunk 288 of 469\n","Making phenotypes for Chunk 289 of 469\n","Making phenotypes for Chunk 290 of 469\n","Making phenotypes for Chunk 291 of 469\n","Making phenotypes for Chunk 292 of 469\n","Making phenotypes for Chunk 293 of 469\n","Making phenotypes for Chunk 294 of 469\n","Making phenotypes for Chunk 295 of 469\n","Making phenotypes for Chunk 296 of 469\n","Making phenotypes for Chunk 297 of 469\n","Making phenotypes for Chunk 298 of 469\n","Making phenotypes for Chunk 299 of 469\n","Making phenotypes for Chunk 300 of 469\n","Making phenotypes for Chunk 301 of 469\n","Making phenotypes for Chunk 302 of 469\n","Making phenotypes for Chunk 303 of 469\n","Making phenotypes for Chunk 304 of 469\n","Making phenotypes for Chunk 305 of 469\n","Making phenotypes for Chunk 306 of 469\n","Making phenotypes for Chunk 307 of 469\n","Making phenotypes for Chunk 308 of 469\n","Making phenotypes for Chunk 309 of 469\n","Making phenotypes for Chunk 310 of 469\n","Making phenotypes for Chunk 311 of 469\n","Making phenotypes for Chunk 312 of 469\n","Making phenotypes for Chunk 313 of 469\n","Making phenotypes for Chunk 314 of 469\n","Making phenotypes for Chunk 315 of 469\n","Making phenotypes for Chunk 316 of 469\n","Making phenotypes for Chunk 317 of 469\n","Making phenotypes for Chunk 318 of 469\n","Making phenotypes for Chunk 319 of 469\n","Making phenotypes for Chunk 320 of 469\n","Making phenotypes for Chunk 321 of 469\n","Making phenotypes for Chunk 322 of 469\n","Making phenotypes for Chunk 323 of 469\n","Making phenotypes for Chunk 324 of 469\n","Making phenotypes for Chunk 325 of 469\n","Making phenotypes for Chunk 326 of 469\n","Making phenotypes for Chunk 327 of 469\n","Making phenotypes for Chunk 328 of 469\n","Making phenotypes for Chunk 329 of 469\n","Making phenotypes for Chunk 330 of 469\n","Making phenotypes for Chunk 331 of 469\n","Making phenotypes for Chunk 332 of 469\n","Making phenotypes for Chunk 333 of 469\n","Making phenotypes for Chunk 334 of 469\n","Making phenotypes for Chunk 335 of 469\n","Making phenotypes for Chunk 336 of 469\n","Making phenotypes for Chunk 337 of 469\n","Making phenotypes for Chunk 338 of 469\n","Making phenotypes for Chunk 339 of 469\n","Making phenotypes for Chunk 340 of 469\n","Making phenotypes for Chunk 341 of 469\n","Making phenotypes for Chunk 342 of 469\n","Making phenotypes for Chunk 343 of 469\n","Making phenotypes for Chunk 344 of 469\n","Making phenotypes for Chunk 345 of 469\n","Making phenotypes for Chunk 346 of 469\n","Making phenotypes for Chunk 347 of 469\n","Making phenotypes for Chunk 348 of 469\n","Making phenotypes for Chunk 349 of 469\n","Making phenotypes for Chunk 350 of 469\n","Making phenotypes for Chunk 351 of 469\n","Making phenotypes for Chunk 352 of 469\n","Making phenotypes for Chunk 353 of 469\n","Making phenotypes for Chunk 354 of 469\n","Making phenotypes for Chunk 355 of 469\n","Making phenotypes for Chunk 356 of 469\n","Making phenotypes for Chunk 357 of 469\n","Making phenotypes for Chunk 358 of 469\n","Making phenotypes for Chunk 359 of 469\n","Making phenotypes for Chunk 360 of 469\n","Making phenotypes for Chunk 361 of 469\n","Making phenotypes for Chunk 362 of 469\n","Making phenotypes for Chunk 363 of 469\n","Making phenotypes for Chunk 364 of 469\n","Making phenotypes for Chunk 365 of 469\n","Making phenotypes for Chunk 366 of 469\n","Making phenotypes for Chunk 367 of 469\n","Making phenotypes for Chunk 368 of 469\n","Making phenotypes for Chunk 369 of 469\n","Making phenotypes for Chunk 370 of 469\n","Making phenotypes for Chunk 371 of 469\n","Making phenotypes for Chunk 372 of 469\n","Making phenotypes for Chunk 373 of 469\n","Making phenotypes for Chunk 374 of 469\n","Making phenotypes for Chunk 375 of 469\n","Making phenotypes for Chunk 376 of 469\n","Making phenotypes for Chunk 377 of 469\n","Making phenotypes for Chunk 378 of 469\n","Making phenotypes for Chunk 379 of 469\n","Making phenotypes for Chunk 380 of 469\n","Making phenotypes for Chunk 381 of 469\n","Making phenotypes for Chunk 382 of 469\n","Making phenotypes for Chunk 383 of 469\n","Making phenotypes for Chunk 384 of 469\n","Making phenotypes for Chunk 385 of 469\n","Making phenotypes for Chunk 386 of 469\n","Making phenotypes for Chunk 387 of 469\n","Making phenotypes for Chunk 388 of 469\n","Making phenotypes for Chunk 389 of 469\n","Making phenotypes for Chunk 390 of 469\n","Making phenotypes for Chunk 391 of 469\n","Making phenotypes for Chunk 392 of 469\n","Making phenotypes for Chunk 393 of 469\n","Making phenotypes for Chunk 394 of 469\n","Making phenotypes for Chunk 395 of 469\n","Making phenotypes for Chunk 396 of 469\n","Making phenotypes for Chunk 397 of 469\n","Making phenotypes for Chunk 398 of 469\n","Making phenotypes for Chunk 399 of 469\n","Making phenotypes for Chunk 400 of 469\n","Making phenotypes for Chunk 401 of 469\n","Making phenotypes for Chunk 402 of 469\n","Making phenotypes for Chunk 403 of 469\n","Making phenotypes for Chunk 404 of 469\n","Making phenotypes for Chunk 405 of 469\n","Making phenotypes for Chunk 406 of 469\n","Making phenotypes for Chunk 407 of 469\n","Making phenotypes for Chunk 408 of 469\n","Making phenotypes for Chunk 409 of 469\n","Making phenotypes for Chunk 410 of 469\n","Making phenotypes for Chunk 411 of 469\n","Making phenotypes for Chunk 412 of 469\n","Making phenotypes for Chunk 413 of 469\n","Making phenotypes for Chunk 414 of 469\n","Making phenotypes for Chunk 415 of 469\n","Making phenotypes for Chunk 416 of 469\n","Making phenotypes for Chunk 417 of 469\n","Making phenotypes for Chunk 418 of 469\n","Making phenotypes for Chunk 419 of 469\n","Making phenotypes for Chunk 420 of 469\n","Making phenotypes for Chunk 421 of 469\n","Making phenotypes for Chunk 422 of 469\n","Making phenotypes for Chunk 423 of 469\n","Making phenotypes for Chunk 424 of 469\n","Making phenotypes for Chunk 425 of 469\n","Making phenotypes for Chunk 426 of 469\n","Making phenotypes for Chunk 427 of 469\n","Making phenotypes for Chunk 428 of 469\n","Making phenotypes for Chunk 429 of 469\n","Making phenotypes for Chunk 430 of 469\n","Making phenotypes for Chunk 431 of 469\n","Making phenotypes for Chunk 432 of 469\n","Making phenotypes for Chunk 433 of 469\n","Making phenotypes for Chunk 434 of 469\n","Making phenotypes for Chunk 435 of 469\n","Making phenotypes for Chunk 436 of 469\n","Making phenotypes for Chunk 437 of 469\n","Making phenotypes for Chunk 438 of 469\n","Making phenotypes for Chunk 439 of 469\n","Making phenotypes for Chunk 440 of 469\n","Making phenotypes for Chunk 441 of 469\n","Making phenotypes for Chunk 442 of 469\n","Making phenotypes for Chunk 443 of 469\n","Making phenotypes for Chunk 444 of 469\n","Making phenotypes for Chunk 445 of 469\n","Making phenotypes for Chunk 446 of 469\n","Making phenotypes for Chunk 447 of 469\n","Making phenotypes for Chunk 448 of 469\n","Making phenotypes for Chunk 449 of 469\n","Making phenotypes for Chunk 450 of 469\n","Making phenotypes for Chunk 451 of 469\n","Making phenotypes for Chunk 452 of 469\n","Making phenotypes for Chunk 453 of 469\n","Making phenotypes for Chunk 454 of 469\n","Making phenotypes for Chunk 455 of 469\n","Making phenotypes for Chunk 456 of 469\n","Making phenotypes for Chunk 457 of 469\n","Making phenotypes for Chunk 458 of 469\n","Making phenotypes for Chunk 459 of 469\n","Making phenotypes for Chunk 460 of 469\n","Making phenotypes for Chunk 461 of 469\n","Making phenotypes for Chunk 462 of 469\n","Making phenotypes for Chunk 463 of 469\n","Making phenotypes for Chunk 464 of 469\n","Making phenotypes for Chunk 465 of 469\n","Making phenotypes for Chunk 466 of 469\n","Making phenotypes for Chunk 467 of 469\n","Making phenotypes for Chunk 468 of 469\n","Making phenotypes for Chunk 469 of 469\n","\n","Phenotypes saved in HumDef_params={her=0.5,num-causals=10000}.pheno, with breeding values in HumDef_params={her=0.5,num-causals=10000}.breed and effect sizes in HumDef_params={her=0.5,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.7,num-causals=1}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.7\n","--num-causals 1\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.7,num-causals=1}.pheno, with breeding values in HumDef_params={her=0.7,num-causals=1}.breed and effect sizes in HumDef_params={her=0.7,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.7,num-causals=10}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.7\n","--num-causals 10\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.7,num-causals=10}.pheno, with breeding values in HumDef_params={her=0.7,num-causals=10}.breed and effect sizes in HumDef_params={her=0.7,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.7,num-causals=100}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.7\n","--num-causals 100\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in HumDef_params={her=0.7,num-causals=100}.pheno, with breeding values in HumDef_params={her=0.7,num-causals=100}.breed and effect sizes in HumDef_params={her=0.7,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.7,num-causals=1000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.7\n","--num-causals 1000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in HumDef_params={her=0.7,num-causals=1000}.pheno, with breeding values in HumDef_params={her=0.7,num-causals=1000}.breed and effect sizes in HumDef_params={her=0.7,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.7,num-causals=10000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.7\n","--num-causals 10000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 469\n","Making phenotypes for Chunk 2 of 469\n","Making phenotypes for Chunk 3 of 469\n","Making phenotypes for Chunk 4 of 469\n","Making phenotypes for Chunk 5 of 469\n","Making phenotypes for Chunk 6 of 469\n","Making phenotypes for Chunk 7 of 469\n","Making phenotypes for Chunk 8 of 469\n","Making phenotypes for Chunk 9 of 469\n","Making phenotypes for Chunk 10 of 469\n","Making phenotypes for Chunk 11 of 469\n","Making phenotypes for Chunk 12 of 469\n","Making phenotypes for Chunk 13 of 469\n","Making phenotypes for Chunk 14 of 469\n","Making phenotypes for Chunk 15 of 469\n","Making phenotypes for Chunk 16 of 469\n","Making phenotypes for Chunk 17 of 469\n","Making phenotypes for Chunk 18 of 469\n","Making phenotypes for Chunk 19 of 469\n","Making phenotypes for Chunk 20 of 469\n","Making phenotypes for Chunk 21 of 469\n","Making phenotypes for Chunk 22 of 469\n","Making phenotypes for Chunk 23 of 469\n","Making phenotypes for Chunk 24 of 469\n","Making phenotypes for Chunk 25 of 469\n","Making phenotypes for Chunk 26 of 469\n","Making phenotypes for Chunk 27 of 469\n","Making phenotypes for Chunk 28 of 469\n","Making phenotypes for Chunk 29 of 469\n","Making phenotypes for Chunk 30 of 469\n","Making phenotypes for Chunk 31 of 469\n","Making phenotypes for Chunk 32 of 469\n","Making phenotypes for Chunk 33 of 469\n","Making phenotypes for Chunk 34 of 469\n","Making phenotypes for Chunk 35 of 469\n","Making phenotypes for Chunk 36 of 469\n","Making phenotypes for Chunk 37 of 469\n","Making phenotypes for Chunk 38 of 469\n","Making phenotypes for Chunk 39 of 469\n","Making phenotypes for Chunk 40 of 469\n","Making phenotypes for Chunk 41 of 469\n","Making phenotypes for Chunk 42 of 469\n","Making phenotypes for Chunk 43 of 469\n","Making phenotypes for Chunk 44 of 469\n","Making phenotypes for Chunk 45 of 469\n","Making phenotypes for Chunk 46 of 469\n","Making phenotypes for Chunk 47 of 469\n","Making phenotypes for Chunk 48 of 469\n","Making phenotypes for Chunk 49 of 469\n","Making phenotypes for Chunk 50 of 469\n","Making phenotypes for Chunk 51 of 469\n","Making phenotypes for Chunk 52 of 469\n","Making phenotypes for Chunk 53 of 469\n","Making phenotypes for Chunk 54 of 469\n","Making phenotypes for Chunk 55 of 469\n","Making phenotypes for Chunk 56 of 469\n","Making phenotypes for Chunk 57 of 469\n","Making phenotypes for Chunk 58 of 469\n","Making phenotypes for Chunk 59 of 469\n","Making phenotypes for Chunk 60 of 469\n","Making phenotypes for Chunk 61 of 469\n","Making phenotypes for Chunk 62 of 469\n","Making phenotypes for Chunk 63 of 469\n","Making phenotypes for Chunk 64 of 469\n","Making phenotypes for Chunk 65 of 469\n","Making phenotypes for Chunk 66 of 469\n","Making phenotypes for Chunk 67 of 469\n","Making phenotypes for Chunk 68 of 469\n","Making phenotypes for Chunk 69 of 469\n","Making phenotypes for Chunk 70 of 469\n","Making phenotypes for Chunk 71 of 469\n","Making phenotypes for Chunk 72 of 469\n","Making phenotypes for Chunk 73 of 469\n","Making phenotypes for Chunk 74 of 469\n","Making phenotypes for Chunk 75 of 469\n","Making phenotypes for Chunk 76 of 469\n","Making phenotypes for Chunk 77 of 469\n","Making phenotypes for Chunk 78 of 469\n","Making phenotypes for Chunk 79 of 469\n","Making phenotypes for Chunk 80 of 469\n","Making phenotypes for Chunk 81 of 469\n","Making phenotypes for Chunk 82 of 469\n","Making phenotypes for Chunk 83 of 469\n","Making phenotypes for Chunk 84 of 469\n","Making phenotypes for Chunk 85 of 469\n","Making phenotypes for Chunk 86 of 469\n","Making phenotypes for Chunk 87 of 469\n","Making phenotypes for Chunk 88 of 469\n","Making phenotypes for Chunk 89 of 469\n","Making phenotypes for Chunk 90 of 469\n","Making phenotypes for Chunk 91 of 469\n","Making phenotypes for Chunk 92 of 469\n","Making phenotypes for Chunk 93 of 469\n","Making phenotypes for Chunk 94 of 469\n","Making phenotypes for Chunk 95 of 469\n","Making phenotypes for Chunk 96 of 469\n","Making phenotypes for Chunk 97 of 469\n","Making phenotypes for Chunk 98 of 469\n","Making phenotypes for Chunk 99 of 469\n","Making phenotypes for Chunk 100 of 469\n","Making phenotypes for Chunk 101 of 469\n","Making phenotypes for Chunk 102 of 469\n","Making phenotypes for Chunk 103 of 469\n","Making phenotypes for Chunk 104 of 469\n","Making phenotypes for Chunk 105 of 469\n","Making phenotypes for Chunk 106 of 469\n","Making phenotypes for Chunk 107 of 469\n","Making phenotypes for Chunk 108 of 469\n","Making phenotypes for Chunk 109 of 469\n","Making phenotypes for Chunk 110 of 469\n","Making phenotypes for Chunk 111 of 469\n","Making phenotypes for Chunk 112 of 469\n","Making phenotypes for Chunk 113 of 469\n","Making phenotypes for Chunk 114 of 469\n","Making phenotypes for Chunk 115 of 469\n","Making phenotypes for Chunk 116 of 469\n","Making phenotypes for Chunk 117 of 469\n","Making phenotypes for Chunk 118 of 469\n","Making phenotypes for Chunk 119 of 469\n","Making phenotypes for Chunk 120 of 469\n","Making phenotypes for Chunk 121 of 469\n","Making phenotypes for Chunk 122 of 469\n","Making phenotypes for Chunk 123 of 469\n","Making phenotypes for Chunk 124 of 469\n","Making phenotypes for Chunk 125 of 469\n","Making phenotypes for Chunk 126 of 469\n","Making phenotypes for Chunk 127 of 469\n","Making phenotypes for Chunk 128 of 469\n","Making phenotypes for Chunk 129 of 469\n","Making phenotypes for Chunk 130 of 469\n","Making phenotypes for Chunk 131 of 469\n","Making phenotypes for Chunk 132 of 469\n","Making phenotypes for Chunk 133 of 469\n","Making phenotypes for Chunk 134 of 469\n","Making phenotypes for Chunk 135 of 469\n","Making phenotypes for Chunk 136 of 469\n","Making phenotypes for Chunk 137 of 469\n","Making phenotypes for Chunk 138 of 469\n","Making phenotypes for Chunk 139 of 469\n","Making phenotypes for Chunk 140 of 469\n","Making phenotypes for Chunk 141 of 469\n","Making phenotypes for Chunk 142 of 469\n","Making phenotypes for Chunk 143 of 469\n","Making phenotypes for Chunk 144 of 469\n","Making phenotypes for Chunk 145 of 469\n","Making phenotypes for Chunk 146 of 469\n","Making phenotypes for Chunk 147 of 469\n","Making phenotypes for Chunk 148 of 469\n","Making phenotypes for Chunk 149 of 469\n","Making phenotypes for Chunk 150 of 469\n","Making phenotypes for Chunk 151 of 469\n","Making phenotypes for Chunk 152 of 469\n","Making phenotypes for Chunk 153 of 469\n","Making phenotypes for Chunk 154 of 469\n","Making phenotypes for Chunk 155 of 469\n","Making phenotypes for Chunk 156 of 469\n","Making phenotypes for Chunk 157 of 469\n","Making phenotypes for Chunk 158 of 469\n","Making phenotypes for Chunk 159 of 469\n","Making phenotypes for Chunk 160 of 469\n","Making phenotypes for Chunk 161 of 469\n","Making phenotypes for Chunk 162 of 469\n","Making phenotypes for Chunk 163 of 469\n","Making phenotypes for Chunk 164 of 469\n","Making phenotypes for Chunk 165 of 469\n","Making phenotypes for Chunk 166 of 469\n","Making phenotypes for Chunk 167 of 469\n","Making phenotypes for Chunk 168 of 469\n","Making phenotypes for Chunk 169 of 469\n","Making phenotypes for Chunk 170 of 469\n","Making phenotypes for Chunk 171 of 469\n","Making phenotypes for Chunk 172 of 469\n","Making phenotypes for Chunk 173 of 469\n","Making phenotypes for Chunk 174 of 469\n","Making phenotypes for Chunk 175 of 469\n","Making phenotypes for Chunk 176 of 469\n","Making phenotypes for Chunk 177 of 469\n","Making phenotypes for Chunk 178 of 469\n","Making phenotypes for Chunk 179 of 469\n","Making phenotypes for Chunk 180 of 469\n","Making phenotypes for Chunk 181 of 469\n","Making phenotypes for Chunk 182 of 469\n","Making phenotypes for Chunk 183 of 469\n","Making phenotypes for Chunk 184 of 469\n","Making phenotypes for Chunk 185 of 469\n","Making phenotypes for Chunk 186 of 469\n","Making phenotypes for Chunk 187 of 469\n","Making phenotypes for Chunk 188 of 469\n","Making phenotypes for Chunk 189 of 469\n","Making phenotypes for Chunk 190 of 469\n","Making phenotypes for Chunk 191 of 469\n","Making phenotypes for Chunk 192 of 469\n","Making phenotypes for Chunk 193 of 469\n","Making phenotypes for Chunk 194 of 469\n","Making phenotypes for Chunk 195 of 469\n","Making phenotypes for Chunk 196 of 469\n","Making phenotypes for Chunk 197 of 469\n","Making phenotypes for Chunk 198 of 469\n","Making phenotypes for Chunk 199 of 469\n","Making phenotypes for Chunk 200 of 469\n","Making phenotypes for Chunk 201 of 469\n","Making phenotypes for Chunk 202 of 469\n","Making phenotypes for Chunk 203 of 469\n","Making phenotypes for Chunk 204 of 469\n","Making phenotypes for Chunk 205 of 469\n","Making phenotypes for Chunk 206 of 469\n","Making phenotypes for Chunk 207 of 469\n","Making phenotypes for Chunk 208 of 469\n","Making phenotypes for Chunk 209 of 469\n","Making phenotypes for Chunk 210 of 469\n","Making phenotypes for Chunk 211 of 469\n","Making phenotypes for Chunk 212 of 469\n","Making phenotypes for Chunk 213 of 469\n","Making phenotypes for Chunk 214 of 469\n","Making phenotypes for Chunk 215 of 469\n","Making phenotypes for Chunk 216 of 469\n","Making phenotypes for Chunk 217 of 469\n","Making phenotypes for Chunk 218 of 469\n","Making phenotypes for Chunk 219 of 469\n","Making phenotypes for Chunk 220 of 469\n","Making phenotypes for Chunk 221 of 469\n","Making phenotypes for Chunk 222 of 469\n","Making phenotypes for Chunk 223 of 469\n","Making phenotypes for Chunk 224 of 469\n","Making phenotypes for Chunk 225 of 469\n","Making phenotypes for Chunk 226 of 469\n","Making phenotypes for Chunk 227 of 469\n","Making phenotypes for Chunk 228 of 469\n","Making phenotypes for Chunk 229 of 469\n","Making phenotypes for Chunk 230 of 469\n","Making phenotypes for Chunk 231 of 469\n","Making phenotypes for Chunk 232 of 469\n","Making phenotypes for Chunk 233 of 469\n","Making phenotypes for Chunk 234 of 469\n","Making phenotypes for Chunk 235 of 469\n","Making phenotypes for Chunk 236 of 469\n","Making phenotypes for Chunk 237 of 469\n","Making phenotypes for Chunk 238 of 469\n","Making phenotypes for Chunk 239 of 469\n","Making phenotypes for Chunk 240 of 469\n","Making phenotypes for Chunk 241 of 469\n","Making phenotypes for Chunk 242 of 469\n","Making phenotypes for Chunk 243 of 469\n","Making phenotypes for Chunk 244 of 469\n","Making phenotypes for Chunk 245 of 469\n","Making phenotypes for Chunk 246 of 469\n","Making phenotypes for Chunk 247 of 469\n","Making phenotypes for Chunk 248 of 469\n","Making phenotypes for Chunk 249 of 469\n","Making phenotypes for Chunk 250 of 469\n","Making phenotypes for Chunk 251 of 469\n","Making phenotypes for Chunk 252 of 469\n","Making phenotypes for Chunk 253 of 469\n","Making phenotypes for Chunk 254 of 469\n","Making phenotypes for Chunk 255 of 469\n","Making phenotypes for Chunk 256 of 469\n","Making phenotypes for Chunk 257 of 469\n","Making phenotypes for Chunk 258 of 469\n","Making phenotypes for Chunk 259 of 469\n","Making phenotypes for Chunk 260 of 469\n","Making phenotypes for Chunk 261 of 469\n","Making phenotypes for Chunk 262 of 469\n","Making phenotypes for Chunk 263 of 469\n","Making phenotypes for Chunk 264 of 469\n","Making phenotypes for Chunk 265 of 469\n","Making phenotypes for Chunk 266 of 469\n","Making phenotypes for Chunk 267 of 469\n","Making phenotypes for Chunk 268 of 469\n","Making phenotypes for Chunk 269 of 469\n","Making phenotypes for Chunk 270 of 469\n","Making phenotypes for Chunk 271 of 469\n","Making phenotypes for Chunk 272 of 469\n","Making phenotypes for Chunk 273 of 469\n","Making phenotypes for Chunk 274 of 469\n","Making phenotypes for Chunk 275 of 469\n","Making phenotypes for Chunk 276 of 469\n","Making phenotypes for Chunk 277 of 469\n","Making phenotypes for Chunk 278 of 469\n","Making phenotypes for Chunk 279 of 469\n","Making phenotypes for Chunk 280 of 469\n","Making phenotypes for Chunk 281 of 469\n","Making phenotypes for Chunk 282 of 469\n","Making phenotypes for Chunk 283 of 469\n","Making phenotypes for Chunk 284 of 469\n","Making phenotypes for Chunk 285 of 469\n","Making phenotypes for Chunk 286 of 469\n","Making phenotypes for Chunk 287 of 469\n","Making phenotypes for Chunk 288 of 469\n","Making phenotypes for Chunk 289 of 469\n","Making phenotypes for Chunk 290 of 469\n","Making phenotypes for Chunk 291 of 469\n","Making phenotypes for Chunk 292 of 469\n","Making phenotypes for Chunk 293 of 469\n","Making phenotypes for Chunk 294 of 469\n","Making phenotypes for Chunk 295 of 469\n","Making phenotypes for Chunk 296 of 469\n","Making phenotypes for Chunk 297 of 469\n","Making phenotypes for Chunk 298 of 469\n","Making phenotypes for Chunk 299 of 469\n","Making phenotypes for Chunk 300 of 469\n","Making phenotypes for Chunk 301 of 469\n","Making phenotypes for Chunk 302 of 469\n","Making phenotypes for Chunk 303 of 469\n","Making phenotypes for Chunk 304 of 469\n","Making phenotypes for Chunk 305 of 469\n","Making phenotypes for Chunk 306 of 469\n","Making phenotypes for Chunk 307 of 469\n","Making phenotypes for Chunk 308 of 469\n","Making phenotypes for Chunk 309 of 469\n","Making phenotypes for Chunk 310 of 469\n","Making phenotypes for Chunk 311 of 469\n","Making phenotypes for Chunk 312 of 469\n","Making phenotypes for Chunk 313 of 469\n","Making phenotypes for Chunk 314 of 469\n","Making phenotypes for Chunk 315 of 469\n","Making phenotypes for Chunk 316 of 469\n","Making phenotypes for Chunk 317 of 469\n","Making phenotypes for Chunk 318 of 469\n","Making phenotypes for Chunk 319 of 469\n","Making phenotypes for Chunk 320 of 469\n","Making phenotypes for Chunk 321 of 469\n","Making phenotypes for Chunk 322 of 469\n","Making phenotypes for Chunk 323 of 469\n","Making phenotypes for Chunk 324 of 469\n","Making phenotypes for Chunk 325 of 469\n","Making phenotypes for Chunk 326 of 469\n","Making phenotypes for Chunk 327 of 469\n","Making phenotypes for Chunk 328 of 469\n","Making phenotypes for Chunk 329 of 469\n","Making phenotypes for Chunk 330 of 469\n","Making phenotypes for Chunk 331 of 469\n","Making phenotypes for Chunk 332 of 469\n","Making phenotypes for Chunk 333 of 469\n","Making phenotypes for Chunk 334 of 469\n","Making phenotypes for Chunk 335 of 469\n","Making phenotypes for Chunk 336 of 469\n","Making phenotypes for Chunk 337 of 469\n","Making phenotypes for Chunk 338 of 469\n","Making phenotypes for Chunk 339 of 469\n","Making phenotypes for Chunk 340 of 469\n","Making phenotypes for Chunk 341 of 469\n","Making phenotypes for Chunk 342 of 469\n","Making phenotypes for Chunk 343 of 469\n","Making phenotypes for Chunk 344 of 469\n","Making phenotypes for Chunk 345 of 469\n","Making phenotypes for Chunk 346 of 469\n","Making phenotypes for Chunk 347 of 469\n","Making phenotypes for Chunk 348 of 469\n","Making phenotypes for Chunk 349 of 469\n","Making phenotypes for Chunk 350 of 469\n","Making phenotypes for Chunk 351 of 469\n","Making phenotypes for Chunk 352 of 469\n","Making phenotypes for Chunk 353 of 469\n","Making phenotypes for Chunk 354 of 469\n","Making phenotypes for Chunk 355 of 469\n","Making phenotypes for Chunk 356 of 469\n","Making phenotypes for Chunk 357 of 469\n","Making phenotypes for Chunk 358 of 469\n","Making phenotypes for Chunk 359 of 469\n","Making phenotypes for Chunk 360 of 469\n","Making phenotypes for Chunk 361 of 469\n","Making phenotypes for Chunk 362 of 469\n","Making phenotypes for Chunk 363 of 469\n","Making phenotypes for Chunk 364 of 469\n","Making phenotypes for Chunk 365 of 469\n","Making phenotypes for Chunk 366 of 469\n","Making phenotypes for Chunk 367 of 469\n","Making phenotypes for Chunk 368 of 469\n","Making phenotypes for Chunk 369 of 469\n","Making phenotypes for Chunk 370 of 469\n","Making phenotypes for Chunk 371 of 469\n","Making phenotypes for Chunk 372 of 469\n","Making phenotypes for Chunk 373 of 469\n","Making phenotypes for Chunk 374 of 469\n","Making phenotypes for Chunk 375 of 469\n","Making phenotypes for Chunk 376 of 469\n","Making phenotypes for Chunk 377 of 469\n","Making phenotypes for Chunk 378 of 469\n","Making phenotypes for Chunk 379 of 469\n","Making phenotypes for Chunk 380 of 469\n","Making phenotypes for Chunk 381 of 469\n","Making phenotypes for Chunk 382 of 469\n","Making phenotypes for Chunk 383 of 469\n","Making phenotypes for Chunk 384 of 469\n","Making phenotypes for Chunk 385 of 469\n","Making phenotypes for Chunk 386 of 469\n","Making phenotypes for Chunk 387 of 469\n","Making phenotypes for Chunk 388 of 469\n","Making phenotypes for Chunk 389 of 469\n","Making phenotypes for Chunk 390 of 469\n","Making phenotypes for Chunk 391 of 469\n","Making phenotypes for Chunk 392 of 469\n","Making phenotypes for Chunk 393 of 469\n","Making phenotypes for Chunk 394 of 469\n","Making phenotypes for Chunk 395 of 469\n","Making phenotypes for Chunk 396 of 469\n","Making phenotypes for Chunk 397 of 469\n","Making phenotypes for Chunk 398 of 469\n","Making phenotypes for Chunk 399 of 469\n","Making phenotypes for Chunk 400 of 469\n","Making phenotypes for Chunk 401 of 469\n","Making phenotypes for Chunk 402 of 469\n","Making phenotypes for Chunk 403 of 469\n","Making phenotypes for Chunk 404 of 469\n","Making phenotypes for Chunk 405 of 469\n","Making phenotypes for Chunk 406 of 469\n","Making phenotypes for Chunk 407 of 469\n","Making phenotypes for Chunk 408 of 469\n","Making phenotypes for Chunk 409 of 469\n","Making phenotypes for Chunk 410 of 469\n","Making phenotypes for Chunk 411 of 469\n","Making phenotypes for Chunk 412 of 469\n","Making phenotypes for Chunk 413 of 469\n","Making phenotypes for Chunk 414 of 469\n","Making phenotypes for Chunk 415 of 469\n","Making phenotypes for Chunk 416 of 469\n","Making phenotypes for Chunk 417 of 469\n","Making phenotypes for Chunk 418 of 469\n","Making phenotypes for Chunk 419 of 469\n","Making phenotypes for Chunk 420 of 469\n","Making phenotypes for Chunk 421 of 469\n","Making phenotypes for Chunk 422 of 469\n","Making phenotypes for Chunk 423 of 469\n","Making phenotypes for Chunk 424 of 469\n","Making phenotypes for Chunk 425 of 469\n","Making phenotypes for Chunk 426 of 469\n","Making phenotypes for Chunk 427 of 469\n","Making phenotypes for Chunk 428 of 469\n","Making phenotypes for Chunk 429 of 469\n","Making phenotypes for Chunk 430 of 469\n","Making phenotypes for Chunk 431 of 469\n","Making phenotypes for Chunk 432 of 469\n","Making phenotypes for Chunk 433 of 469\n","Making phenotypes for Chunk 434 of 469\n","Making phenotypes for Chunk 435 of 469\n","Making phenotypes for Chunk 436 of 469\n","Making phenotypes for Chunk 437 of 469\n","Making phenotypes for Chunk 438 of 469\n","Making phenotypes for Chunk 439 of 469\n","Making phenotypes for Chunk 440 of 469\n","Making phenotypes for Chunk 441 of 469\n","Making phenotypes for Chunk 442 of 469\n","Making phenotypes for Chunk 443 of 469\n","Making phenotypes for Chunk 444 of 469\n","Making phenotypes for Chunk 445 of 469\n","Making phenotypes for Chunk 446 of 469\n","Making phenotypes for Chunk 447 of 469\n","Making phenotypes for Chunk 448 of 469\n","Making phenotypes for Chunk 449 of 469\n","Making phenotypes for Chunk 450 of 469\n","Making phenotypes for Chunk 451 of 469\n","Making phenotypes for Chunk 452 of 469\n","Making phenotypes for Chunk 453 of 469\n","Making phenotypes for Chunk 454 of 469\n","Making phenotypes for Chunk 455 of 469\n","Making phenotypes for Chunk 456 of 469\n","Making phenotypes for Chunk 457 of 469\n","Making phenotypes for Chunk 458 of 469\n","Making phenotypes for Chunk 459 of 469\n","Making phenotypes for Chunk 460 of 469\n","Making phenotypes for Chunk 461 of 469\n","Making phenotypes for Chunk 462 of 469\n","Making phenotypes for Chunk 463 of 469\n","Making phenotypes for Chunk 464 of 469\n","Making phenotypes for Chunk 465 of 469\n","Making phenotypes for Chunk 466 of 469\n","Making phenotypes for Chunk 467 of 469\n","Making phenotypes for Chunk 468 of 469\n","Making phenotypes for Chunk 469 of 469\n","\n","Phenotypes saved in HumDef_params={her=0.7,num-causals=10000}.pheno, with breeding values in HumDef_params={her=0.7,num-causals=10000}.breed and effect sizes in HumDef_params={her=0.7,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.9,num-causals=1}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.9\n","--num-causals 1\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.9,num-causals=1}.pheno, with breeding values in HumDef_params={her=0.9,num-causals=1}.breed and effect sizes in HumDef_params={her=0.9,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.9,num-causals=10}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.9\n","--num-causals 10\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in HumDef_params={her=0.9,num-causals=10}.pheno, with breeding values in HumDef_params={her=0.9,num-causals=10}.breed and effect sizes in HumDef_params={her=0.9,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.9,num-causals=100}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.9\n","--num-causals 100\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in HumDef_params={her=0.9,num-causals=100}.pheno, with breeding values in HumDef_params={her=0.9,num-causals=100}.breed and effect sizes in HumDef_params={her=0.9,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.9,num-causals=1000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.9\n","--num-causals 1000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in HumDef_params={her=0.9,num-causals=1000}.pheno, with breeding values in HumDef_params={her=0.9,num-causals=1000}.breed and effect sizes in HumDef_params={her=0.9,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 6 pairs of arguments:\n","--make-phenos HumDef_params={her=0.9,num-causals=10000}\n","--bfile 1000g\n","--power -.25\n","--num-phenos 100\n","--her 0.9\n","--num-causals 10000\n","\n","Warning, the predictor weightings have been set to one (equivalent to adding \"--ignore-weights YES\"); if you wish to specify different weightings, use \"--weights\"\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-0.2500/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 470\n","Making phenotypes for Chunk 2 of 470\n","Making phenotypes for Chunk 3 of 470\n","Making phenotypes for Chunk 4 of 470\n","Making phenotypes for Chunk 5 of 470\n","Making phenotypes for Chunk 6 of 470\n","Making phenotypes for Chunk 7 of 470\n","Making phenotypes for Chunk 8 of 470\n","Making phenotypes for Chunk 9 of 470\n","Making phenotypes for Chunk 10 of 470\n","Making phenotypes for Chunk 11 of 470\n","Making phenotypes for Chunk 12 of 470\n","Making phenotypes for Chunk 13 of 470\n","Making phenotypes for Chunk 14 of 470\n","Making phenotypes for Chunk 15 of 470\n","Making phenotypes for Chunk 16 of 470\n","Making phenotypes for Chunk 17 of 470\n","Making phenotypes for Chunk 18 of 470\n","Making phenotypes for Chunk 19 of 470\n","Making phenotypes for Chunk 20 of 470\n","Making phenotypes for Chunk 21 of 470\n","Making phenotypes for Chunk 22 of 470\n","Making phenotypes for Chunk 23 of 470\n","Making phenotypes for Chunk 24 of 470\n","Making phenotypes for Chunk 25 of 470\n","Making phenotypes for Chunk 26 of 470\n","Making phenotypes for Chunk 27 of 470\n","Making phenotypes for Chunk 28 of 470\n","Making phenotypes for Chunk 29 of 470\n","Making phenotypes for Chunk 30 of 470\n","Making phenotypes for Chunk 31 of 470\n","Making phenotypes for Chunk 32 of 470\n","Making phenotypes for Chunk 33 of 470\n","Making phenotypes for Chunk 34 of 470\n","Making phenotypes for Chunk 35 of 470\n","Making phenotypes for Chunk 36 of 470\n","Making phenotypes for Chunk 37 of 470\n","Making phenotypes for Chunk 38 of 470\n","Making phenotypes for Chunk 39 of 470\n","Making phenotypes for Chunk 40 of 470\n","Making phenotypes for Chunk 41 of 470\n","Making phenotypes for Chunk 42 of 470\n","Making phenotypes for Chunk 43 of 470\n","Making phenotypes for Chunk 44 of 470\n","Making phenotypes for Chunk 45 of 470\n","Making phenotypes for Chunk 46 of 470\n","Making phenotypes for Chunk 47 of 470\n","Making phenotypes for Chunk 48 of 470\n","Making phenotypes for Chunk 49 of 470\n","Making phenotypes for Chunk 50 of 470\n","Making phenotypes for Chunk 51 of 470\n","Making phenotypes for Chunk 52 of 470\n","Making phenotypes for Chunk 53 of 470\n","Warning, Predictor 2:91795325 is trivial (takes at most one non-missing value) and will be ignored\n","Warning, Predictor 2:91802817 is trivial (takes at most one non-missing value) and will be ignored\n","\n","Making phenotypes for Chunk 54 of 470\n","Making phenotypes for Chunk 55 of 470\n","Making phenotypes for Chunk 56 of 470\n","Making phenotypes for Chunk 57 of 470\n","Making phenotypes for Chunk 58 of 470\n","Making phenotypes for Chunk 59 of 470\n","Making phenotypes for Chunk 60 of 470\n","Making phenotypes for Chunk 61 of 470\n","Making phenotypes for Chunk 62 of 470\n","Making phenotypes for Chunk 63 of 470\n","Making phenotypes for Chunk 64 of 470\n","Making phenotypes for Chunk 65 of 470\n","Making phenotypes for Chunk 66 of 470\n","Making phenotypes for Chunk 67 of 470\n","Making phenotypes for Chunk 68 of 470\n","Making phenotypes for Chunk 69 of 470\n","Making phenotypes for Chunk 70 of 470\n","Making phenotypes for Chunk 71 of 470\n","Making phenotypes for Chunk 72 of 470\n","Making phenotypes for Chunk 73 of 470\n","Making phenotypes for Chunk 74 of 470\n","Making phenotypes for Chunk 75 of 470\n","Making phenotypes for Chunk 76 of 470\n","Making phenotypes for Chunk 77 of 470\n","Making phenotypes for Chunk 78 of 470\n","Making phenotypes for Chunk 79 of 470\n","Making phenotypes for Chunk 80 of 470\n","Making phenotypes for Chunk 81 of 470\n","Making phenotypes for Chunk 82 of 470\n","Making phenotypes for Chunk 83 of 470\n","Making phenotypes for Chunk 84 of 470\n","Making phenotypes for Chunk 85 of 470\n","Making phenotypes for Chunk 86 of 470\n","Making phenotypes for Chunk 87 of 470\n","Making phenotypes for Chunk 88 of 470\n","Making phenotypes for Chunk 89 of 470\n","Making phenotypes for Chunk 90 of 470\n","Making phenotypes for Chunk 91 of 470\n","Making phenotypes for Chunk 92 of 470\n","Making phenotypes for Chunk 93 of 470\n","Making phenotypes for Chunk 94 of 470\n","Making phenotypes for Chunk 95 of 470\n","Making phenotypes for Chunk 96 of 470\n","Making phenotypes for Chunk 97 of 470\n","Making phenotypes for Chunk 98 of 470\n","Making phenotypes for Chunk 99 of 470\n","Making phenotypes for Chunk 100 of 470\n","Making phenotypes for Chunk 101 of 470\n","Making phenotypes for Chunk 102 of 470\n","Making phenotypes for Chunk 103 of 470\n","Making phenotypes for Chunk 104 of 470\n","Making phenotypes for Chunk 105 of 470\n","Making phenotypes for Chunk 106 of 470\n","Making phenotypes for Chunk 107 of 470\n","Making phenotypes for Chunk 108 of 470\n","Making phenotypes for Chunk 109 of 470\n","Making phenotypes for Chunk 110 of 470\n","Making phenotypes for Chunk 111 of 470\n","Making phenotypes for Chunk 112 of 470\n","Making phenotypes for Chunk 113 of 470\n","Making phenotypes for Chunk 114 of 470\n","Making phenotypes for Chunk 115 of 470\n","Making phenotypes for Chunk 116 of 470\n","Making phenotypes for Chunk 117 of 470\n","Making phenotypes for Chunk 118 of 470\n","Making phenotypes for Chunk 119 of 470\n","Making phenotypes for Chunk 120 of 470\n","Making phenotypes for Chunk 121 of 470\n","Making phenotypes for Chunk 122 of 470\n","Making phenotypes for Chunk 123 of 470\n","Making phenotypes for Chunk 124 of 470\n","Making phenotypes for Chunk 125 of 470\n","Making phenotypes for Chunk 126 of 470\n","Making phenotypes for Chunk 127 of 470\n","Making phenotypes for Chunk 128 of 470\n","Making phenotypes for Chunk 129 of 470\n","Making phenotypes for Chunk 130 of 470\n","Making phenotypes for Chunk 131 of 470\n","Making phenotypes for Chunk 132 of 470\n","Making phenotypes for Chunk 133 of 470\n","Making phenotypes for Chunk 134 of 470\n","Making phenotypes for Chunk 135 of 470\n","Making phenotypes for Chunk 136 of 470\n","Making phenotypes for Chunk 137 of 470\n","Making phenotypes for Chunk 138 of 470\n","Making phenotypes for Chunk 139 of 470\n","Making phenotypes for Chunk 140 of 470\n","Making phenotypes for Chunk 141 of 470\n","Making phenotypes for Chunk 142 of 470\n","Making phenotypes for Chunk 143 of 470\n","Making phenotypes for Chunk 144 of 470\n","Making phenotypes for Chunk 145 of 470\n","Making phenotypes for Chunk 146 of 470\n","Making phenotypes for Chunk 147 of 470\n","Making phenotypes for Chunk 148 of 470\n","Making phenotypes for Chunk 149 of 470\n","Making phenotypes for Chunk 150 of 470\n","Making phenotypes for Chunk 151 of 470\n","Making phenotypes for Chunk 152 of 470\n","Making phenotypes for Chunk 153 of 470\n","Making phenotypes for Chunk 154 of 470\n","Making phenotypes for Chunk 155 of 470\n","Making phenotypes for Chunk 156 of 470\n","Making phenotypes for Chunk 157 of 470\n","Making phenotypes for Chunk 158 of 470\n","Making phenotypes for Chunk 159 of 470\n","Making phenotypes for Chunk 160 of 470\n","Making phenotypes for Chunk 161 of 470\n","Making phenotypes for Chunk 162 of 470\n","Making phenotypes for Chunk 163 of 470\n","Making phenotypes for Chunk 164 of 470\n","Making phenotypes for Chunk 165 of 470\n","Making phenotypes for Chunk 166 of 470\n","Making phenotypes for Chunk 167 of 470\n","Making phenotypes for Chunk 168 of 470\n","Making phenotypes for Chunk 169 of 470\n","Making phenotypes for Chunk 170 of 470\n","Making phenotypes for Chunk 171 of 470\n","Making phenotypes for Chunk 172 of 470\n","Making phenotypes for Chunk 173 of 470\n","Making phenotypes for Chunk 174 of 470\n","Making phenotypes for Chunk 175 of 470\n","Making phenotypes for Chunk 176 of 470\n","Making phenotypes for Chunk 177 of 470\n","Making phenotypes for Chunk 178 of 470\n","Making phenotypes for Chunk 179 of 470\n","Making phenotypes for Chunk 180 of 470\n","Making phenotypes for Chunk 181 of 470\n","Making phenotypes for Chunk 182 of 470\n","Making phenotypes for Chunk 183 of 470\n","Making phenotypes for Chunk 184 of 470\n","Making phenotypes for Chunk 185 of 470\n","Making phenotypes for Chunk 186 of 470\n","Making phenotypes for Chunk 187 of 470\n","Making phenotypes for Chunk 188 of 470\n","Making phenotypes for Chunk 189 of 470\n","Making phenotypes for Chunk 190 of 470\n","Making phenotypes for Chunk 191 of 470\n","Making phenotypes for Chunk 192 of 470\n","Making phenotypes for Chunk 193 of 470\n","Making phenotypes for Chunk 194 of 470\n","Making phenotypes for Chunk 195 of 470\n","Making phenotypes for Chunk 196 of 470\n","Making phenotypes for Chunk 197 of 470\n","Making phenotypes for Chunk 198 of 470\n","Making phenotypes for Chunk 199 of 470\n","Making phenotypes for Chunk 200 of 470\n","Making phenotypes for Chunk 201 of 470\n","Making phenotypes for Chunk 202 of 470\n","Making phenotypes for Chunk 203 of 470\n","Making phenotypes for Chunk 204 of 470\n","Making phenotypes for Chunk 205 of 470\n","Making phenotypes for Chunk 206 of 470\n","Making phenotypes for Chunk 207 of 470\n","Making phenotypes for Chunk 208 of 470\n","Making phenotypes for Chunk 209 of 470\n","Making phenotypes for Chunk 210 of 470\n","Making phenotypes for Chunk 211 of 470\n","Making phenotypes for Chunk 212 of 470\n","Making phenotypes for Chunk 213 of 470\n","Making phenotypes for Chunk 214 of 470\n","Making phenotypes for Chunk 215 of 470\n","Making phenotypes for Chunk 216 of 470\n","Making phenotypes for Chunk 217 of 470\n","Making phenotypes for Chunk 218 of 470\n","Making phenotypes for Chunk 219 of 470\n","Making phenotypes for Chunk 220 of 470\n","Making phenotypes for Chunk 221 of 470\n","Making phenotypes for Chunk 222 of 470\n","Making phenotypes for Chunk 223 of 470\n","Making phenotypes for Chunk 224 of 470\n","Making phenotypes for Chunk 225 of 470\n","Making phenotypes for Chunk 226 of 470\n","Making phenotypes for Chunk 227 of 470\n","Making phenotypes for Chunk 228 of 470\n","Making phenotypes for Chunk 229 of 470\n","Making phenotypes for Chunk 230 of 470\n","Making phenotypes for Chunk 231 of 470\n","Making phenotypes for Chunk 232 of 470\n","Making phenotypes for Chunk 233 of 470\n","Making phenotypes for Chunk 234 of 470\n","Making phenotypes for Chunk 235 of 470\n","Making phenotypes for Chunk 236 of 470\n","Making phenotypes for Chunk 237 of 470\n","Making phenotypes for Chunk 238 of 470\n","Making phenotypes for Chunk 239 of 470\n","Making phenotypes for Chunk 240 of 470\n","Making phenotypes for Chunk 241 of 470\n","Making phenotypes for Chunk 242 of 470\n","Making phenotypes for Chunk 243 of 470\n","Making phenotypes for Chunk 244 of 470\n","Making phenotypes for Chunk 245 of 470\n","Making phenotypes for Chunk 246 of 470\n","Making phenotypes for Chunk 247 of 470\n","Making phenotypes for Chunk 248 of 470\n","Making phenotypes for Chunk 249 of 470\n","Making phenotypes for Chunk 250 of 470\n","Making phenotypes for Chunk 251 of 470\n","Making phenotypes for Chunk 252 of 470\n","Making phenotypes for Chunk 253 of 470\n","Making phenotypes for Chunk 254 of 470\n","Making phenotypes for Chunk 255 of 470\n","Making phenotypes for Chunk 256 of 470\n","Making phenotypes for Chunk 257 of 470\n","Making phenotypes for Chunk 258 of 470\n","Making phenotypes for Chunk 259 of 470\n","Making phenotypes for Chunk 260 of 470\n","Making phenotypes for Chunk 261 of 470\n","Making phenotypes for Chunk 262 of 470\n","Making phenotypes for Chunk 263 of 470\n","Making phenotypes for Chunk 264 of 470\n","Making phenotypes for Chunk 265 of 470\n","Making phenotypes for Chunk 266 of 470\n","Making phenotypes for Chunk 267 of 470\n","Making phenotypes for Chunk 268 of 470\n","Making phenotypes for Chunk 269 of 470\n","Making phenotypes for Chunk 270 of 470\n","Making phenotypes for Chunk 271 of 470\n","Making phenotypes for Chunk 272 of 470\n","Making phenotypes for Chunk 273 of 470\n","Making phenotypes for Chunk 274 of 470\n","Making phenotypes for Chunk 275 of 470\n","Making phenotypes for Chunk 276 of 470\n","Making phenotypes for Chunk 277 of 470\n","Making phenotypes for Chunk 278 of 470\n","Making phenotypes for Chunk 279 of 470\n","Making phenotypes for Chunk 280 of 470\n","Making phenotypes for Chunk 281 of 470\n","Making phenotypes for Chunk 282 of 470\n","Making phenotypes for Chunk 283 of 470\n","Making phenotypes for Chunk 284 of 470\n","Making phenotypes for Chunk 285 of 470\n","Making phenotypes for Chunk 286 of 470\n","Making phenotypes for Chunk 287 of 470\n","Making phenotypes for Chunk 288 of 470\n","Making phenotypes for Chunk 289 of 470\n","Making phenotypes for Chunk 290 of 470\n","Making phenotypes for Chunk 291 of 470\n","Making phenotypes for Chunk 292 of 470\n","Making phenotypes for Chunk 293 of 470\n","Making phenotypes for Chunk 294 of 470\n","Making phenotypes for Chunk 295 of 470\n","Making phenotypes for Chunk 296 of 470\n","Making phenotypes for Chunk 297 of 470\n","Making phenotypes for Chunk 298 of 470\n","Making phenotypes for Chunk 299 of 470\n","Making phenotypes for Chunk 300 of 470\n","Making phenotypes for Chunk 301 of 470\n","Making phenotypes for Chunk 302 of 470\n","Making phenotypes for Chunk 303 of 470\n","Making phenotypes for Chunk 304 of 470\n","Making phenotypes for Chunk 305 of 470\n","Making phenotypes for Chunk 306 of 470\n","Making phenotypes for Chunk 307 of 470\n","Making phenotypes for Chunk 308 of 470\n","Making phenotypes for Chunk 309 of 470\n","Making phenotypes for Chunk 310 of 470\n","Making phenotypes for Chunk 311 of 470\n","Making phenotypes for Chunk 312 of 470\n","Making phenotypes for Chunk 313 of 470\n","Making phenotypes for Chunk 314 of 470\n","Making phenotypes for Chunk 315 of 470\n","Making phenotypes for Chunk 316 of 470\n","Making phenotypes for Chunk 317 of 470\n","Making phenotypes for Chunk 318 of 470\n","Making phenotypes for Chunk 319 of 470\n","Making phenotypes for Chunk 320 of 470\n","Making phenotypes for Chunk 321 of 470\n","Making phenotypes for Chunk 322 of 470\n","Making phenotypes for Chunk 323 of 470\n","Making phenotypes for Chunk 324 of 470\n","Making phenotypes for Chunk 325 of 470\n","Making phenotypes for Chunk 326 of 470\n","Making phenotypes for Chunk 327 of 470\n","Making phenotypes for Chunk 328 of 470\n","Making phenotypes for Chunk 329 of 470\n","Making phenotypes for Chunk 330 of 470\n","Making phenotypes for Chunk 331 of 470\n","Making phenotypes for Chunk 332 of 470\n","Making phenotypes for Chunk 333 of 470\n","Making phenotypes for Chunk 334 of 470\n","Making phenotypes for Chunk 335 of 470\n","Making phenotypes for Chunk 336 of 470\n","Making phenotypes for Chunk 337 of 470\n","Making phenotypes for Chunk 338 of 470\n","Making phenotypes for Chunk 339 of 470\n","Making phenotypes for Chunk 340 of 470\n","Making phenotypes for Chunk 341 of 470\n","Making phenotypes for Chunk 342 of 470\n","Making phenotypes for Chunk 343 of 470\n","Making phenotypes for Chunk 344 of 470\n","Making phenotypes for Chunk 345 of 470\n","Making phenotypes for Chunk 346 of 470\n","Making phenotypes for Chunk 347 of 470\n","Making phenotypes for Chunk 348 of 470\n","Making phenotypes for Chunk 349 of 470\n","Making phenotypes for Chunk 350 of 470\n","Making phenotypes for Chunk 351 of 470\n","Making phenotypes for Chunk 352 of 470\n","Making phenotypes for Chunk 353 of 470\n","Making phenotypes for Chunk 354 of 470\n","Making phenotypes for Chunk 355 of 470\n","Making phenotypes for Chunk 356 of 470\n","Making phenotypes for Chunk 357 of 470\n","Making phenotypes for Chunk 358 of 470\n","Making phenotypes for Chunk 359 of 470\n","Making phenotypes for Chunk 360 of 470\n","Making phenotypes for Chunk 361 of 470\n","Making phenotypes for Chunk 362 of 470\n","Making phenotypes for Chunk 363 of 470\n","Making phenotypes for Chunk 364 of 470\n","Making phenotypes for Chunk 365 of 470\n","Making phenotypes for Chunk 366 of 470\n","Making phenotypes for Chunk 367 of 470\n","Making phenotypes for Chunk 368 of 470\n","Making phenotypes for Chunk 369 of 470\n","Making phenotypes for Chunk 370 of 470\n","Making phenotypes for Chunk 371 of 470\n","Making phenotypes for Chunk 372 of 470\n","Making phenotypes for Chunk 373 of 470\n","Making phenotypes for Chunk 374 of 470\n","Making phenotypes for Chunk 375 of 470\n","Making phenotypes for Chunk 376 of 470\n","Making phenotypes for Chunk 377 of 470\n","Making phenotypes for Chunk 378 of 470\n","Making phenotypes for Chunk 379 of 470\n","Making phenotypes for Chunk 380 of 470\n","Making phenotypes for Chunk 381 of 470\n","Making phenotypes for Chunk 382 of 470\n","Making phenotypes for Chunk 383 of 470\n","Making phenotypes for Chunk 384 of 470\n","Making phenotypes for Chunk 385 of 470\n","Making phenotypes for Chunk 386 of 470\n","Making phenotypes for Chunk 387 of 470\n","Making phenotypes for Chunk 388 of 470\n","Making phenotypes for Chunk 389 of 470\n","Making phenotypes for Chunk 390 of 470\n","Making phenotypes for Chunk 391 of 470\n","Making phenotypes for Chunk 392 of 470\n","Making phenotypes for Chunk 393 of 470\n","Making phenotypes for Chunk 394 of 470\n","Making phenotypes for Chunk 395 of 470\n","Making phenotypes for Chunk 396 of 470\n","Making phenotypes for Chunk 397 of 470\n","Making phenotypes for Chunk 398 of 470\n","Making phenotypes for Chunk 399 of 470\n","Making phenotypes for Chunk 400 of 470\n","Making phenotypes for Chunk 401 of 470\n","Making phenotypes for Chunk 402 of 470\n","Making phenotypes for Chunk 403 of 470\n","Making phenotypes for Chunk 404 of 470\n","Making phenotypes for Chunk 405 of 470\n","Making phenotypes for Chunk 406 of 470\n","Making phenotypes for Chunk 407 of 470\n","Making phenotypes for Chunk 408 of 470\n","Making phenotypes for Chunk 409 of 470\n","Making phenotypes for Chunk 410 of 470\n","Making phenotypes for Chunk 411 of 470\n","Making phenotypes for Chunk 412 of 470\n","Making phenotypes for Chunk 413 of 470\n","Making phenotypes for Chunk 414 of 470\n","Making phenotypes for Chunk 415 of 470\n","Making phenotypes for Chunk 416 of 470\n","Making phenotypes for Chunk 417 of 470\n","Making phenotypes for Chunk 418 of 470\n","Making phenotypes for Chunk 419 of 470\n","Making phenotypes for Chunk 420 of 470\n","Making phenotypes for Chunk 421 of 470\n","Making phenotypes for Chunk 422 of 470\n","Making phenotypes for Chunk 423 of 470\n","Making phenotypes for Chunk 424 of 470\n","Making phenotypes for Chunk 425 of 470\n","Making phenotypes for Chunk 426 of 470\n","Making phenotypes for Chunk 427 of 470\n","Making phenotypes for Chunk 428 of 470\n","Making phenotypes for Chunk 429 of 470\n","Making phenotypes for Chunk 430 of 470\n","Making phenotypes for Chunk 431 of 470\n","Making phenotypes for Chunk 432 of 470\n","Making phenotypes for Chunk 433 of 470\n","Making phenotypes for Chunk 434 of 470\n","Making phenotypes for Chunk 435 of 470\n","Making phenotypes for Chunk 436 of 470\n","Making phenotypes for Chunk 437 of 470\n","Making phenotypes for Chunk 438 of 470\n","Making phenotypes for Chunk 439 of 470\n","Making phenotypes for Chunk 440 of 470\n","Making phenotypes for Chunk 441 of 470\n","Making phenotypes for Chunk 442 of 470\n","Making phenotypes for Chunk 443 of 470\n","Making phenotypes for Chunk 444 of 470\n","Making phenotypes for Chunk 445 of 470\n","Making phenotypes for Chunk 446 of 470\n","Making phenotypes for Chunk 447 of 470\n","Making phenotypes for Chunk 448 of 470\n","Making phenotypes for Chunk 449 of 470\n","Making phenotypes for Chunk 450 of 470\n","Making phenotypes for Chunk 451 of 470\n","Making phenotypes for Chunk 452 of 470\n","Making phenotypes for Chunk 453 of 470\n","Making phenotypes for Chunk 454 of 470\n","Making phenotypes for Chunk 455 of 470\n","Making phenotypes for Chunk 456 of 470\n","Making phenotypes for Chunk 457 of 470\n","Making phenotypes for Chunk 458 of 470\n","Making phenotypes for Chunk 459 of 470\n","Making phenotypes for Chunk 460 of 470\n","Making phenotypes for Chunk 461 of 470\n","Making phenotypes for Chunk 462 of 470\n","Making phenotypes for Chunk 463 of 470\n","Making phenotypes for Chunk 464 of 470\n","Making phenotypes for Chunk 465 of 470\n","Making phenotypes for Chunk 466 of 470\n","Making phenotypes for Chunk 467 of 470\n","Making phenotypes for Chunk 468 of 470\n","Making phenotypes for Chunk 469 of 470\n","Making phenotypes for Chunk 470 of 470\n","\n","Phenotypes saved in HumDef_params={her=0.9,num-causals=10000}.pheno, with breeding values in HumDef_params={her=0.9,num-causals=10000}.breed and effect sizes in HumDef_params={her=0.9,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n"]}]},{"cell_type":"code","source":["sh = \"\"\"\n","\n","BFILE=1000g\n","\n","for HER in {0.1,0.3,0.5,0.7,0.9}\n","\n","do\n","    for NUM in {1,10,100,1000,10000}\n","\n","    do\n","\n","        OUT=GCTA_params={her=$HER,num-causals=$NUM}\n","\n","        ./ldak5.2.linux \\\n","            --make-phenos $OUT \\\n","            --bfile $BFILE \\\n","            --ignore-weights YES \\\n","            --power -1 \\\n","            --num-phenos 100 \\\n","            --her $HER \\\n","            --num-causals $NUM\n","\n","    done\n","\n","done\n","\n","\"\"\"\n","with open('script.sh', 'w') as file:\n","  file.write(sh)\n","\n","! bash script.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"feMVc65MUWmd","executionInfo":{"status":"ok","timestamp":1709680877495,"user_tz":480,"elapsed":4552161,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"42f7a8cf-959c-439a-ddc1-e714ca224bb3"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.1,num-causals=1}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.1\n","--num-causals 1\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.1,num-causals=1}.pheno, with breeding values in GCTA_params={her=0.1,num-causals=1}.breed and effect sizes in GCTA_params={her=0.1,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.1,num-causals=10}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.1\n","--num-causals 10\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.1,num-causals=10}.pheno, with breeding values in GCTA_params={her=0.1,num-causals=10}.breed and effect sizes in GCTA_params={her=0.1,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.1,num-causals=100}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.1\n","--num-causals 100\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in GCTA_params={her=0.1,num-causals=100}.pheno, with breeding values in GCTA_params={her=0.1,num-causals=100}.breed and effect sizes in GCTA_params={her=0.1,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.1,num-causals=1000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.1\n","--num-causals 1000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in GCTA_params={her=0.1,num-causals=1000}.pheno, with breeding values in GCTA_params={her=0.1,num-causals=1000}.breed and effect sizes in GCTA_params={her=0.1,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.1,num-causals=10000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.1\n","--num-causals 10000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.1000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 469\n","Making phenotypes for Chunk 2 of 469\n","Making phenotypes for Chunk 3 of 469\n","Making phenotypes for Chunk 4 of 469\n","Making phenotypes for Chunk 5 of 469\n","Making phenotypes for Chunk 6 of 469\n","Making phenotypes for Chunk 7 of 469\n","Making phenotypes for Chunk 8 of 469\n","Making phenotypes for Chunk 9 of 469\n","Making phenotypes for Chunk 10 of 469\n","Making phenotypes for Chunk 11 of 469\n","Making phenotypes for Chunk 12 of 469\n","Making phenotypes for Chunk 13 of 469\n","Making phenotypes for Chunk 14 of 469\n","Making phenotypes for Chunk 15 of 469\n","Making phenotypes for Chunk 16 of 469\n","Making phenotypes for Chunk 17 of 469\n","Making phenotypes for Chunk 18 of 469\n","Making phenotypes for Chunk 19 of 469\n","Making phenotypes for Chunk 20 of 469\n","Making phenotypes for Chunk 21 of 469\n","Making phenotypes for Chunk 22 of 469\n","Making phenotypes for Chunk 23 of 469\n","Making phenotypes for Chunk 24 of 469\n","Making phenotypes for Chunk 25 of 469\n","Making phenotypes for Chunk 26 of 469\n","Making phenotypes for Chunk 27 of 469\n","Making phenotypes for Chunk 28 of 469\n","Making phenotypes for Chunk 29 of 469\n","Making phenotypes for Chunk 30 of 469\n","Making phenotypes for Chunk 31 of 469\n","Making phenotypes for Chunk 32 of 469\n","Making phenotypes for Chunk 33 of 469\n","Making phenotypes for Chunk 34 of 469\n","Making phenotypes for Chunk 35 of 469\n","Making phenotypes for Chunk 36 of 469\n","Making phenotypes for Chunk 37 of 469\n","Making phenotypes for Chunk 38 of 469\n","Making phenotypes for Chunk 39 of 469\n","Making phenotypes for Chunk 40 of 469\n","Making phenotypes for Chunk 41 of 469\n","Making phenotypes for Chunk 42 of 469\n","Making phenotypes for Chunk 43 of 469\n","Making phenotypes for Chunk 44 of 469\n","Making phenotypes for Chunk 45 of 469\n","Making phenotypes for Chunk 46 of 469\n","Making phenotypes for Chunk 47 of 469\n","Making phenotypes for Chunk 48 of 469\n","Making phenotypes for Chunk 49 of 469\n","Making phenotypes for Chunk 50 of 469\n","Making phenotypes for Chunk 51 of 469\n","Making phenotypes for Chunk 52 of 469\n","Making phenotypes for Chunk 53 of 469\n","Making phenotypes for Chunk 54 of 469\n","Making phenotypes for Chunk 55 of 469\n","Making phenotypes for Chunk 56 of 469\n","Making phenotypes for Chunk 57 of 469\n","Making phenotypes for Chunk 58 of 469\n","Making phenotypes for Chunk 59 of 469\n","Making phenotypes for Chunk 60 of 469\n","Making phenotypes for Chunk 61 of 469\n","Making phenotypes for Chunk 62 of 469\n","Making phenotypes for Chunk 63 of 469\n","Making phenotypes for Chunk 64 of 469\n","Making phenotypes for Chunk 65 of 469\n","Making phenotypes for Chunk 66 of 469\n","Making phenotypes for Chunk 67 of 469\n","Making phenotypes for Chunk 68 of 469\n","Making phenotypes for Chunk 69 of 469\n","Making phenotypes for Chunk 70 of 469\n","Making phenotypes for Chunk 71 of 469\n","Making phenotypes for Chunk 72 of 469\n","Making phenotypes for Chunk 73 of 469\n","Making phenotypes for Chunk 74 of 469\n","Making phenotypes for Chunk 75 of 469\n","Making phenotypes for Chunk 76 of 469\n","Making phenotypes for Chunk 77 of 469\n","Making phenotypes for Chunk 78 of 469\n","Making phenotypes for Chunk 79 of 469\n","Making phenotypes for Chunk 80 of 469\n","Making phenotypes for Chunk 81 of 469\n","Making phenotypes for Chunk 82 of 469\n","Making phenotypes for Chunk 83 of 469\n","Making phenotypes for Chunk 84 of 469\n","Making phenotypes for Chunk 85 of 469\n","Making phenotypes for Chunk 86 of 469\n","Making phenotypes for Chunk 87 of 469\n","Making phenotypes for Chunk 88 of 469\n","Making phenotypes for Chunk 89 of 469\n","Making phenotypes for Chunk 90 of 469\n","Making phenotypes for Chunk 91 of 469\n","Making phenotypes for Chunk 92 of 469\n","Making phenotypes for Chunk 93 of 469\n","Making phenotypes for Chunk 94 of 469\n","Making phenotypes for Chunk 95 of 469\n","Making phenotypes for Chunk 96 of 469\n","Making phenotypes for Chunk 97 of 469\n","Making phenotypes for Chunk 98 of 469\n","Making phenotypes for Chunk 99 of 469\n","Making phenotypes for Chunk 100 of 469\n","Making phenotypes for Chunk 101 of 469\n","Making phenotypes for Chunk 102 of 469\n","Making phenotypes for Chunk 103 of 469\n","Making phenotypes for Chunk 104 of 469\n","Making phenotypes for Chunk 105 of 469\n","Making phenotypes for Chunk 106 of 469\n","Making phenotypes for Chunk 107 of 469\n","Making phenotypes for Chunk 108 of 469\n","Making phenotypes for Chunk 109 of 469\n","Making phenotypes for Chunk 110 of 469\n","Making phenotypes for Chunk 111 of 469\n","Making phenotypes for Chunk 112 of 469\n","Making phenotypes for Chunk 113 of 469\n","Making phenotypes for Chunk 114 of 469\n","Making phenotypes for Chunk 115 of 469\n","Making phenotypes for Chunk 116 of 469\n","Making phenotypes for Chunk 117 of 469\n","Making phenotypes for Chunk 118 of 469\n","Making phenotypes for Chunk 119 of 469\n","Making phenotypes for Chunk 120 of 469\n","Making phenotypes for Chunk 121 of 469\n","Making phenotypes for Chunk 122 of 469\n","Making phenotypes for Chunk 123 of 469\n","Making phenotypes for Chunk 124 of 469\n","Making phenotypes for Chunk 125 of 469\n","Making phenotypes for Chunk 126 of 469\n","Making phenotypes for Chunk 127 of 469\n","Making phenotypes for Chunk 128 of 469\n","Making phenotypes for Chunk 129 of 469\n","Making phenotypes for Chunk 130 of 469\n","Making phenotypes for Chunk 131 of 469\n","Making phenotypes for Chunk 132 of 469\n","Making phenotypes for Chunk 133 of 469\n","Making phenotypes for Chunk 134 of 469\n","Making phenotypes for Chunk 135 of 469\n","Making phenotypes for Chunk 136 of 469\n","Making phenotypes for Chunk 137 of 469\n","Making phenotypes for Chunk 138 of 469\n","Making phenotypes for Chunk 139 of 469\n","Making phenotypes for Chunk 140 of 469\n","Making phenotypes for Chunk 141 of 469\n","Making phenotypes for Chunk 142 of 469\n","Making phenotypes for Chunk 143 of 469\n","Making phenotypes for Chunk 144 of 469\n","Making phenotypes for Chunk 145 of 469\n","Making phenotypes for Chunk 146 of 469\n","Making phenotypes for Chunk 147 of 469\n","Making phenotypes for Chunk 148 of 469\n","Making phenotypes for Chunk 149 of 469\n","Making phenotypes for Chunk 150 of 469\n","Making phenotypes for Chunk 151 of 469\n","Making phenotypes for Chunk 152 of 469\n","Making phenotypes for Chunk 153 of 469\n","Making phenotypes for Chunk 154 of 469\n","Making phenotypes for Chunk 155 of 469\n","Making phenotypes for Chunk 156 of 469\n","Making phenotypes for Chunk 157 of 469\n","Making phenotypes for Chunk 158 of 469\n","Making phenotypes for Chunk 159 of 469\n","Making phenotypes for Chunk 160 of 469\n","Making phenotypes for Chunk 161 of 469\n","Making phenotypes for Chunk 162 of 469\n","Making phenotypes for Chunk 163 of 469\n","Making phenotypes for Chunk 164 of 469\n","Making phenotypes for Chunk 165 of 469\n","Making phenotypes for Chunk 166 of 469\n","Making phenotypes for Chunk 167 of 469\n","Making phenotypes for Chunk 168 of 469\n","Making phenotypes for Chunk 169 of 469\n","Making phenotypes for Chunk 170 of 469\n","Making phenotypes for Chunk 171 of 469\n","Making phenotypes for Chunk 172 of 469\n","Making phenotypes for Chunk 173 of 469\n","Making phenotypes for Chunk 174 of 469\n","Making phenotypes for Chunk 175 of 469\n","Making phenotypes for Chunk 176 of 469\n","Making phenotypes for Chunk 177 of 469\n","Making phenotypes for Chunk 178 of 469\n","Making phenotypes for Chunk 179 of 469\n","Making phenotypes for Chunk 180 of 469\n","Making phenotypes for Chunk 181 of 469\n","Making phenotypes for Chunk 182 of 469\n","Making phenotypes for Chunk 183 of 469\n","Making phenotypes for Chunk 184 of 469\n","Making phenotypes for Chunk 185 of 469\n","Making phenotypes for Chunk 186 of 469\n","Making phenotypes for Chunk 187 of 469\n","Making phenotypes for Chunk 188 of 469\n","Making phenotypes for Chunk 189 of 469\n","Making phenotypes for Chunk 190 of 469\n","Making phenotypes for Chunk 191 of 469\n","Making phenotypes for Chunk 192 of 469\n","Making phenotypes for Chunk 193 of 469\n","Making phenotypes for Chunk 194 of 469\n","Making phenotypes for Chunk 195 of 469\n","Making phenotypes for Chunk 196 of 469\n","Making phenotypes for Chunk 197 of 469\n","Making phenotypes for Chunk 198 of 469\n","Making phenotypes for Chunk 199 of 469\n","Making phenotypes for Chunk 200 of 469\n","Making phenotypes for Chunk 201 of 469\n","Making phenotypes for Chunk 202 of 469\n","Making phenotypes for Chunk 203 of 469\n","Making phenotypes for Chunk 204 of 469\n","Making phenotypes for Chunk 205 of 469\n","Making phenotypes for Chunk 206 of 469\n","Making phenotypes for Chunk 207 of 469\n","Making phenotypes for Chunk 208 of 469\n","Making phenotypes for Chunk 209 of 469\n","Making phenotypes for Chunk 210 of 469\n","Making phenotypes for Chunk 211 of 469\n","Making phenotypes for Chunk 212 of 469\n","Making phenotypes for Chunk 213 of 469\n","Making phenotypes for Chunk 214 of 469\n","Making phenotypes for Chunk 215 of 469\n","Making phenotypes for Chunk 216 of 469\n","Making phenotypes for Chunk 217 of 469\n","Making phenotypes for Chunk 218 of 469\n","Making phenotypes for Chunk 219 of 469\n","Making phenotypes for Chunk 220 of 469\n","Making phenotypes for Chunk 221 of 469\n","Making phenotypes for Chunk 222 of 469\n","Making phenotypes for Chunk 223 of 469\n","Making phenotypes for Chunk 224 of 469\n","Making phenotypes for Chunk 225 of 469\n","Making phenotypes for Chunk 226 of 469\n","Making phenotypes for Chunk 227 of 469\n","Making phenotypes for Chunk 228 of 469\n","Making phenotypes for Chunk 229 of 469\n","Making phenotypes for Chunk 230 of 469\n","Making phenotypes for Chunk 231 of 469\n","Making phenotypes for Chunk 232 of 469\n","Making phenotypes for Chunk 233 of 469\n","Making phenotypes for Chunk 234 of 469\n","Making phenotypes for Chunk 235 of 469\n","Making phenotypes for Chunk 236 of 469\n","Making phenotypes for Chunk 237 of 469\n","Making phenotypes for Chunk 238 of 469\n","Making phenotypes for Chunk 239 of 469\n","Making phenotypes for Chunk 240 of 469\n","Making phenotypes for Chunk 241 of 469\n","Making phenotypes for Chunk 242 of 469\n","Making phenotypes for Chunk 243 of 469\n","Making phenotypes for Chunk 244 of 469\n","Making phenotypes for Chunk 245 of 469\n","Making phenotypes for Chunk 246 of 469\n","Making phenotypes for Chunk 247 of 469\n","Making phenotypes for Chunk 248 of 469\n","Making phenotypes for Chunk 249 of 469\n","Making phenotypes for Chunk 250 of 469\n","Making phenotypes for Chunk 251 of 469\n","Making phenotypes for Chunk 252 of 469\n","Making phenotypes for Chunk 253 of 469\n","Making phenotypes for Chunk 254 of 469\n","Making phenotypes for Chunk 255 of 469\n","Making phenotypes for Chunk 256 of 469\n","Making phenotypes for Chunk 257 of 469\n","Making phenotypes for Chunk 258 of 469\n","Making phenotypes for Chunk 259 of 469\n","Making phenotypes for Chunk 260 of 469\n","Making phenotypes for Chunk 261 of 469\n","Making phenotypes for Chunk 262 of 469\n","Making phenotypes for Chunk 263 of 469\n","Making phenotypes for Chunk 264 of 469\n","Making phenotypes for Chunk 265 of 469\n","Making phenotypes for Chunk 266 of 469\n","Making phenotypes for Chunk 267 of 469\n","Making phenotypes for Chunk 268 of 469\n","Making phenotypes for Chunk 269 of 469\n","Making phenotypes for Chunk 270 of 469\n","Making phenotypes for Chunk 271 of 469\n","Making phenotypes for Chunk 272 of 469\n","Making phenotypes for Chunk 273 of 469\n","Making phenotypes for Chunk 274 of 469\n","Making phenotypes for Chunk 275 of 469\n","Making phenotypes for Chunk 276 of 469\n","Making phenotypes for Chunk 277 of 469\n","Making phenotypes for Chunk 278 of 469\n","Making phenotypes for Chunk 279 of 469\n","Making phenotypes for Chunk 280 of 469\n","Making phenotypes for Chunk 281 of 469\n","Making phenotypes for Chunk 282 of 469\n","Making phenotypes for Chunk 283 of 469\n","Making phenotypes for Chunk 284 of 469\n","Making phenotypes for Chunk 285 of 469\n","Making phenotypes for Chunk 286 of 469\n","Making phenotypes for Chunk 287 of 469\n","Making phenotypes for Chunk 288 of 469\n","Making phenotypes for Chunk 289 of 469\n","Making phenotypes for Chunk 290 of 469\n","Making phenotypes for Chunk 291 of 469\n","Making phenotypes for Chunk 292 of 469\n","Making phenotypes for Chunk 293 of 469\n","Making phenotypes for Chunk 294 of 469\n","Making phenotypes for Chunk 295 of 469\n","Making phenotypes for Chunk 296 of 469\n","Making phenotypes for Chunk 297 of 469\n","Making phenotypes for Chunk 298 of 469\n","Making phenotypes for Chunk 299 of 469\n","Making phenotypes for Chunk 300 of 469\n","Making phenotypes for Chunk 301 of 469\n","Making phenotypes for Chunk 302 of 469\n","Making phenotypes for Chunk 303 of 469\n","Making phenotypes for Chunk 304 of 469\n","Making phenotypes for Chunk 305 of 469\n","Making phenotypes for Chunk 306 of 469\n","Making phenotypes for Chunk 307 of 469\n","Making phenotypes for Chunk 308 of 469\n","Making phenotypes for Chunk 309 of 469\n","Making phenotypes for Chunk 310 of 469\n","Making phenotypes for Chunk 311 of 469\n","Making phenotypes for Chunk 312 of 469\n","Making phenotypes for Chunk 313 of 469\n","Making phenotypes for Chunk 314 of 469\n","Making phenotypes for Chunk 315 of 469\n","Making phenotypes for Chunk 316 of 469\n","Making phenotypes for Chunk 317 of 469\n","Making phenotypes for Chunk 318 of 469\n","Making phenotypes for Chunk 319 of 469\n","Making phenotypes for Chunk 320 of 469\n","Making phenotypes for Chunk 321 of 469\n","Making phenotypes for Chunk 322 of 469\n","Making phenotypes for Chunk 323 of 469\n","Making phenotypes for Chunk 324 of 469\n","Making phenotypes for Chunk 325 of 469\n","Making phenotypes for Chunk 326 of 469\n","Making phenotypes for Chunk 327 of 469\n","Making phenotypes for Chunk 328 of 469\n","Making phenotypes for Chunk 329 of 469\n","Making phenotypes for Chunk 330 of 469\n","Making phenotypes for Chunk 331 of 469\n","Making phenotypes for Chunk 332 of 469\n","Making phenotypes for Chunk 333 of 469\n","Making phenotypes for Chunk 334 of 469\n","Making phenotypes for Chunk 335 of 469\n","Making phenotypes for Chunk 336 of 469\n","Making phenotypes for Chunk 337 of 469\n","Making phenotypes for Chunk 338 of 469\n","Making phenotypes for Chunk 339 of 469\n","Making phenotypes for Chunk 340 of 469\n","Making phenotypes for Chunk 341 of 469\n","Making phenotypes for Chunk 342 of 469\n","Making phenotypes for Chunk 343 of 469\n","Making phenotypes for Chunk 344 of 469\n","Making phenotypes for Chunk 345 of 469\n","Making phenotypes for Chunk 346 of 469\n","Making phenotypes for Chunk 347 of 469\n","Making phenotypes for Chunk 348 of 469\n","Making phenotypes for Chunk 349 of 469\n","Making phenotypes for Chunk 350 of 469\n","Making phenotypes for Chunk 351 of 469\n","Making phenotypes for Chunk 352 of 469\n","Making phenotypes for Chunk 353 of 469\n","Making phenotypes for Chunk 354 of 469\n","Making phenotypes for Chunk 355 of 469\n","Making phenotypes for Chunk 356 of 469\n","Making phenotypes for Chunk 357 of 469\n","Making phenotypes for Chunk 358 of 469\n","Making phenotypes for Chunk 359 of 469\n","Making phenotypes for Chunk 360 of 469\n","Making phenotypes for Chunk 361 of 469\n","Making phenotypes for Chunk 362 of 469\n","Making phenotypes for Chunk 363 of 469\n","Making phenotypes for Chunk 364 of 469\n","Making phenotypes for Chunk 365 of 469\n","Making phenotypes for Chunk 366 of 469\n","Making phenotypes for Chunk 367 of 469\n","Making phenotypes for Chunk 368 of 469\n","Making phenotypes for Chunk 369 of 469\n","Making phenotypes for Chunk 370 of 469\n","Making phenotypes for Chunk 371 of 469\n","Making phenotypes for Chunk 372 of 469\n","Making phenotypes for Chunk 373 of 469\n","Making phenotypes for Chunk 374 of 469\n","Making phenotypes for Chunk 375 of 469\n","Making phenotypes for Chunk 376 of 469\n","Making phenotypes for Chunk 377 of 469\n","Making phenotypes for Chunk 378 of 469\n","Making phenotypes for Chunk 379 of 469\n","Making phenotypes for Chunk 380 of 469\n","Making phenotypes for Chunk 381 of 469\n","Making phenotypes for Chunk 382 of 469\n","Making phenotypes for Chunk 383 of 469\n","Making phenotypes for Chunk 384 of 469\n","Making phenotypes for Chunk 385 of 469\n","Making phenotypes for Chunk 386 of 469\n","Making phenotypes for Chunk 387 of 469\n","Making phenotypes for Chunk 388 of 469\n","Making phenotypes for Chunk 389 of 469\n","Making phenotypes for Chunk 390 of 469\n","Making phenotypes for Chunk 391 of 469\n","Making phenotypes for Chunk 392 of 469\n","Making phenotypes for Chunk 393 of 469\n","Making phenotypes for Chunk 394 of 469\n","Making phenotypes for Chunk 395 of 469\n","Making phenotypes for Chunk 396 of 469\n","Making phenotypes for Chunk 397 of 469\n","Making phenotypes for Chunk 398 of 469\n","Making phenotypes for Chunk 399 of 469\n","Making phenotypes for Chunk 400 of 469\n","Making phenotypes for Chunk 401 of 469\n","Making phenotypes for Chunk 402 of 469\n","Making phenotypes for Chunk 403 of 469\n","Making phenotypes for Chunk 404 of 469\n","Making phenotypes for Chunk 405 of 469\n","Making phenotypes for Chunk 406 of 469\n","Making phenotypes for Chunk 407 of 469\n","Making phenotypes for Chunk 408 of 469\n","Making phenotypes for Chunk 409 of 469\n","Making phenotypes for Chunk 410 of 469\n","Making phenotypes for Chunk 411 of 469\n","Making phenotypes for Chunk 412 of 469\n","Making phenotypes for Chunk 413 of 469\n","Making phenotypes for Chunk 414 of 469\n","Making phenotypes for Chunk 415 of 469\n","Making phenotypes for Chunk 416 of 469\n","Making phenotypes for Chunk 417 of 469\n","Making phenotypes for Chunk 418 of 469\n","Making phenotypes for Chunk 419 of 469\n","Making phenotypes for Chunk 420 of 469\n","Making phenotypes for Chunk 421 of 469\n","Making phenotypes for Chunk 422 of 469\n","Making phenotypes for Chunk 423 of 469\n","Making phenotypes for Chunk 424 of 469\n","Making phenotypes for Chunk 425 of 469\n","Making phenotypes for Chunk 426 of 469\n","Making phenotypes for Chunk 427 of 469\n","Making phenotypes for Chunk 428 of 469\n","Making phenotypes for Chunk 429 of 469\n","Making phenotypes for Chunk 430 of 469\n","Making phenotypes for Chunk 431 of 469\n","Making phenotypes for Chunk 432 of 469\n","Making phenotypes for Chunk 433 of 469\n","Making phenotypes for Chunk 434 of 469\n","Making phenotypes for Chunk 435 of 469\n","Making phenotypes for Chunk 436 of 469\n","Making phenotypes for Chunk 437 of 469\n","Making phenotypes for Chunk 438 of 469\n","Making phenotypes for Chunk 439 of 469\n","Making phenotypes for Chunk 440 of 469\n","Making phenotypes for Chunk 441 of 469\n","Making phenotypes for Chunk 442 of 469\n","Making phenotypes for Chunk 443 of 469\n","Making phenotypes for Chunk 444 of 469\n","Making phenotypes for Chunk 445 of 469\n","Making phenotypes for Chunk 446 of 469\n","Making phenotypes for Chunk 447 of 469\n","Making phenotypes for Chunk 448 of 469\n","Making phenotypes for Chunk 449 of 469\n","Making phenotypes for Chunk 450 of 469\n","Making phenotypes for Chunk 451 of 469\n","Making phenotypes for Chunk 452 of 469\n","Making phenotypes for Chunk 453 of 469\n","Making phenotypes for Chunk 454 of 469\n","Making phenotypes for Chunk 455 of 469\n","Making phenotypes for Chunk 456 of 469\n","Making phenotypes for Chunk 457 of 469\n","Making phenotypes for Chunk 458 of 469\n","Making phenotypes for Chunk 459 of 469\n","Making phenotypes for Chunk 460 of 469\n","Making phenotypes for Chunk 461 of 469\n","Making phenotypes for Chunk 462 of 469\n","Making phenotypes for Chunk 463 of 469\n","Making phenotypes for Chunk 464 of 469\n","Making phenotypes for Chunk 465 of 469\n","Making phenotypes for Chunk 466 of 469\n","Making phenotypes for Chunk 467 of 469\n","Making phenotypes for Chunk 468 of 469\n","Making phenotypes for Chunk 469 of 469\n","\n","Phenotypes saved in GCTA_params={her=0.1,num-causals=10000}.pheno, with breeding values in GCTA_params={her=0.1,num-causals=10000}.breed and effect sizes in GCTA_params={her=0.1,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.3,num-causals=1}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.3\n","--num-causals 1\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.3,num-causals=1}.pheno, with breeding values in GCTA_params={her=0.3,num-causals=1}.breed and effect sizes in GCTA_params={her=0.3,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.3,num-causals=10}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.3\n","--num-causals 10\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.3,num-causals=10}.pheno, with breeding values in GCTA_params={her=0.3,num-causals=10}.breed and effect sizes in GCTA_params={her=0.3,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.3,num-causals=100}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.3\n","--num-causals 100\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in GCTA_params={her=0.3,num-causals=100}.pheno, with breeding values in GCTA_params={her=0.3,num-causals=100}.breed and effect sizes in GCTA_params={her=0.3,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.3,num-causals=1000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.3\n","--num-causals 1000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Warning, Predictor 2:91799813 is trivial (takes at most one non-missing value) and will be ignored\n","\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in GCTA_params={her=0.3,num-causals=1000}.pheno, with breeding values in GCTA_params={her=0.3,num-causals=1000}.breed and effect sizes in GCTA_params={her=0.3,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.3,num-causals=10000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.3\n","--num-causals 10000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.3000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 470\n","Making phenotypes for Chunk 2 of 470\n","Making phenotypes for Chunk 3 of 470\n","Making phenotypes for Chunk 4 of 470\n","Making phenotypes for Chunk 5 of 470\n","Making phenotypes for Chunk 6 of 470\n","Making phenotypes for Chunk 7 of 470\n","Making phenotypes for Chunk 8 of 470\n","Making phenotypes for Chunk 9 of 470\n","Making phenotypes for Chunk 10 of 470\n","Making phenotypes for Chunk 11 of 470\n","Making phenotypes for Chunk 12 of 470\n","Making phenotypes for Chunk 13 of 470\n","Making phenotypes for Chunk 14 of 470\n","Making phenotypes for Chunk 15 of 470\n","Making phenotypes for Chunk 16 of 470\n","Making phenotypes for Chunk 17 of 470\n","Making phenotypes for Chunk 18 of 470\n","Making phenotypes for Chunk 19 of 470\n","Making phenotypes for Chunk 20 of 470\n","Making phenotypes for Chunk 21 of 470\n","Making phenotypes for Chunk 22 of 470\n","Making phenotypes for Chunk 23 of 470\n","Making phenotypes for Chunk 24 of 470\n","Making phenotypes for Chunk 25 of 470\n","Making phenotypes for Chunk 26 of 470\n","Making phenotypes for Chunk 27 of 470\n","Making phenotypes for Chunk 28 of 470\n","Making phenotypes for Chunk 29 of 470\n","Making phenotypes for Chunk 30 of 470\n","Making phenotypes for Chunk 31 of 470\n","Making phenotypes for Chunk 32 of 470\n","Making phenotypes for Chunk 33 of 470\n","Making phenotypes for Chunk 34 of 470\n","Making phenotypes for Chunk 35 of 470\n","Making phenotypes for Chunk 36 of 470\n","Making phenotypes for Chunk 37 of 470\n","Making phenotypes for Chunk 38 of 470\n","Making phenotypes for Chunk 39 of 470\n","Making phenotypes for Chunk 40 of 470\n","Making phenotypes for Chunk 41 of 470\n","Making phenotypes for Chunk 42 of 470\n","Making phenotypes for Chunk 43 of 470\n","Making phenotypes for Chunk 44 of 470\n","Making phenotypes for Chunk 45 of 470\n","Making phenotypes for Chunk 46 of 470\n","Making phenotypes for Chunk 47 of 470\n","Making phenotypes for Chunk 48 of 470\n","Making phenotypes for Chunk 49 of 470\n","Making phenotypes for Chunk 50 of 470\n","Making phenotypes for Chunk 51 of 470\n","Making phenotypes for Chunk 52 of 470\n","Making phenotypes for Chunk 53 of 470\n","Making phenotypes for Chunk 54 of 470\n","Making phenotypes for Chunk 55 of 470\n","Making phenotypes for Chunk 56 of 470\n","Making phenotypes for Chunk 57 of 470\n","Making phenotypes for Chunk 58 of 470\n","Making phenotypes for Chunk 59 of 470\n","Making phenotypes for Chunk 60 of 470\n","Making phenotypes for Chunk 61 of 470\n","Making phenotypes for Chunk 62 of 470\n","Making phenotypes for Chunk 63 of 470\n","Making phenotypes for Chunk 64 of 470\n","Making phenotypes for Chunk 65 of 470\n","Making phenotypes for Chunk 66 of 470\n","Making phenotypes for Chunk 67 of 470\n","Making phenotypes for Chunk 68 of 470\n","Making phenotypes for Chunk 69 of 470\n","Making phenotypes for Chunk 70 of 470\n","Making phenotypes for Chunk 71 of 470\n","Making phenotypes for Chunk 72 of 470\n","Making phenotypes for Chunk 73 of 470\n","Making phenotypes for Chunk 74 of 470\n","Making phenotypes for Chunk 75 of 470\n","Making phenotypes for Chunk 76 of 470\n","Making phenotypes for Chunk 77 of 470\n","Making phenotypes for Chunk 78 of 470\n","Making phenotypes for Chunk 79 of 470\n","Making phenotypes for Chunk 80 of 470\n","Making phenotypes for Chunk 81 of 470\n","Making phenotypes for Chunk 82 of 470\n","Making phenotypes for Chunk 83 of 470\n","Making phenotypes for Chunk 84 of 470\n","Making phenotypes for Chunk 85 of 470\n","Making phenotypes for Chunk 86 of 470\n","Making phenotypes for Chunk 87 of 470\n","Making phenotypes for Chunk 88 of 470\n","Making phenotypes for Chunk 89 of 470\n","Making phenotypes for Chunk 90 of 470\n","Making phenotypes for Chunk 91 of 470\n","Making phenotypes for Chunk 92 of 470\n","Making phenotypes for Chunk 93 of 470\n","Making phenotypes for Chunk 94 of 470\n","Making phenotypes for Chunk 95 of 470\n","Making phenotypes for Chunk 96 of 470\n","Making phenotypes for Chunk 97 of 470\n","Making phenotypes for Chunk 98 of 470\n","Making phenotypes for Chunk 99 of 470\n","Making phenotypes for Chunk 100 of 470\n","Making phenotypes for Chunk 101 of 470\n","Making phenotypes for Chunk 102 of 470\n","Making phenotypes for Chunk 103 of 470\n","Making phenotypes for Chunk 104 of 470\n","Making phenotypes for Chunk 105 of 470\n","Making phenotypes for Chunk 106 of 470\n","Making phenotypes for Chunk 107 of 470\n","Making phenotypes for Chunk 108 of 470\n","Making phenotypes for Chunk 109 of 470\n","Making phenotypes for Chunk 110 of 470\n","Making phenotypes for Chunk 111 of 470\n","Making phenotypes for Chunk 112 of 470\n","Making phenotypes for Chunk 113 of 470\n","Making phenotypes for Chunk 114 of 470\n","Making phenotypes for Chunk 115 of 470\n","Making phenotypes for Chunk 116 of 470\n","Making phenotypes for Chunk 117 of 470\n","Making phenotypes for Chunk 118 of 470\n","Making phenotypes for Chunk 119 of 470\n","Making phenotypes for Chunk 120 of 470\n","Making phenotypes for Chunk 121 of 470\n","Making phenotypes for Chunk 122 of 470\n","Making phenotypes for Chunk 123 of 470\n","Making phenotypes for Chunk 124 of 470\n","Making phenotypes for Chunk 125 of 470\n","Making phenotypes for Chunk 126 of 470\n","Making phenotypes for Chunk 127 of 470\n","Making phenotypes for Chunk 128 of 470\n","Making phenotypes for Chunk 129 of 470\n","Making phenotypes for Chunk 130 of 470\n","Making phenotypes for Chunk 131 of 470\n","Making phenotypes for Chunk 132 of 470\n","Making phenotypes for Chunk 133 of 470\n","Making phenotypes for Chunk 134 of 470\n","Making phenotypes for Chunk 135 of 470\n","Making phenotypes for Chunk 136 of 470\n","Making phenotypes for Chunk 137 of 470\n","Making phenotypes for Chunk 138 of 470\n","Making phenotypes for Chunk 139 of 470\n","Making phenotypes for Chunk 140 of 470\n","Making phenotypes for Chunk 141 of 470\n","Making phenotypes for Chunk 142 of 470\n","Making phenotypes for Chunk 143 of 470\n","Making phenotypes for Chunk 144 of 470\n","Making phenotypes for Chunk 145 of 470\n","Making phenotypes for Chunk 146 of 470\n","Making phenotypes for Chunk 147 of 470\n","Making phenotypes for Chunk 148 of 470\n","Making phenotypes for Chunk 149 of 470\n","Making phenotypes for Chunk 150 of 470\n","Making phenotypes for Chunk 151 of 470\n","Making phenotypes for Chunk 152 of 470\n","Making phenotypes for Chunk 153 of 470\n","Making phenotypes for Chunk 154 of 470\n","Making phenotypes for Chunk 155 of 470\n","Making phenotypes for Chunk 156 of 470\n","Making phenotypes for Chunk 157 of 470\n","Making phenotypes for Chunk 158 of 470\n","Making phenotypes for Chunk 159 of 470\n","Making phenotypes for Chunk 160 of 470\n","Making phenotypes for Chunk 161 of 470\n","Making phenotypes for Chunk 162 of 470\n","Making phenotypes for Chunk 163 of 470\n","Making phenotypes for Chunk 164 of 470\n","Making phenotypes for Chunk 165 of 470\n","Making phenotypes for Chunk 166 of 470\n","Making phenotypes for Chunk 167 of 470\n","Making phenotypes for Chunk 168 of 470\n","Making phenotypes for Chunk 169 of 470\n","Making phenotypes for Chunk 170 of 470\n","Making phenotypes for Chunk 171 of 470\n","Making phenotypes for Chunk 172 of 470\n","Making phenotypes for Chunk 173 of 470\n","Making phenotypes for Chunk 174 of 470\n","Making phenotypes for Chunk 175 of 470\n","Making phenotypes for Chunk 176 of 470\n","Making phenotypes for Chunk 177 of 470\n","Making phenotypes for Chunk 178 of 470\n","Making phenotypes for Chunk 179 of 470\n","Making phenotypes for Chunk 180 of 470\n","Making phenotypes for Chunk 181 of 470\n","Making phenotypes for Chunk 182 of 470\n","Making phenotypes for Chunk 183 of 470\n","Making phenotypes for Chunk 184 of 470\n","Making phenotypes for Chunk 185 of 470\n","Making phenotypes for Chunk 186 of 470\n","Making phenotypes for Chunk 187 of 470\n","Making phenotypes for Chunk 188 of 470\n","Making phenotypes for Chunk 189 of 470\n","Making phenotypes for Chunk 190 of 470\n","Making phenotypes for Chunk 191 of 470\n","Making phenotypes for Chunk 192 of 470\n","Making phenotypes for Chunk 193 of 470\n","Making phenotypes for Chunk 194 of 470\n","Making phenotypes for Chunk 195 of 470\n","Making phenotypes for Chunk 196 of 470\n","Making phenotypes for Chunk 197 of 470\n","Making phenotypes for Chunk 198 of 470\n","Making phenotypes for Chunk 199 of 470\n","Making phenotypes for Chunk 200 of 470\n","Making phenotypes for Chunk 201 of 470\n","Making phenotypes for Chunk 202 of 470\n","Making phenotypes for Chunk 203 of 470\n","Making phenotypes for Chunk 204 of 470\n","Making phenotypes for Chunk 205 of 470\n","Making phenotypes for Chunk 206 of 470\n","Making phenotypes for Chunk 207 of 470\n","Making phenotypes for Chunk 208 of 470\n","Making phenotypes for Chunk 209 of 470\n","Making phenotypes for Chunk 210 of 470\n","Making phenotypes for Chunk 211 of 470\n","Making phenotypes for Chunk 212 of 470\n","Making phenotypes for Chunk 213 of 470\n","Making phenotypes for Chunk 214 of 470\n","Making phenotypes for Chunk 215 of 470\n","Making phenotypes for Chunk 216 of 470\n","Making phenotypes for Chunk 217 of 470\n","Making phenotypes for Chunk 218 of 470\n","Making phenotypes for Chunk 219 of 470\n","Making phenotypes for Chunk 220 of 470\n","Making phenotypes for Chunk 221 of 470\n","Making phenotypes for Chunk 222 of 470\n","Making phenotypes for Chunk 223 of 470\n","Making phenotypes for Chunk 224 of 470\n","Making phenotypes for Chunk 225 of 470\n","Making phenotypes for Chunk 226 of 470\n","Making phenotypes for Chunk 227 of 470\n","Making phenotypes for Chunk 228 of 470\n","Making phenotypes for Chunk 229 of 470\n","Making phenotypes for Chunk 230 of 470\n","Making phenotypes for Chunk 231 of 470\n","Making phenotypes for Chunk 232 of 470\n","Making phenotypes for Chunk 233 of 470\n","Making phenotypes for Chunk 234 of 470\n","Making phenotypes for Chunk 235 of 470\n","Making phenotypes for Chunk 236 of 470\n","Making phenotypes for Chunk 237 of 470\n","Making phenotypes for Chunk 238 of 470\n","Making phenotypes for Chunk 239 of 470\n","Making phenotypes for Chunk 240 of 470\n","Making phenotypes for Chunk 241 of 470\n","Making phenotypes for Chunk 242 of 470\n","Making phenotypes for Chunk 243 of 470\n","Making phenotypes for Chunk 244 of 470\n","Making phenotypes for Chunk 245 of 470\n","Making phenotypes for Chunk 246 of 470\n","Making phenotypes for Chunk 247 of 470\n","Making phenotypes for Chunk 248 of 470\n","Making phenotypes for Chunk 249 of 470\n","Making phenotypes for Chunk 250 of 470\n","Making phenotypes for Chunk 251 of 470\n","Making phenotypes for Chunk 252 of 470\n","Making phenotypes for Chunk 253 of 470\n","Making phenotypes for Chunk 254 of 470\n","Making phenotypes for Chunk 255 of 470\n","Making phenotypes for Chunk 256 of 470\n","Making phenotypes for Chunk 257 of 470\n","Making phenotypes for Chunk 258 of 470\n","Making phenotypes for Chunk 259 of 470\n","Making phenotypes for Chunk 260 of 470\n","Making phenotypes for Chunk 261 of 470\n","Making phenotypes for Chunk 262 of 470\n","Making phenotypes for Chunk 263 of 470\n","Making phenotypes for Chunk 264 of 470\n","Making phenotypes for Chunk 265 of 470\n","Making phenotypes for Chunk 266 of 470\n","Making phenotypes for Chunk 267 of 470\n","Making phenotypes for Chunk 268 of 470\n","Making phenotypes for Chunk 269 of 470\n","Making phenotypes for Chunk 270 of 470\n","Making phenotypes for Chunk 271 of 470\n","Making phenotypes for Chunk 272 of 470\n","Making phenotypes for Chunk 273 of 470\n","Making phenotypes for Chunk 274 of 470\n","Making phenotypes for Chunk 275 of 470\n","Making phenotypes for Chunk 276 of 470\n","Making phenotypes for Chunk 277 of 470\n","Making phenotypes for Chunk 278 of 470\n","Making phenotypes for Chunk 279 of 470\n","Making phenotypes for Chunk 280 of 470\n","Making phenotypes for Chunk 281 of 470\n","Making phenotypes for Chunk 282 of 470\n","Making phenotypes for Chunk 283 of 470\n","Making phenotypes for Chunk 284 of 470\n","Making phenotypes for Chunk 285 of 470\n","Making phenotypes for Chunk 286 of 470\n","Making phenotypes for Chunk 287 of 470\n","Making phenotypes for Chunk 288 of 470\n","Making phenotypes for Chunk 289 of 470\n","Making phenotypes for Chunk 290 of 470\n","Making phenotypes for Chunk 291 of 470\n","Making phenotypes for Chunk 292 of 470\n","Making phenotypes for Chunk 293 of 470\n","Making phenotypes for Chunk 294 of 470\n","Making phenotypes for Chunk 295 of 470\n","Making phenotypes for Chunk 296 of 470\n","Making phenotypes for Chunk 297 of 470\n","Making phenotypes for Chunk 298 of 470\n","Making phenotypes for Chunk 299 of 470\n","Making phenotypes for Chunk 300 of 470\n","Making phenotypes for Chunk 301 of 470\n","Making phenotypes for Chunk 302 of 470\n","Making phenotypes for Chunk 303 of 470\n","Making phenotypes for Chunk 304 of 470\n","Making phenotypes for Chunk 305 of 470\n","Making phenotypes for Chunk 306 of 470\n","Making phenotypes for Chunk 307 of 470\n","Making phenotypes for Chunk 308 of 470\n","Making phenotypes for Chunk 309 of 470\n","Making phenotypes for Chunk 310 of 470\n","Making phenotypes for Chunk 311 of 470\n","Making phenotypes for Chunk 312 of 470\n","Making phenotypes for Chunk 313 of 470\n","Making phenotypes for Chunk 314 of 470\n","Making phenotypes for Chunk 315 of 470\n","Making phenotypes for Chunk 316 of 470\n","Making phenotypes for Chunk 317 of 470\n","Making phenotypes for Chunk 318 of 470\n","Making phenotypes for Chunk 319 of 470\n","Making phenotypes for Chunk 320 of 470\n","Making phenotypes for Chunk 321 of 470\n","Making phenotypes for Chunk 322 of 470\n","Making phenotypes for Chunk 323 of 470\n","Making phenotypes for Chunk 324 of 470\n","Making phenotypes for Chunk 325 of 470\n","Making phenotypes for Chunk 326 of 470\n","Making phenotypes for Chunk 327 of 470\n","Making phenotypes for Chunk 328 of 470\n","Making phenotypes for Chunk 329 of 470\n","Making phenotypes for Chunk 330 of 470\n","Making phenotypes for Chunk 331 of 470\n","Making phenotypes for Chunk 332 of 470\n","Making phenotypes for Chunk 333 of 470\n","Making phenotypes for Chunk 334 of 470\n","Making phenotypes for Chunk 335 of 470\n","Making phenotypes for Chunk 336 of 470\n","Making phenotypes for Chunk 337 of 470\n","Making phenotypes for Chunk 338 of 470\n","Making phenotypes for Chunk 339 of 470\n","Making phenotypes for Chunk 340 of 470\n","Making phenotypes for Chunk 341 of 470\n","Making phenotypes for Chunk 342 of 470\n","Making phenotypes for Chunk 343 of 470\n","Making phenotypes for Chunk 344 of 470\n","Making phenotypes for Chunk 345 of 470\n","Making phenotypes for Chunk 346 of 470\n","Making phenotypes for Chunk 347 of 470\n","Making phenotypes for Chunk 348 of 470\n","Making phenotypes for Chunk 349 of 470\n","Making phenotypes for Chunk 350 of 470\n","Making phenotypes for Chunk 351 of 470\n","Making phenotypes for Chunk 352 of 470\n","Making phenotypes for Chunk 353 of 470\n","Making phenotypes for Chunk 354 of 470\n","Making phenotypes for Chunk 355 of 470\n","Making phenotypes for Chunk 356 of 470\n","Making phenotypes for Chunk 357 of 470\n","Making phenotypes for Chunk 358 of 470\n","Making phenotypes for Chunk 359 of 470\n","Making phenotypes for Chunk 360 of 470\n","Making phenotypes for Chunk 361 of 470\n","Making phenotypes for Chunk 362 of 470\n","Making phenotypes for Chunk 363 of 470\n","Making phenotypes for Chunk 364 of 470\n","Making phenotypes for Chunk 365 of 470\n","Making phenotypes for Chunk 366 of 470\n","Making phenotypes for Chunk 367 of 470\n","Making phenotypes for Chunk 368 of 470\n","Making phenotypes for Chunk 369 of 470\n","Making phenotypes for Chunk 370 of 470\n","Making phenotypes for Chunk 371 of 470\n","Making phenotypes for Chunk 372 of 470\n","Making phenotypes for Chunk 373 of 470\n","Making phenotypes for Chunk 374 of 470\n","Making phenotypes for Chunk 375 of 470\n","Making phenotypes for Chunk 376 of 470\n","Making phenotypes for Chunk 377 of 470\n","Making phenotypes for Chunk 378 of 470\n","Making phenotypes for Chunk 379 of 470\n","Making phenotypes for Chunk 380 of 470\n","Making phenotypes for Chunk 381 of 470\n","Making phenotypes for Chunk 382 of 470\n","Making phenotypes for Chunk 383 of 470\n","Making phenotypes for Chunk 384 of 470\n","Making phenotypes for Chunk 385 of 470\n","Making phenotypes for Chunk 386 of 470\n","Making phenotypes for Chunk 387 of 470\n","Making phenotypes for Chunk 388 of 470\n","Making phenotypes for Chunk 389 of 470\n","Making phenotypes for Chunk 390 of 470\n","Making phenotypes for Chunk 391 of 470\n","Making phenotypes for Chunk 392 of 470\n","Making phenotypes for Chunk 393 of 470\n","Making phenotypes for Chunk 394 of 470\n","Making phenotypes for Chunk 395 of 470\n","Making phenotypes for Chunk 396 of 470\n","Making phenotypes for Chunk 397 of 470\n","Making phenotypes for Chunk 398 of 470\n","Making phenotypes for Chunk 399 of 470\n","Making phenotypes for Chunk 400 of 470\n","Making phenotypes for Chunk 401 of 470\n","Making phenotypes for Chunk 402 of 470\n","Making phenotypes for Chunk 403 of 470\n","Making phenotypes for Chunk 404 of 470\n","Making phenotypes for Chunk 405 of 470\n","Making phenotypes for Chunk 406 of 470\n","Making phenotypes for Chunk 407 of 470\n","Making phenotypes for Chunk 408 of 470\n","Making phenotypes for Chunk 409 of 470\n","Making phenotypes for Chunk 410 of 470\n","Making phenotypes for Chunk 411 of 470\n","Making phenotypes for Chunk 412 of 470\n","Making phenotypes for Chunk 413 of 470\n","Making phenotypes for Chunk 414 of 470\n","Making phenotypes for Chunk 415 of 470\n","Making phenotypes for Chunk 416 of 470\n","Making phenotypes for Chunk 417 of 470\n","Making phenotypes for Chunk 418 of 470\n","Making phenotypes for Chunk 419 of 470\n","Making phenotypes for Chunk 420 of 470\n","Making phenotypes for Chunk 421 of 470\n","Making phenotypes for Chunk 422 of 470\n","Making phenotypes for Chunk 423 of 470\n","Making phenotypes for Chunk 424 of 470\n","Making phenotypes for Chunk 425 of 470\n","Making phenotypes for Chunk 426 of 470\n","Making phenotypes for Chunk 427 of 470\n","Making phenotypes for Chunk 428 of 470\n","Making phenotypes for Chunk 429 of 470\n","Making phenotypes for Chunk 430 of 470\n","Making phenotypes for Chunk 431 of 470\n","Making phenotypes for Chunk 432 of 470\n","Making phenotypes for Chunk 433 of 470\n","Making phenotypes for Chunk 434 of 470\n","Making phenotypes for Chunk 435 of 470\n","Making phenotypes for Chunk 436 of 470\n","Making phenotypes for Chunk 437 of 470\n","Making phenotypes for Chunk 438 of 470\n","Making phenotypes for Chunk 439 of 470\n","Making phenotypes for Chunk 440 of 470\n","Making phenotypes for Chunk 441 of 470\n","Making phenotypes for Chunk 442 of 470\n","Making phenotypes for Chunk 443 of 470\n","Making phenotypes for Chunk 444 of 470\n","Making phenotypes for Chunk 445 of 470\n","Making phenotypes for Chunk 446 of 470\n","Making phenotypes for Chunk 447 of 470\n","Making phenotypes for Chunk 448 of 470\n","Making phenotypes for Chunk 449 of 470\n","Making phenotypes for Chunk 450 of 470\n","Making phenotypes for Chunk 451 of 470\n","Making phenotypes for Chunk 452 of 470\n","Making phenotypes for Chunk 453 of 470\n","Making phenotypes for Chunk 454 of 470\n","Making phenotypes for Chunk 455 of 470\n","Making phenotypes for Chunk 456 of 470\n","Making phenotypes for Chunk 457 of 470\n","Making phenotypes for Chunk 458 of 470\n","Making phenotypes for Chunk 459 of 470\n","Making phenotypes for Chunk 460 of 470\n","Making phenotypes for Chunk 461 of 470\n","Making phenotypes for Chunk 462 of 470\n","Making phenotypes for Chunk 463 of 470\n","Making phenotypes for Chunk 464 of 470\n","Making phenotypes for Chunk 465 of 470\n","Making phenotypes for Chunk 466 of 470\n","Making phenotypes for Chunk 467 of 470\n","Making phenotypes for Chunk 468 of 470\n","Making phenotypes for Chunk 469 of 470\n","Making phenotypes for Chunk 470 of 470\n","\n","Phenotypes saved in GCTA_params={her=0.3,num-causals=10000}.pheno, with breeding values in GCTA_params={her=0.3,num-causals=10000}.breed and effect sizes in GCTA_params={her=0.3,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.5,num-causals=1}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.5\n","--num-causals 1\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.5,num-causals=1}.pheno, with breeding values in GCTA_params={her=0.5,num-causals=1}.breed and effect sizes in GCTA_params={her=0.5,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.5,num-causals=10}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.5\n","--num-causals 10\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.5,num-causals=10}.pheno, with breeding values in GCTA_params={her=0.5,num-causals=10}.breed and effect sizes in GCTA_params={her=0.5,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.5,num-causals=100}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.5\n","--num-causals 100\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in GCTA_params={her=0.5,num-causals=100}.pheno, with breeding values in GCTA_params={her=0.5,num-causals=100}.breed and effect sizes in GCTA_params={her=0.5,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.5,num-causals=1000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.5\n","--num-causals 1000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in GCTA_params={her=0.5,num-causals=1000}.pheno, with breeding values in GCTA_params={her=0.5,num-causals=1000}.breed and effect sizes in GCTA_params={her=0.5,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.5,num-causals=10000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.5\n","--num-causals 10000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.5000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 470\n","Making phenotypes for Chunk 2 of 470\n","Making phenotypes for Chunk 3 of 470\n","Making phenotypes for Chunk 4 of 470\n","Making phenotypes for Chunk 5 of 470\n","Making phenotypes for Chunk 6 of 470\n","Making phenotypes for Chunk 7 of 470\n","Making phenotypes for Chunk 8 of 470\n","Making phenotypes for Chunk 9 of 470\n","Making phenotypes for Chunk 10 of 470\n","Making phenotypes for Chunk 11 of 470\n","Making phenotypes for Chunk 12 of 470\n","Making phenotypes for Chunk 13 of 470\n","Making phenotypes for Chunk 14 of 470\n","Making phenotypes for Chunk 15 of 470\n","Making phenotypes for Chunk 16 of 470\n","Making phenotypes for Chunk 17 of 470\n","Making phenotypes for Chunk 18 of 470\n","Making phenotypes for Chunk 19 of 470\n","Making phenotypes for Chunk 20 of 470\n","Making phenotypes for Chunk 21 of 470\n","Making phenotypes for Chunk 22 of 470\n","Making phenotypes for Chunk 23 of 470\n","Making phenotypes for Chunk 24 of 470\n","Making phenotypes for Chunk 25 of 470\n","Making phenotypes for Chunk 26 of 470\n","Making phenotypes for Chunk 27 of 470\n","Making phenotypes for Chunk 28 of 470\n","Making phenotypes for Chunk 29 of 470\n","Making phenotypes for Chunk 30 of 470\n","Making phenotypes for Chunk 31 of 470\n","Making phenotypes for Chunk 32 of 470\n","Making phenotypes for Chunk 33 of 470\n","Making phenotypes for Chunk 34 of 470\n","Making phenotypes for Chunk 35 of 470\n","Making phenotypes for Chunk 36 of 470\n","Making phenotypes for Chunk 37 of 470\n","Making phenotypes for Chunk 38 of 470\n","Making phenotypes for Chunk 39 of 470\n","Making phenotypes for Chunk 40 of 470\n","Making phenotypes for Chunk 41 of 470\n","Making phenotypes for Chunk 42 of 470\n","Making phenotypes for Chunk 43 of 470\n","Making phenotypes for Chunk 44 of 470\n","Making phenotypes for Chunk 45 of 470\n","Making phenotypes for Chunk 46 of 470\n","Making phenotypes for Chunk 47 of 470\n","Making phenotypes for Chunk 48 of 470\n","Making phenotypes for Chunk 49 of 470\n","Making phenotypes for Chunk 50 of 470\n","Making phenotypes for Chunk 51 of 470\n","Making phenotypes for Chunk 52 of 470\n","Making phenotypes for Chunk 53 of 470\n","Warning, Predictor 2:91795325 is trivial (takes at most one non-missing value) and will be ignored\n","Warning, Predictor 2:91819253 is trivial (takes at most one non-missing value) and will be ignored\n","\n","Making phenotypes for Chunk 54 of 470\n","Making phenotypes for Chunk 55 of 470\n","Making phenotypes for Chunk 56 of 470\n","Making phenotypes for Chunk 57 of 470\n","Making phenotypes for Chunk 58 of 470\n","Making phenotypes for Chunk 59 of 470\n","Making phenotypes for Chunk 60 of 470\n","Making phenotypes for Chunk 61 of 470\n","Making phenotypes for Chunk 62 of 470\n","Making phenotypes for Chunk 63 of 470\n","Making phenotypes for Chunk 64 of 470\n","Making phenotypes for Chunk 65 of 470\n","Making phenotypes for Chunk 66 of 470\n","Making phenotypes for Chunk 67 of 470\n","Making phenotypes for Chunk 68 of 470\n","Making phenotypes for Chunk 69 of 470\n","Making phenotypes for Chunk 70 of 470\n","Making phenotypes for Chunk 71 of 470\n","Making phenotypes for Chunk 72 of 470\n","Making phenotypes for Chunk 73 of 470\n","Making phenotypes for Chunk 74 of 470\n","Making phenotypes for Chunk 75 of 470\n","Making phenotypes for Chunk 76 of 470\n","Making phenotypes for Chunk 77 of 470\n","Making phenotypes for Chunk 78 of 470\n","Making phenotypes for Chunk 79 of 470\n","Making phenotypes for Chunk 80 of 470\n","Making phenotypes for Chunk 81 of 470\n","Making phenotypes for Chunk 82 of 470\n","Making phenotypes for Chunk 83 of 470\n","Making phenotypes for Chunk 84 of 470\n","Making phenotypes for Chunk 85 of 470\n","Making phenotypes for Chunk 86 of 470\n","Making phenotypes for Chunk 87 of 470\n","Making phenotypes for Chunk 88 of 470\n","Making phenotypes for Chunk 89 of 470\n","Making phenotypes for Chunk 90 of 470\n","Making phenotypes for Chunk 91 of 470\n","Making phenotypes for Chunk 92 of 470\n","Making phenotypes for Chunk 93 of 470\n","Making phenotypes for Chunk 94 of 470\n","Making phenotypes for Chunk 95 of 470\n","Making phenotypes for Chunk 96 of 470\n","Making phenotypes for Chunk 97 of 470\n","Making phenotypes for Chunk 98 of 470\n","Making phenotypes for Chunk 99 of 470\n","Making phenotypes for Chunk 100 of 470\n","Making phenotypes for Chunk 101 of 470\n","Making phenotypes for Chunk 102 of 470\n","Making phenotypes for Chunk 103 of 470\n","Making phenotypes for Chunk 104 of 470\n","Making phenotypes for Chunk 105 of 470\n","Making phenotypes for Chunk 106 of 470\n","Making phenotypes for Chunk 107 of 470\n","Making phenotypes for Chunk 108 of 470\n","Making phenotypes for Chunk 109 of 470\n","Making phenotypes for Chunk 110 of 470\n","Making phenotypes for Chunk 111 of 470\n","Making phenotypes for Chunk 112 of 470\n","Making phenotypes for Chunk 113 of 470\n","Making phenotypes for Chunk 114 of 470\n","Making phenotypes for Chunk 115 of 470\n","Making phenotypes for Chunk 116 of 470\n","Making phenotypes for Chunk 117 of 470\n","Making phenotypes for Chunk 118 of 470\n","Making phenotypes for Chunk 119 of 470\n","Making phenotypes for Chunk 120 of 470\n","Making phenotypes for Chunk 121 of 470\n","Making phenotypes for Chunk 122 of 470\n","Making phenotypes for Chunk 123 of 470\n","Making phenotypes for Chunk 124 of 470\n","Making phenotypes for Chunk 125 of 470\n","Making phenotypes for Chunk 126 of 470\n","Making phenotypes for Chunk 127 of 470\n","Making phenotypes for Chunk 128 of 470\n","Making phenotypes for Chunk 129 of 470\n","Making phenotypes for Chunk 130 of 470\n","Making phenotypes for Chunk 131 of 470\n","Making phenotypes for Chunk 132 of 470\n","Making phenotypes for Chunk 133 of 470\n","Making phenotypes for Chunk 134 of 470\n","Making phenotypes for Chunk 135 of 470\n","Making phenotypes for Chunk 136 of 470\n","Making phenotypes for Chunk 137 of 470\n","Making phenotypes for Chunk 138 of 470\n","Making phenotypes for Chunk 139 of 470\n","Making phenotypes for Chunk 140 of 470\n","Making phenotypes for Chunk 141 of 470\n","Making phenotypes for Chunk 142 of 470\n","Making phenotypes for Chunk 143 of 470\n","Making phenotypes for Chunk 144 of 470\n","Making phenotypes for Chunk 145 of 470\n","Making phenotypes for Chunk 146 of 470\n","Making phenotypes for Chunk 147 of 470\n","Making phenotypes for Chunk 148 of 470\n","Making phenotypes for Chunk 149 of 470\n","Making phenotypes for Chunk 150 of 470\n","Making phenotypes for Chunk 151 of 470\n","Making phenotypes for Chunk 152 of 470\n","Making phenotypes for Chunk 153 of 470\n","Making phenotypes for Chunk 154 of 470\n","Making phenotypes for Chunk 155 of 470\n","Making phenotypes for Chunk 156 of 470\n","Making phenotypes for Chunk 157 of 470\n","Making phenotypes for Chunk 158 of 470\n","Making phenotypes for Chunk 159 of 470\n","Making phenotypes for Chunk 160 of 470\n","Making phenotypes for Chunk 161 of 470\n","Making phenotypes for Chunk 162 of 470\n","Making phenotypes for Chunk 163 of 470\n","Making phenotypes for Chunk 164 of 470\n","Making phenotypes for Chunk 165 of 470\n","Making phenotypes for Chunk 166 of 470\n","Making phenotypes for Chunk 167 of 470\n","Making phenotypes for Chunk 168 of 470\n","Making phenotypes for Chunk 169 of 470\n","Making phenotypes for Chunk 170 of 470\n","Making phenotypes for Chunk 171 of 470\n","Making phenotypes for Chunk 172 of 470\n","Making phenotypes for Chunk 173 of 470\n","Making phenotypes for Chunk 174 of 470\n","Making phenotypes for Chunk 175 of 470\n","Making phenotypes for Chunk 176 of 470\n","Making phenotypes for Chunk 177 of 470\n","Making phenotypes for Chunk 178 of 470\n","Making phenotypes for Chunk 179 of 470\n","Making phenotypes for Chunk 180 of 470\n","Making phenotypes for Chunk 181 of 470\n","Making phenotypes for Chunk 182 of 470\n","Making phenotypes for Chunk 183 of 470\n","Making phenotypes for Chunk 184 of 470\n","Making phenotypes for Chunk 185 of 470\n","Making phenotypes for Chunk 186 of 470\n","Making phenotypes for Chunk 187 of 470\n","Making phenotypes for Chunk 188 of 470\n","Making phenotypes for Chunk 189 of 470\n","Making phenotypes for Chunk 190 of 470\n","Making phenotypes for Chunk 191 of 470\n","Making phenotypes for Chunk 192 of 470\n","Making phenotypes for Chunk 193 of 470\n","Making phenotypes for Chunk 194 of 470\n","Making phenotypes for Chunk 195 of 470\n","Making phenotypes for Chunk 196 of 470\n","Making phenotypes for Chunk 197 of 470\n","Making phenotypes for Chunk 198 of 470\n","Making phenotypes for Chunk 199 of 470\n","Making phenotypes for Chunk 200 of 470\n","Making phenotypes for Chunk 201 of 470\n","Making phenotypes for Chunk 202 of 470\n","Making phenotypes for Chunk 203 of 470\n","Making phenotypes for Chunk 204 of 470\n","Making phenotypes for Chunk 205 of 470\n","Making phenotypes for Chunk 206 of 470\n","Making phenotypes for Chunk 207 of 470\n","Making phenotypes for Chunk 208 of 470\n","Making phenotypes for Chunk 209 of 470\n","Making phenotypes for Chunk 210 of 470\n","Making phenotypes for Chunk 211 of 470\n","Making phenotypes for Chunk 212 of 470\n","Making phenotypes for Chunk 213 of 470\n","Making phenotypes for Chunk 214 of 470\n","Making phenotypes for Chunk 215 of 470\n","Making phenotypes for Chunk 216 of 470\n","Making phenotypes for Chunk 217 of 470\n","Making phenotypes for Chunk 218 of 470\n","Making phenotypes for Chunk 219 of 470\n","Making phenotypes for Chunk 220 of 470\n","Making phenotypes for Chunk 221 of 470\n","Making phenotypes for Chunk 222 of 470\n","Making phenotypes for Chunk 223 of 470\n","Making phenotypes for Chunk 224 of 470\n","Making phenotypes for Chunk 225 of 470\n","Making phenotypes for Chunk 226 of 470\n","Making phenotypes for Chunk 227 of 470\n","Making phenotypes for Chunk 228 of 470\n","Making phenotypes for Chunk 229 of 470\n","Making phenotypes for Chunk 230 of 470\n","Making phenotypes for Chunk 231 of 470\n","Making phenotypes for Chunk 232 of 470\n","Making phenotypes for Chunk 233 of 470\n","Making phenotypes for Chunk 234 of 470\n","Making phenotypes for Chunk 235 of 470\n","Making phenotypes for Chunk 236 of 470\n","Making phenotypes for Chunk 237 of 470\n","Making phenotypes for Chunk 238 of 470\n","Making phenotypes for Chunk 239 of 470\n","Making phenotypes for Chunk 240 of 470\n","Making phenotypes for Chunk 241 of 470\n","Making phenotypes for Chunk 242 of 470\n","Making phenotypes for Chunk 243 of 470\n","Making phenotypes for Chunk 244 of 470\n","Making phenotypes for Chunk 245 of 470\n","Making phenotypes for Chunk 246 of 470\n","Making phenotypes for Chunk 247 of 470\n","Making phenotypes for Chunk 248 of 470\n","Making phenotypes for Chunk 249 of 470\n","Making phenotypes for Chunk 250 of 470\n","Making phenotypes for Chunk 251 of 470\n","Making phenotypes for Chunk 252 of 470\n","Making phenotypes for Chunk 253 of 470\n","Making phenotypes for Chunk 254 of 470\n","Making phenotypes for Chunk 255 of 470\n","Making phenotypes for Chunk 256 of 470\n","Making phenotypes for Chunk 257 of 470\n","Making phenotypes for Chunk 258 of 470\n","Making phenotypes for Chunk 259 of 470\n","Making phenotypes for Chunk 260 of 470\n","Making phenotypes for Chunk 261 of 470\n","Making phenotypes for Chunk 262 of 470\n","Making phenotypes for Chunk 263 of 470\n","Making phenotypes for Chunk 264 of 470\n","Making phenotypes for Chunk 265 of 470\n","Making phenotypes for Chunk 266 of 470\n","Making phenotypes for Chunk 267 of 470\n","Making phenotypes for Chunk 268 of 470\n","Making phenotypes for Chunk 269 of 470\n","Making phenotypes for Chunk 270 of 470\n","Making phenotypes for Chunk 271 of 470\n","Making phenotypes for Chunk 272 of 470\n","Making phenotypes for Chunk 273 of 470\n","Making phenotypes for Chunk 274 of 470\n","Making phenotypes for Chunk 275 of 470\n","Making phenotypes for Chunk 276 of 470\n","Making phenotypes for Chunk 277 of 470\n","Making phenotypes for Chunk 278 of 470\n","Making phenotypes for Chunk 279 of 470\n","Making phenotypes for Chunk 280 of 470\n","Making phenotypes for Chunk 281 of 470\n","Making phenotypes for Chunk 282 of 470\n","Making phenotypes for Chunk 283 of 470\n","Making phenotypes for Chunk 284 of 470\n","Making phenotypes for Chunk 285 of 470\n","Making phenotypes for Chunk 286 of 470\n","Making phenotypes for Chunk 287 of 470\n","Making phenotypes for Chunk 288 of 470\n","Making phenotypes for Chunk 289 of 470\n","Making phenotypes for Chunk 290 of 470\n","Making phenotypes for Chunk 291 of 470\n","Making phenotypes for Chunk 292 of 470\n","Making phenotypes for Chunk 293 of 470\n","Making phenotypes for Chunk 294 of 470\n","Making phenotypes for Chunk 295 of 470\n","Making phenotypes for Chunk 296 of 470\n","Making phenotypes for Chunk 297 of 470\n","Making phenotypes for Chunk 298 of 470\n","Making phenotypes for Chunk 299 of 470\n","Making phenotypes for Chunk 300 of 470\n","Making phenotypes for Chunk 301 of 470\n","Making phenotypes for Chunk 302 of 470\n","Making phenotypes for Chunk 303 of 470\n","Making phenotypes for Chunk 304 of 470\n","Making phenotypes for Chunk 305 of 470\n","Making phenotypes for Chunk 306 of 470\n","Making phenotypes for Chunk 307 of 470\n","Making phenotypes for Chunk 308 of 470\n","Making phenotypes for Chunk 309 of 470\n","Making phenotypes for Chunk 310 of 470\n","Making phenotypes for Chunk 311 of 470\n","Making phenotypes for Chunk 312 of 470\n","Making phenotypes for Chunk 313 of 470\n","Making phenotypes for Chunk 314 of 470\n","Making phenotypes for Chunk 315 of 470\n","Making phenotypes for Chunk 316 of 470\n","Making phenotypes for Chunk 317 of 470\n","Making phenotypes for Chunk 318 of 470\n","Making phenotypes for Chunk 319 of 470\n","Making phenotypes for Chunk 320 of 470\n","Making phenotypes for Chunk 321 of 470\n","Making phenotypes for Chunk 322 of 470\n","Making phenotypes for Chunk 323 of 470\n","Making phenotypes for Chunk 324 of 470\n","Making phenotypes for Chunk 325 of 470\n","Making phenotypes for Chunk 326 of 470\n","Making phenotypes for Chunk 327 of 470\n","Making phenotypes for Chunk 328 of 470\n","Making phenotypes for Chunk 329 of 470\n","Making phenotypes for Chunk 330 of 470\n","Making phenotypes for Chunk 331 of 470\n","Making phenotypes for Chunk 332 of 470\n","Making phenotypes for Chunk 333 of 470\n","Making phenotypes for Chunk 334 of 470\n","Making phenotypes for Chunk 335 of 470\n","Making phenotypes for Chunk 336 of 470\n","Making phenotypes for Chunk 337 of 470\n","Making phenotypes for Chunk 338 of 470\n","Making phenotypes for Chunk 339 of 470\n","Making phenotypes for Chunk 340 of 470\n","Making phenotypes for Chunk 341 of 470\n","Making phenotypes for Chunk 342 of 470\n","Making phenotypes for Chunk 343 of 470\n","Making phenotypes for Chunk 344 of 470\n","Making phenotypes for Chunk 345 of 470\n","Making phenotypes for Chunk 346 of 470\n","Making phenotypes for Chunk 347 of 470\n","Making phenotypes for Chunk 348 of 470\n","Making phenotypes for Chunk 349 of 470\n","Making phenotypes for Chunk 350 of 470\n","Making phenotypes for Chunk 351 of 470\n","Making phenotypes for Chunk 352 of 470\n","Making phenotypes for Chunk 353 of 470\n","Making phenotypes for Chunk 354 of 470\n","Making phenotypes for Chunk 355 of 470\n","Making phenotypes for Chunk 356 of 470\n","Making phenotypes for Chunk 357 of 470\n","Making phenotypes for Chunk 358 of 470\n","Making phenotypes for Chunk 359 of 470\n","Making phenotypes for Chunk 360 of 470\n","Making phenotypes for Chunk 361 of 470\n","Making phenotypes for Chunk 362 of 470\n","Making phenotypes for Chunk 363 of 470\n","Making phenotypes for Chunk 364 of 470\n","Making phenotypes for Chunk 365 of 470\n","Making phenotypes for Chunk 366 of 470\n","Making phenotypes for Chunk 367 of 470\n","Making phenotypes for Chunk 368 of 470\n","Making phenotypes for Chunk 369 of 470\n","Making phenotypes for Chunk 370 of 470\n","Making phenotypes for Chunk 371 of 470\n","Making phenotypes for Chunk 372 of 470\n","Making phenotypes for Chunk 373 of 470\n","Making phenotypes for Chunk 374 of 470\n","Making phenotypes for Chunk 375 of 470\n","Making phenotypes for Chunk 376 of 470\n","Making phenotypes for Chunk 377 of 470\n","Making phenotypes for Chunk 378 of 470\n","Making phenotypes for Chunk 379 of 470\n","Making phenotypes for Chunk 380 of 470\n","Making phenotypes for Chunk 381 of 470\n","Making phenotypes for Chunk 382 of 470\n","Making phenotypes for Chunk 383 of 470\n","Making phenotypes for Chunk 384 of 470\n","Making phenotypes for Chunk 385 of 470\n","Making phenotypes for Chunk 386 of 470\n","Making phenotypes for Chunk 387 of 470\n","Making phenotypes for Chunk 388 of 470\n","Making phenotypes for Chunk 389 of 470\n","Making phenotypes for Chunk 390 of 470\n","Making phenotypes for Chunk 391 of 470\n","Making phenotypes for Chunk 392 of 470\n","Making phenotypes for Chunk 393 of 470\n","Making phenotypes for Chunk 394 of 470\n","Making phenotypes for Chunk 395 of 470\n","Making phenotypes for Chunk 396 of 470\n","Making phenotypes for Chunk 397 of 470\n","Making phenotypes for Chunk 398 of 470\n","Making phenotypes for Chunk 399 of 470\n","Making phenotypes for Chunk 400 of 470\n","Making phenotypes for Chunk 401 of 470\n","Making phenotypes for Chunk 402 of 470\n","Making phenotypes for Chunk 403 of 470\n","Making phenotypes for Chunk 404 of 470\n","Making phenotypes for Chunk 405 of 470\n","Making phenotypes for Chunk 406 of 470\n","Making phenotypes for Chunk 407 of 470\n","Making phenotypes for Chunk 408 of 470\n","Making phenotypes for Chunk 409 of 470\n","Making phenotypes for Chunk 410 of 470\n","Making phenotypes for Chunk 411 of 470\n","Making phenotypes for Chunk 412 of 470\n","Making phenotypes for Chunk 413 of 470\n","Making phenotypes for Chunk 414 of 470\n","Making phenotypes for Chunk 415 of 470\n","Making phenotypes for Chunk 416 of 470\n","Making phenotypes for Chunk 417 of 470\n","Making phenotypes for Chunk 418 of 470\n","Making phenotypes for Chunk 419 of 470\n","Making phenotypes for Chunk 420 of 470\n","Making phenotypes for Chunk 421 of 470\n","Making phenotypes for Chunk 422 of 470\n","Making phenotypes for Chunk 423 of 470\n","Making phenotypes for Chunk 424 of 470\n","Making phenotypes for Chunk 425 of 470\n","Making phenotypes for Chunk 426 of 470\n","Making phenotypes for Chunk 427 of 470\n","Making phenotypes for Chunk 428 of 470\n","Making phenotypes for Chunk 429 of 470\n","Making phenotypes for Chunk 430 of 470\n","Making phenotypes for Chunk 431 of 470\n","Making phenotypes for Chunk 432 of 470\n","Making phenotypes for Chunk 433 of 470\n","Making phenotypes for Chunk 434 of 470\n","Making phenotypes for Chunk 435 of 470\n","Making phenotypes for Chunk 436 of 470\n","Making phenotypes for Chunk 437 of 470\n","Making phenotypes for Chunk 438 of 470\n","Making phenotypes for Chunk 439 of 470\n","Making phenotypes for Chunk 440 of 470\n","Making phenotypes for Chunk 441 of 470\n","Making phenotypes for Chunk 442 of 470\n","Making phenotypes for Chunk 443 of 470\n","Making phenotypes for Chunk 444 of 470\n","Making phenotypes for Chunk 445 of 470\n","Making phenotypes for Chunk 446 of 470\n","Making phenotypes for Chunk 447 of 470\n","Making phenotypes for Chunk 448 of 470\n","Making phenotypes for Chunk 449 of 470\n","Making phenotypes for Chunk 450 of 470\n","Making phenotypes for Chunk 451 of 470\n","Making phenotypes for Chunk 452 of 470\n","Making phenotypes for Chunk 453 of 470\n","Making phenotypes for Chunk 454 of 470\n","Making phenotypes for Chunk 455 of 470\n","Making phenotypes for Chunk 456 of 470\n","Making phenotypes for Chunk 457 of 470\n","Making phenotypes for Chunk 458 of 470\n","Making phenotypes for Chunk 459 of 470\n","Making phenotypes for Chunk 460 of 470\n","Making phenotypes for Chunk 461 of 470\n","Making phenotypes for Chunk 462 of 470\n","Making phenotypes for Chunk 463 of 470\n","Making phenotypes for Chunk 464 of 470\n","Making phenotypes for Chunk 465 of 470\n","Making phenotypes for Chunk 466 of 470\n","Making phenotypes for Chunk 467 of 470\n","Making phenotypes for Chunk 468 of 470\n","Making phenotypes for Chunk 469 of 470\n","Making phenotypes for Chunk 470 of 470\n","\n","Phenotypes saved in GCTA_params={her=0.5,num-causals=10000}.pheno, with breeding values in GCTA_params={her=0.5,num-causals=10000}.breed and effect sizes in GCTA_params={her=0.5,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.7,num-causals=1}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.7\n","--num-causals 1\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.7,num-causals=1}.pheno, with breeding values in GCTA_params={her=0.7,num-causals=1}.breed and effect sizes in GCTA_params={her=0.7,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.7,num-causals=10}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.7\n","--num-causals 10\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.7,num-causals=10}.pheno, with breeding values in GCTA_params={her=0.7,num-causals=10}.breed and effect sizes in GCTA_params={her=0.7,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.7,num-causals=100}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.7\n","--num-causals 100\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in GCTA_params={her=0.7,num-causals=100}.pheno, with breeding values in GCTA_params={her=0.7,num-causals=100}.breed and effect sizes in GCTA_params={her=0.7,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.7,num-causals=1000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.7\n","--num-causals 1000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in GCTA_params={her=0.7,num-causals=1000}.pheno, with breeding values in GCTA_params={her=0.7,num-causals=1000}.breed and effect sizes in GCTA_params={her=0.7,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.7,num-causals=10000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.7\n","--num-causals 10000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.7000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 469\n","Making phenotypes for Chunk 2 of 469\n","Making phenotypes for Chunk 3 of 469\n","Making phenotypes for Chunk 4 of 469\n","Making phenotypes for Chunk 5 of 469\n","Making phenotypes for Chunk 6 of 469\n","Making phenotypes for Chunk 7 of 469\n","Making phenotypes for Chunk 8 of 469\n","Making phenotypes for Chunk 9 of 469\n","Making phenotypes for Chunk 10 of 469\n","Making phenotypes for Chunk 11 of 469\n","Making phenotypes for Chunk 12 of 469\n","Making phenotypes for Chunk 13 of 469\n","Making phenotypes for Chunk 14 of 469\n","Making phenotypes for Chunk 15 of 469\n","Making phenotypes for Chunk 16 of 469\n","Making phenotypes for Chunk 17 of 469\n","Making phenotypes for Chunk 18 of 469\n","Making phenotypes for Chunk 19 of 469\n","Making phenotypes for Chunk 20 of 469\n","Making phenotypes for Chunk 21 of 469\n","Making phenotypes for Chunk 22 of 469\n","Making phenotypes for Chunk 23 of 469\n","Making phenotypes for Chunk 24 of 469\n","Making phenotypes for Chunk 25 of 469\n","Making phenotypes for Chunk 26 of 469\n","Making phenotypes for Chunk 27 of 469\n","Making phenotypes for Chunk 28 of 469\n","Making phenotypes for Chunk 29 of 469\n","Making phenotypes for Chunk 30 of 469\n","Making phenotypes for Chunk 31 of 469\n","Making phenotypes for Chunk 32 of 469\n","Making phenotypes for Chunk 33 of 469\n","Making phenotypes for Chunk 34 of 469\n","Making phenotypes for Chunk 35 of 469\n","Making phenotypes for Chunk 36 of 469\n","Making phenotypes for Chunk 37 of 469\n","Making phenotypes for Chunk 38 of 469\n","Making phenotypes for Chunk 39 of 469\n","Making phenotypes for Chunk 40 of 469\n","Making phenotypes for Chunk 41 of 469\n","Making phenotypes for Chunk 42 of 469\n","Making phenotypes for Chunk 43 of 469\n","Making phenotypes for Chunk 44 of 469\n","Making phenotypes for Chunk 45 of 469\n","Making phenotypes for Chunk 46 of 469\n","Making phenotypes for Chunk 47 of 469\n","Making phenotypes for Chunk 48 of 469\n","Making phenotypes for Chunk 49 of 469\n","Making phenotypes for Chunk 50 of 469\n","Making phenotypes for Chunk 51 of 469\n","Making phenotypes for Chunk 52 of 469\n","Making phenotypes for Chunk 53 of 469\n","Making phenotypes for Chunk 54 of 469\n","Making phenotypes for Chunk 55 of 469\n","Making phenotypes for Chunk 56 of 469\n","Making phenotypes for Chunk 57 of 469\n","Making phenotypes for Chunk 58 of 469\n","Making phenotypes for Chunk 59 of 469\n","Making phenotypes for Chunk 60 of 469\n","Making phenotypes for Chunk 61 of 469\n","Making phenotypes for Chunk 62 of 469\n","Making phenotypes for Chunk 63 of 469\n","Making phenotypes for Chunk 64 of 469\n","Making phenotypes for Chunk 65 of 469\n","Making phenotypes for Chunk 66 of 469\n","Making phenotypes for Chunk 67 of 469\n","Making phenotypes for Chunk 68 of 469\n","Making phenotypes for Chunk 69 of 469\n","Making phenotypes for Chunk 70 of 469\n","Making phenotypes for Chunk 71 of 469\n","Making phenotypes for Chunk 72 of 469\n","Making phenotypes for Chunk 73 of 469\n","Making phenotypes for Chunk 74 of 469\n","Making phenotypes for Chunk 75 of 469\n","Making phenotypes for Chunk 76 of 469\n","Making phenotypes for Chunk 77 of 469\n","Making phenotypes for Chunk 78 of 469\n","Making phenotypes for Chunk 79 of 469\n","Making phenotypes for Chunk 80 of 469\n","Making phenotypes for Chunk 81 of 469\n","Making phenotypes for Chunk 82 of 469\n","Making phenotypes for Chunk 83 of 469\n","Making phenotypes for Chunk 84 of 469\n","Making phenotypes for Chunk 85 of 469\n","Making phenotypes for Chunk 86 of 469\n","Making phenotypes for Chunk 87 of 469\n","Making phenotypes for Chunk 88 of 469\n","Making phenotypes for Chunk 89 of 469\n","Making phenotypes for Chunk 90 of 469\n","Making phenotypes for Chunk 91 of 469\n","Making phenotypes for Chunk 92 of 469\n","Making phenotypes for Chunk 93 of 469\n","Making phenotypes for Chunk 94 of 469\n","Making phenotypes for Chunk 95 of 469\n","Making phenotypes for Chunk 96 of 469\n","Making phenotypes for Chunk 97 of 469\n","Making phenotypes for Chunk 98 of 469\n","Making phenotypes for Chunk 99 of 469\n","Making phenotypes for Chunk 100 of 469\n","Making phenotypes for Chunk 101 of 469\n","Making phenotypes for Chunk 102 of 469\n","Making phenotypes for Chunk 103 of 469\n","Making phenotypes for Chunk 104 of 469\n","Making phenotypes for Chunk 105 of 469\n","Making phenotypes for Chunk 106 of 469\n","Making phenotypes for Chunk 107 of 469\n","Making phenotypes for Chunk 108 of 469\n","Making phenotypes for Chunk 109 of 469\n","Making phenotypes for Chunk 110 of 469\n","Making phenotypes for Chunk 111 of 469\n","Making phenotypes for Chunk 112 of 469\n","Making phenotypes for Chunk 113 of 469\n","Making phenotypes for Chunk 114 of 469\n","Making phenotypes for Chunk 115 of 469\n","Making phenotypes for Chunk 116 of 469\n","Making phenotypes for Chunk 117 of 469\n","Making phenotypes for Chunk 118 of 469\n","Making phenotypes for Chunk 119 of 469\n","Making phenotypes for Chunk 120 of 469\n","Making phenotypes for Chunk 121 of 469\n","Making phenotypes for Chunk 122 of 469\n","Making phenotypes for Chunk 123 of 469\n","Making phenotypes for Chunk 124 of 469\n","Making phenotypes for Chunk 125 of 469\n","Making phenotypes for Chunk 126 of 469\n","Making phenotypes for Chunk 127 of 469\n","Making phenotypes for Chunk 128 of 469\n","Making phenotypes for Chunk 129 of 469\n","Making phenotypes for Chunk 130 of 469\n","Making phenotypes for Chunk 131 of 469\n","Making phenotypes for Chunk 132 of 469\n","Making phenotypes for Chunk 133 of 469\n","Making phenotypes for Chunk 134 of 469\n","Making phenotypes for Chunk 135 of 469\n","Making phenotypes for Chunk 136 of 469\n","Making phenotypes for Chunk 137 of 469\n","Making phenotypes for Chunk 138 of 469\n","Making phenotypes for Chunk 139 of 469\n","Making phenotypes for Chunk 140 of 469\n","Making phenotypes for Chunk 141 of 469\n","Making phenotypes for Chunk 142 of 469\n","Making phenotypes for Chunk 143 of 469\n","Making phenotypes for Chunk 144 of 469\n","Making phenotypes for Chunk 145 of 469\n","Making phenotypes for Chunk 146 of 469\n","Making phenotypes for Chunk 147 of 469\n","Making phenotypes for Chunk 148 of 469\n","Making phenotypes for Chunk 149 of 469\n","Making phenotypes for Chunk 150 of 469\n","Making phenotypes for Chunk 151 of 469\n","Making phenotypes for Chunk 152 of 469\n","Making phenotypes for Chunk 153 of 469\n","Making phenotypes for Chunk 154 of 469\n","Making phenotypes for Chunk 155 of 469\n","Making phenotypes for Chunk 156 of 469\n","Making phenotypes for Chunk 157 of 469\n","Making phenotypes for Chunk 158 of 469\n","Making phenotypes for Chunk 159 of 469\n","Making phenotypes for Chunk 160 of 469\n","Making phenotypes for Chunk 161 of 469\n","Making phenotypes for Chunk 162 of 469\n","Making phenotypes for Chunk 163 of 469\n","Making phenotypes for Chunk 164 of 469\n","Making phenotypes for Chunk 165 of 469\n","Making phenotypes for Chunk 166 of 469\n","Making phenotypes for Chunk 167 of 469\n","Making phenotypes for Chunk 168 of 469\n","Making phenotypes for Chunk 169 of 469\n","Making phenotypes for Chunk 170 of 469\n","Making phenotypes for Chunk 171 of 469\n","Making phenotypes for Chunk 172 of 469\n","Making phenotypes for Chunk 173 of 469\n","Making phenotypes for Chunk 174 of 469\n","Making phenotypes for Chunk 175 of 469\n","Making phenotypes for Chunk 176 of 469\n","Making phenotypes for Chunk 177 of 469\n","Making phenotypes for Chunk 178 of 469\n","Making phenotypes for Chunk 179 of 469\n","Making phenotypes for Chunk 180 of 469\n","Making phenotypes for Chunk 181 of 469\n","Making phenotypes for Chunk 182 of 469\n","Making phenotypes for Chunk 183 of 469\n","Making phenotypes for Chunk 184 of 469\n","Making phenotypes for Chunk 185 of 469\n","Making phenotypes for Chunk 186 of 469\n","Making phenotypes for Chunk 187 of 469\n","Making phenotypes for Chunk 188 of 469\n","Making phenotypes for Chunk 189 of 469\n","Making phenotypes for Chunk 190 of 469\n","Making phenotypes for Chunk 191 of 469\n","Making phenotypes for Chunk 192 of 469\n","Making phenotypes for Chunk 193 of 469\n","Making phenotypes for Chunk 194 of 469\n","Making phenotypes for Chunk 195 of 469\n","Making phenotypes for Chunk 196 of 469\n","Making phenotypes for Chunk 197 of 469\n","Making phenotypes for Chunk 198 of 469\n","Making phenotypes for Chunk 199 of 469\n","Making phenotypes for Chunk 200 of 469\n","Making phenotypes for Chunk 201 of 469\n","Making phenotypes for Chunk 202 of 469\n","Making phenotypes for Chunk 203 of 469\n","Making phenotypes for Chunk 204 of 469\n","Making phenotypes for Chunk 205 of 469\n","Making phenotypes for Chunk 206 of 469\n","Making phenotypes for Chunk 207 of 469\n","Making phenotypes for Chunk 208 of 469\n","Making phenotypes for Chunk 209 of 469\n","Making phenotypes for Chunk 210 of 469\n","Making phenotypes for Chunk 211 of 469\n","Making phenotypes for Chunk 212 of 469\n","Making phenotypes for Chunk 213 of 469\n","Making phenotypes for Chunk 214 of 469\n","Making phenotypes for Chunk 215 of 469\n","Making phenotypes for Chunk 216 of 469\n","Making phenotypes for Chunk 217 of 469\n","Making phenotypes for Chunk 218 of 469\n","Making phenotypes for Chunk 219 of 469\n","Making phenotypes for Chunk 220 of 469\n","Making phenotypes for Chunk 221 of 469\n","Making phenotypes for Chunk 222 of 469\n","Making phenotypes for Chunk 223 of 469\n","Making phenotypes for Chunk 224 of 469\n","Making phenotypes for Chunk 225 of 469\n","Making phenotypes for Chunk 226 of 469\n","Making phenotypes for Chunk 227 of 469\n","Making phenotypes for Chunk 228 of 469\n","Making phenotypes for Chunk 229 of 469\n","Making phenotypes for Chunk 230 of 469\n","Making phenotypes for Chunk 231 of 469\n","Making phenotypes for Chunk 232 of 469\n","Making phenotypes for Chunk 233 of 469\n","Making phenotypes for Chunk 234 of 469\n","Making phenotypes for Chunk 235 of 469\n","Making phenotypes for Chunk 236 of 469\n","Making phenotypes for Chunk 237 of 469\n","Making phenotypes for Chunk 238 of 469\n","Making phenotypes for Chunk 239 of 469\n","Making phenotypes for Chunk 240 of 469\n","Making phenotypes for Chunk 241 of 469\n","Making phenotypes for Chunk 242 of 469\n","Making phenotypes for Chunk 243 of 469\n","Making phenotypes for Chunk 244 of 469\n","Making phenotypes for Chunk 245 of 469\n","Making phenotypes for Chunk 246 of 469\n","Making phenotypes for Chunk 247 of 469\n","Making phenotypes for Chunk 248 of 469\n","Making phenotypes for Chunk 249 of 469\n","Making phenotypes for Chunk 250 of 469\n","Making phenotypes for Chunk 251 of 469\n","Making phenotypes for Chunk 252 of 469\n","Making phenotypes for Chunk 253 of 469\n","Making phenotypes for Chunk 254 of 469\n","Making phenotypes for Chunk 255 of 469\n","Making phenotypes for Chunk 256 of 469\n","Making phenotypes for Chunk 257 of 469\n","Making phenotypes for Chunk 258 of 469\n","Making phenotypes for Chunk 259 of 469\n","Making phenotypes for Chunk 260 of 469\n","Making phenotypes for Chunk 261 of 469\n","Making phenotypes for Chunk 262 of 469\n","Making phenotypes for Chunk 263 of 469\n","Making phenotypes for Chunk 264 of 469\n","Making phenotypes for Chunk 265 of 469\n","Making phenotypes for Chunk 266 of 469\n","Making phenotypes for Chunk 267 of 469\n","Making phenotypes for Chunk 268 of 469\n","Making phenotypes for Chunk 269 of 469\n","Making phenotypes for Chunk 270 of 469\n","Making phenotypes for Chunk 271 of 469\n","Making phenotypes for Chunk 272 of 469\n","Making phenotypes for Chunk 273 of 469\n","Making phenotypes for Chunk 274 of 469\n","Making phenotypes for Chunk 275 of 469\n","Making phenotypes for Chunk 276 of 469\n","Making phenotypes for Chunk 277 of 469\n","Making phenotypes for Chunk 278 of 469\n","Making phenotypes for Chunk 279 of 469\n","Making phenotypes for Chunk 280 of 469\n","Making phenotypes for Chunk 281 of 469\n","Making phenotypes for Chunk 282 of 469\n","Making phenotypes for Chunk 283 of 469\n","Making phenotypes for Chunk 284 of 469\n","Making phenotypes for Chunk 285 of 469\n","Making phenotypes for Chunk 286 of 469\n","Making phenotypes for Chunk 287 of 469\n","Making phenotypes for Chunk 288 of 469\n","Making phenotypes for Chunk 289 of 469\n","Making phenotypes for Chunk 290 of 469\n","Making phenotypes for Chunk 291 of 469\n","Making phenotypes for Chunk 292 of 469\n","Making phenotypes for Chunk 293 of 469\n","Making phenotypes for Chunk 294 of 469\n","Making phenotypes for Chunk 295 of 469\n","Making phenotypes for Chunk 296 of 469\n","Making phenotypes for Chunk 297 of 469\n","Making phenotypes for Chunk 298 of 469\n","Making phenotypes for Chunk 299 of 469\n","Making phenotypes for Chunk 300 of 469\n","Making phenotypes for Chunk 301 of 469\n","Making phenotypes for Chunk 302 of 469\n","Making phenotypes for Chunk 303 of 469\n","Making phenotypes for Chunk 304 of 469\n","Making phenotypes for Chunk 305 of 469\n","Making phenotypes for Chunk 306 of 469\n","Making phenotypes for Chunk 307 of 469\n","Making phenotypes for Chunk 308 of 469\n","Making phenotypes for Chunk 309 of 469\n","Making phenotypes for Chunk 310 of 469\n","Making phenotypes for Chunk 311 of 469\n","Making phenotypes for Chunk 312 of 469\n","Making phenotypes for Chunk 313 of 469\n","Making phenotypes for Chunk 314 of 469\n","Making phenotypes for Chunk 315 of 469\n","Making phenotypes for Chunk 316 of 469\n","Making phenotypes for Chunk 317 of 469\n","Making phenotypes for Chunk 318 of 469\n","Making phenotypes for Chunk 319 of 469\n","Making phenotypes for Chunk 320 of 469\n","Making phenotypes for Chunk 321 of 469\n","Making phenotypes for Chunk 322 of 469\n","Making phenotypes for Chunk 323 of 469\n","Making phenotypes for Chunk 324 of 469\n","Making phenotypes for Chunk 325 of 469\n","Making phenotypes for Chunk 326 of 469\n","Making phenotypes for Chunk 327 of 469\n","Making phenotypes for Chunk 328 of 469\n","Making phenotypes for Chunk 329 of 469\n","Making phenotypes for Chunk 330 of 469\n","Making phenotypes for Chunk 331 of 469\n","Making phenotypes for Chunk 332 of 469\n","Making phenotypes for Chunk 333 of 469\n","Making phenotypes for Chunk 334 of 469\n","Making phenotypes for Chunk 335 of 469\n","Making phenotypes for Chunk 336 of 469\n","Making phenotypes for Chunk 337 of 469\n","Making phenotypes for Chunk 338 of 469\n","Making phenotypes for Chunk 339 of 469\n","Making phenotypes for Chunk 340 of 469\n","Making phenotypes for Chunk 341 of 469\n","Making phenotypes for Chunk 342 of 469\n","Making phenotypes for Chunk 343 of 469\n","Making phenotypes for Chunk 344 of 469\n","Making phenotypes for Chunk 345 of 469\n","Making phenotypes for Chunk 346 of 469\n","Making phenotypes for Chunk 347 of 469\n","Making phenotypes for Chunk 348 of 469\n","Making phenotypes for Chunk 349 of 469\n","Making phenotypes for Chunk 350 of 469\n","Making phenotypes for Chunk 351 of 469\n","Making phenotypes for Chunk 352 of 469\n","Making phenotypes for Chunk 353 of 469\n","Making phenotypes for Chunk 354 of 469\n","Making phenotypes for Chunk 355 of 469\n","Making phenotypes for Chunk 356 of 469\n","Making phenotypes for Chunk 357 of 469\n","Making phenotypes for Chunk 358 of 469\n","Making phenotypes for Chunk 359 of 469\n","Making phenotypes for Chunk 360 of 469\n","Making phenotypes for Chunk 361 of 469\n","Making phenotypes for Chunk 362 of 469\n","Making phenotypes for Chunk 363 of 469\n","Making phenotypes for Chunk 364 of 469\n","Making phenotypes for Chunk 365 of 469\n","Making phenotypes for Chunk 366 of 469\n","Making phenotypes for Chunk 367 of 469\n","Making phenotypes for Chunk 368 of 469\n","Making phenotypes for Chunk 369 of 469\n","Making phenotypes for Chunk 370 of 469\n","Making phenotypes for Chunk 371 of 469\n","Making phenotypes for Chunk 372 of 469\n","Making phenotypes for Chunk 373 of 469\n","Making phenotypes for Chunk 374 of 469\n","Making phenotypes for Chunk 375 of 469\n","Making phenotypes for Chunk 376 of 469\n","Making phenotypes for Chunk 377 of 469\n","Making phenotypes for Chunk 378 of 469\n","Making phenotypes for Chunk 379 of 469\n","Making phenotypes for Chunk 380 of 469\n","Making phenotypes for Chunk 381 of 469\n","Making phenotypes for Chunk 382 of 469\n","Making phenotypes for Chunk 383 of 469\n","Making phenotypes for Chunk 384 of 469\n","Making phenotypes for Chunk 385 of 469\n","Making phenotypes for Chunk 386 of 469\n","Making phenotypes for Chunk 387 of 469\n","Making phenotypes for Chunk 388 of 469\n","Making phenotypes for Chunk 389 of 469\n","Making phenotypes for Chunk 390 of 469\n","Making phenotypes for Chunk 391 of 469\n","Making phenotypes for Chunk 392 of 469\n","Making phenotypes for Chunk 393 of 469\n","Making phenotypes for Chunk 394 of 469\n","Making phenotypes for Chunk 395 of 469\n","Making phenotypes for Chunk 396 of 469\n","Making phenotypes for Chunk 397 of 469\n","Making phenotypes for Chunk 398 of 469\n","Making phenotypes for Chunk 399 of 469\n","Making phenotypes for Chunk 400 of 469\n","Making phenotypes for Chunk 401 of 469\n","Making phenotypes for Chunk 402 of 469\n","Making phenotypes for Chunk 403 of 469\n","Making phenotypes for Chunk 404 of 469\n","Making phenotypes for Chunk 405 of 469\n","Making phenotypes for Chunk 406 of 469\n","Making phenotypes for Chunk 407 of 469\n","Making phenotypes for Chunk 408 of 469\n","Making phenotypes for Chunk 409 of 469\n","Making phenotypes for Chunk 410 of 469\n","Making phenotypes for Chunk 411 of 469\n","Making phenotypes for Chunk 412 of 469\n","Making phenotypes for Chunk 413 of 469\n","Making phenotypes for Chunk 414 of 469\n","Making phenotypes for Chunk 415 of 469\n","Making phenotypes for Chunk 416 of 469\n","Making phenotypes for Chunk 417 of 469\n","Making phenotypes for Chunk 418 of 469\n","Making phenotypes for Chunk 419 of 469\n","Making phenotypes for Chunk 420 of 469\n","Making phenotypes for Chunk 421 of 469\n","Making phenotypes for Chunk 422 of 469\n","Making phenotypes for Chunk 423 of 469\n","Making phenotypes for Chunk 424 of 469\n","Making phenotypes for Chunk 425 of 469\n","Making phenotypes for Chunk 426 of 469\n","Making phenotypes for Chunk 427 of 469\n","Making phenotypes for Chunk 428 of 469\n","Making phenotypes for Chunk 429 of 469\n","Making phenotypes for Chunk 430 of 469\n","Making phenotypes for Chunk 431 of 469\n","Making phenotypes for Chunk 432 of 469\n","Making phenotypes for Chunk 433 of 469\n","Making phenotypes for Chunk 434 of 469\n","Making phenotypes for Chunk 435 of 469\n","Making phenotypes for Chunk 436 of 469\n","Making phenotypes for Chunk 437 of 469\n","Making phenotypes for Chunk 438 of 469\n","Making phenotypes for Chunk 439 of 469\n","Making phenotypes for Chunk 440 of 469\n","Making phenotypes for Chunk 441 of 469\n","Making phenotypes for Chunk 442 of 469\n","Making phenotypes for Chunk 443 of 469\n","Making phenotypes for Chunk 444 of 469\n","Making phenotypes for Chunk 445 of 469\n","Making phenotypes for Chunk 446 of 469\n","Making phenotypes for Chunk 447 of 469\n","Making phenotypes for Chunk 448 of 469\n","Making phenotypes for Chunk 449 of 469\n","Making phenotypes for Chunk 450 of 469\n","Making phenotypes for Chunk 451 of 469\n","Making phenotypes for Chunk 452 of 469\n","Making phenotypes for Chunk 453 of 469\n","Making phenotypes for Chunk 454 of 469\n","Making phenotypes for Chunk 455 of 469\n","Making phenotypes for Chunk 456 of 469\n","Making phenotypes for Chunk 457 of 469\n","Making phenotypes for Chunk 458 of 469\n","Making phenotypes for Chunk 459 of 469\n","Making phenotypes for Chunk 460 of 469\n","Making phenotypes for Chunk 461 of 469\n","Making phenotypes for Chunk 462 of 469\n","Making phenotypes for Chunk 463 of 469\n","Making phenotypes for Chunk 464 of 469\n","Making phenotypes for Chunk 465 of 469\n","Making phenotypes for Chunk 466 of 469\n","Making phenotypes for Chunk 467 of 469\n","Making phenotypes for Chunk 468 of 469\n","Making phenotypes for Chunk 469 of 469\n","\n","Phenotypes saved in GCTA_params={her=0.7,num-causals=10000}.pheno, with breeding values in GCTA_params={her=0.7,num-causals=10000}.breed and effect sizes in GCTA_params={her=0.7,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.9,num-causals=1}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.9\n","--num-causals 1\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 1 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.9,num-causals=1}.pheno, with breeding values in GCTA_params={her=0.9,num-causals=1}.breed and effect sizes in GCTA_params={her=0.9,num-causals=1}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.9,num-causals=10}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.9\n","--num-causals 10\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 10 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 1\n","\n","Phenotypes saved in GCTA_params={her=0.9,num-causals=10}.pheno, with breeding values in GCTA_params={her=0.9,num-causals=10}.breed and effect sizes in GCTA_params={her=0.9,num-causals=10}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.9,num-causals=100}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.9\n","--num-causals 100\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 100 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 5\n","Making phenotypes for Chunk 2 of 5\n","Making phenotypes for Chunk 3 of 5\n","Making phenotypes for Chunk 4 of 5\n","Making phenotypes for Chunk 5 of 5\n","\n","Phenotypes saved in GCTA_params={her=0.9,num-causals=100}.pheno, with breeding values in GCTA_params={her=0.9,num-causals=100}.breed and effect sizes in GCTA_params={her=0.9,num-causals=100}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.9,num-causals=1000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.9\n","--num-causals 1000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 1000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 49\n","Making phenotypes for Chunk 2 of 49\n","Making phenotypes for Chunk 3 of 49\n","Making phenotypes for Chunk 4 of 49\n","Making phenotypes for Chunk 5 of 49\n","Making phenotypes for Chunk 6 of 49\n","Making phenotypes for Chunk 7 of 49\n","Making phenotypes for Chunk 8 of 49\n","Making phenotypes for Chunk 9 of 49\n","Making phenotypes for Chunk 10 of 49\n","Making phenotypes for Chunk 11 of 49\n","Making phenotypes for Chunk 12 of 49\n","Making phenotypes for Chunk 13 of 49\n","Making phenotypes for Chunk 14 of 49\n","Making phenotypes for Chunk 15 of 49\n","Making phenotypes for Chunk 16 of 49\n","Making phenotypes for Chunk 17 of 49\n","Making phenotypes for Chunk 18 of 49\n","Making phenotypes for Chunk 19 of 49\n","Making phenotypes for Chunk 20 of 49\n","Making phenotypes for Chunk 21 of 49\n","Making phenotypes for Chunk 22 of 49\n","Making phenotypes for Chunk 23 of 49\n","Making phenotypes for Chunk 24 of 49\n","Making phenotypes for Chunk 25 of 49\n","Making phenotypes for Chunk 26 of 49\n","Making phenotypes for Chunk 27 of 49\n","Making phenotypes for Chunk 28 of 49\n","Making phenotypes for Chunk 29 of 49\n","Making phenotypes for Chunk 30 of 49\n","Making phenotypes for Chunk 31 of 49\n","Making phenotypes for Chunk 32 of 49\n","Making phenotypes for Chunk 33 of 49\n","Making phenotypes for Chunk 34 of 49\n","Making phenotypes for Chunk 35 of 49\n","Making phenotypes for Chunk 36 of 49\n","Making phenotypes for Chunk 37 of 49\n","Making phenotypes for Chunk 38 of 49\n","Making phenotypes for Chunk 39 of 49\n","Making phenotypes for Chunk 40 of 49\n","Making phenotypes for Chunk 41 of 49\n","Making phenotypes for Chunk 42 of 49\n","Making phenotypes for Chunk 43 of 49\n","Making phenotypes for Chunk 44 of 49\n","Making phenotypes for Chunk 45 of 49\n","Making phenotypes for Chunk 46 of 49\n","Making phenotypes for Chunk 47 of 49\n","Making phenotypes for Chunk 48 of 49\n","Making phenotypes for Chunk 49 of 49\n","\n","Phenotypes saved in GCTA_params={her=0.9,num-causals=1000}.pheno, with breeding values in GCTA_params={her=0.9,num-causals=1000}.breed and effect sizes in GCTA_params={her=0.9,num-causals=1000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","LDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\n","Version 5.2 - Help pages at http://www.ldak.org\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","There are 7 pairs of arguments:\n","--make-phenos GCTA_params={her=0.9,num-causals=10000}\n","--bfile 1000g\n","--ignore-weights YES\n","--power -1\n","--num-phenos 100\n","--her 0.9\n","--num-causals 10000\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Making 100 phenotypes, each with heritability 0.9000 and 10000 causal predictors\n","\n","Predictors will be centred then scaled by V^(-1.0000/2) (option \"--power\"), where V=2*MAF*(1-MAF), the expected variance assuming Hardy-Weinberg Equilibrium; to instead scale based on observed variance use \"--hwe-stand NO\"\n","\n","Causal predictors will be picked at random; if you would prefer to specify them, use \"--causals\"\n","\n","Effect sizes (for scaled predictors) will be drawn from a Gaussian distribution; if you would prefer to specify them, use \"--effects\"\n","\n","To generate a binary phenotype, use \"--prev\" to provide the prevalence of cases\n","\n","To generate correlated pairs of phenotypes, use \"--bivar\"\n","\n","It appears this system has multiple processors available; to run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","\n","Reading IDs for 2504 samples from 1000g.fam\n","\n","Reading details for 12123481 predictors from 1000g.bim\n","Warning, Predictor 2:10514 has a negative genetic distance (-0.0012509007)\n","Warning, Predictor 2:10515 has a negative genetic distance (-0.0012503963)\n","Warning, Predictor 2:10554 has a negative genetic distance (-0.0012307249)\n","Warning, Predictor 2:10560 has a negative genetic distance (-0.0012276985)\n","Warning, Predictor 2:10566 has a negative genetic distance (-0.0012246722)\n","In total 2360 predictors have negative genetic distances\n","\n","Data contain 2504 samples and 12123481 predictors\n","\n","Making phenotypes for Chunk 1 of 470\n","Making phenotypes for Chunk 2 of 470\n","Making phenotypes for Chunk 3 of 470\n","Making phenotypes for Chunk 4 of 470\n","Making phenotypes for Chunk 5 of 470\n","Making phenotypes for Chunk 6 of 470\n","Making phenotypes for Chunk 7 of 470\n","Making phenotypes for Chunk 8 of 470\n","Making phenotypes for Chunk 9 of 470\n","Making phenotypes for Chunk 10 of 470\n","Making phenotypes for Chunk 11 of 470\n","Making phenotypes for Chunk 12 of 470\n","Making phenotypes for Chunk 13 of 470\n","Making phenotypes for Chunk 14 of 470\n","Making phenotypes for Chunk 15 of 470\n","Making phenotypes for Chunk 16 of 470\n","Making phenotypes for Chunk 17 of 470\n","Making phenotypes for Chunk 18 of 470\n","Making phenotypes for Chunk 19 of 470\n","Making phenotypes for Chunk 20 of 470\n","Making phenotypes for Chunk 21 of 470\n","Making phenotypes for Chunk 22 of 470\n","Making phenotypes for Chunk 23 of 470\n","Making phenotypes for Chunk 24 of 470\n","Making phenotypes for Chunk 25 of 470\n","Making phenotypes for Chunk 26 of 470\n","Making phenotypes for Chunk 27 of 470\n","Making phenotypes for Chunk 28 of 470\n","Making phenotypes for Chunk 29 of 470\n","Making phenotypes for Chunk 30 of 470\n","Making phenotypes for Chunk 31 of 470\n","Making phenotypes for Chunk 32 of 470\n","Making phenotypes for Chunk 33 of 470\n","Making phenotypes for Chunk 34 of 470\n","Making phenotypes for Chunk 35 of 470\n","Making phenotypes for Chunk 36 of 470\n","Making phenotypes for Chunk 37 of 470\n","Making phenotypes for Chunk 38 of 470\n","Making phenotypes for Chunk 39 of 470\n","Making phenotypes for Chunk 40 of 470\n","Making phenotypes for Chunk 41 of 470\n","Making phenotypes for Chunk 42 of 470\n","Making phenotypes for Chunk 43 of 470\n","Making phenotypes for Chunk 44 of 470\n","Making phenotypes for Chunk 45 of 470\n","Making phenotypes for Chunk 46 of 470\n","Making phenotypes for Chunk 47 of 470\n","Making phenotypes for Chunk 48 of 470\n","Making phenotypes for Chunk 49 of 470\n","Making phenotypes for Chunk 50 of 470\n","Making phenotypes for Chunk 51 of 470\n","Making phenotypes for Chunk 52 of 470\n","Making phenotypes for Chunk 53 of 470\n","Warning, Predictor 2:91799813 is trivial (takes at most one non-missing value) and will be ignored\n","\n","Making phenotypes for Chunk 54 of 470\n","Making phenotypes for Chunk 55 of 470\n","Making phenotypes for Chunk 56 of 470\n","Making phenotypes for Chunk 57 of 470\n","Making phenotypes for Chunk 58 of 470\n","Making phenotypes for Chunk 59 of 470\n","Making phenotypes for Chunk 60 of 470\n","Making phenotypes for Chunk 61 of 470\n","Making phenotypes for Chunk 62 of 470\n","Making phenotypes for Chunk 63 of 470\n","Making phenotypes for Chunk 64 of 470\n","Making phenotypes for Chunk 65 of 470\n","Making phenotypes for Chunk 66 of 470\n","Making phenotypes for Chunk 67 of 470\n","Making phenotypes for Chunk 68 of 470\n","Making phenotypes for Chunk 69 of 470\n","Making phenotypes for Chunk 70 of 470\n","Making phenotypes for Chunk 71 of 470\n","Making phenotypes for Chunk 72 of 470\n","Making phenotypes for Chunk 73 of 470\n","Making phenotypes for Chunk 74 of 470\n","Making phenotypes for Chunk 75 of 470\n","Making phenotypes for Chunk 76 of 470\n","Making phenotypes for Chunk 77 of 470\n","Making phenotypes for Chunk 78 of 470\n","Making phenotypes for Chunk 79 of 470\n","Making phenotypes for Chunk 80 of 470\n","Making phenotypes for Chunk 81 of 470\n","Making phenotypes for Chunk 82 of 470\n","Making phenotypes for Chunk 83 of 470\n","Making phenotypes for Chunk 84 of 470\n","Making phenotypes for Chunk 85 of 470\n","Making phenotypes for Chunk 86 of 470\n","Making phenotypes for Chunk 87 of 470\n","Making phenotypes for Chunk 88 of 470\n","Making phenotypes for Chunk 89 of 470\n","Making phenotypes for Chunk 90 of 470\n","Making phenotypes for Chunk 91 of 470\n","Making phenotypes for Chunk 92 of 470\n","Making phenotypes for Chunk 93 of 470\n","Making phenotypes for Chunk 94 of 470\n","Making phenotypes for Chunk 95 of 470\n","Making phenotypes for Chunk 96 of 470\n","Making phenotypes for Chunk 97 of 470\n","Making phenotypes for Chunk 98 of 470\n","Making phenotypes for Chunk 99 of 470\n","Making phenotypes for Chunk 100 of 470\n","Making phenotypes for Chunk 101 of 470\n","Making phenotypes for Chunk 102 of 470\n","Making phenotypes for Chunk 103 of 470\n","Making phenotypes for Chunk 104 of 470\n","Making phenotypes for Chunk 105 of 470\n","Making phenotypes for Chunk 106 of 470\n","Making phenotypes for Chunk 107 of 470\n","Making phenotypes for Chunk 108 of 470\n","Making phenotypes for Chunk 109 of 470\n","Making phenotypes for Chunk 110 of 470\n","Making phenotypes for Chunk 111 of 470\n","Making phenotypes for Chunk 112 of 470\n","Making phenotypes for Chunk 113 of 470\n","Making phenotypes for Chunk 114 of 470\n","Making phenotypes for Chunk 115 of 470\n","Making phenotypes for Chunk 116 of 470\n","Making phenotypes for Chunk 117 of 470\n","Making phenotypes for Chunk 118 of 470\n","Making phenotypes for Chunk 119 of 470\n","Making phenotypes for Chunk 120 of 470\n","Making phenotypes for Chunk 121 of 470\n","Making phenotypes for Chunk 122 of 470\n","Making phenotypes for Chunk 123 of 470\n","Making phenotypes for Chunk 124 of 470\n","Making phenotypes for Chunk 125 of 470\n","Making phenotypes for Chunk 126 of 470\n","Making phenotypes for Chunk 127 of 470\n","Making phenotypes for Chunk 128 of 470\n","Making phenotypes for Chunk 129 of 470\n","Making phenotypes for Chunk 130 of 470\n","Making phenotypes for Chunk 131 of 470\n","Making phenotypes for Chunk 132 of 470\n","Making phenotypes for Chunk 133 of 470\n","Making phenotypes for Chunk 134 of 470\n","Making phenotypes for Chunk 135 of 470\n","Making phenotypes for Chunk 136 of 470\n","Making phenotypes for Chunk 137 of 470\n","Making phenotypes for Chunk 138 of 470\n","Making phenotypes for Chunk 139 of 470\n","Making phenotypes for Chunk 140 of 470\n","Making phenotypes for Chunk 141 of 470\n","Making phenotypes for Chunk 142 of 470\n","Making phenotypes for Chunk 143 of 470\n","Making phenotypes for Chunk 144 of 470\n","Making phenotypes for Chunk 145 of 470\n","Making phenotypes for Chunk 146 of 470\n","Making phenotypes for Chunk 147 of 470\n","Making phenotypes for Chunk 148 of 470\n","Making phenotypes for Chunk 149 of 470\n","Making phenotypes for Chunk 150 of 470\n","Making phenotypes for Chunk 151 of 470\n","Making phenotypes for Chunk 152 of 470\n","Making phenotypes for Chunk 153 of 470\n","Making phenotypes for Chunk 154 of 470\n","Making phenotypes for Chunk 155 of 470\n","Making phenotypes for Chunk 156 of 470\n","Making phenotypes for Chunk 157 of 470\n","Making phenotypes for Chunk 158 of 470\n","Making phenotypes for Chunk 159 of 470\n","Making phenotypes for Chunk 160 of 470\n","Making phenotypes for Chunk 161 of 470\n","Making phenotypes for Chunk 162 of 470\n","Making phenotypes for Chunk 163 of 470\n","Making phenotypes for Chunk 164 of 470\n","Making phenotypes for Chunk 165 of 470\n","Making phenotypes for Chunk 166 of 470\n","Making phenotypes for Chunk 167 of 470\n","Making phenotypes for Chunk 168 of 470\n","Making phenotypes for Chunk 169 of 470\n","Making phenotypes for Chunk 170 of 470\n","Making phenotypes for Chunk 171 of 470\n","Making phenotypes for Chunk 172 of 470\n","Making phenotypes for Chunk 173 of 470\n","Making phenotypes for Chunk 174 of 470\n","Making phenotypes for Chunk 175 of 470\n","Making phenotypes for Chunk 176 of 470\n","Making phenotypes for Chunk 177 of 470\n","Making phenotypes for Chunk 178 of 470\n","Making phenotypes for Chunk 179 of 470\n","Making phenotypes for Chunk 180 of 470\n","Making phenotypes for Chunk 181 of 470\n","Making phenotypes for Chunk 182 of 470\n","Making phenotypes for Chunk 183 of 470\n","Making phenotypes for Chunk 184 of 470\n","Making phenotypes for Chunk 185 of 470\n","Making phenotypes for Chunk 186 of 470\n","Making phenotypes for Chunk 187 of 470\n","Making phenotypes for Chunk 188 of 470\n","Making phenotypes for Chunk 189 of 470\n","Making phenotypes for Chunk 190 of 470\n","Making phenotypes for Chunk 191 of 470\n","Making phenotypes for Chunk 192 of 470\n","Making phenotypes for Chunk 193 of 470\n","Making phenotypes for Chunk 194 of 470\n","Making phenotypes for Chunk 195 of 470\n","Making phenotypes for Chunk 196 of 470\n","Making phenotypes for Chunk 197 of 470\n","Making phenotypes for Chunk 198 of 470\n","Making phenotypes for Chunk 199 of 470\n","Making phenotypes for Chunk 200 of 470\n","Making phenotypes for Chunk 201 of 470\n","Making phenotypes for Chunk 202 of 470\n","Making phenotypes for Chunk 203 of 470\n","Making phenotypes for Chunk 204 of 470\n","Making phenotypes for Chunk 205 of 470\n","Making phenotypes for Chunk 206 of 470\n","Making phenotypes for Chunk 207 of 470\n","Making phenotypes for Chunk 208 of 470\n","Making phenotypes for Chunk 209 of 470\n","Making phenotypes for Chunk 210 of 470\n","Making phenotypes for Chunk 211 of 470\n","Making phenotypes for Chunk 212 of 470\n","Making phenotypes for Chunk 213 of 470\n","Making phenotypes for Chunk 214 of 470\n","Making phenotypes for Chunk 215 of 470\n","Making phenotypes for Chunk 216 of 470\n","Making phenotypes for Chunk 217 of 470\n","Making phenotypes for Chunk 218 of 470\n","Making phenotypes for Chunk 219 of 470\n","Making phenotypes for Chunk 220 of 470\n","Making phenotypes for Chunk 221 of 470\n","Making phenotypes for Chunk 222 of 470\n","Making phenotypes for Chunk 223 of 470\n","Making phenotypes for Chunk 224 of 470\n","Making phenotypes for Chunk 225 of 470\n","Making phenotypes for Chunk 226 of 470\n","Making phenotypes for Chunk 227 of 470\n","Making phenotypes for Chunk 228 of 470\n","Making phenotypes for Chunk 229 of 470\n","Making phenotypes for Chunk 230 of 470\n","Making phenotypes for Chunk 231 of 470\n","Making phenotypes for Chunk 232 of 470\n","Making phenotypes for Chunk 233 of 470\n","Making phenotypes for Chunk 234 of 470\n","Making phenotypes for Chunk 235 of 470\n","Making phenotypes for Chunk 236 of 470\n","Making phenotypes for Chunk 237 of 470\n","Making phenotypes for Chunk 238 of 470\n","Making phenotypes for Chunk 239 of 470\n","Making phenotypes for Chunk 240 of 470\n","Making phenotypes for Chunk 241 of 470\n","Making phenotypes for Chunk 242 of 470\n","Making phenotypes for Chunk 243 of 470\n","Making phenotypes for Chunk 244 of 470\n","Making phenotypes for Chunk 245 of 470\n","Making phenotypes for Chunk 246 of 470\n","Making phenotypes for Chunk 247 of 470\n","Making phenotypes for Chunk 248 of 470\n","Making phenotypes for Chunk 249 of 470\n","Making phenotypes for Chunk 250 of 470\n","Making phenotypes for Chunk 251 of 470\n","Making phenotypes for Chunk 252 of 470\n","Making phenotypes for Chunk 253 of 470\n","Making phenotypes for Chunk 254 of 470\n","Making phenotypes for Chunk 255 of 470\n","Making phenotypes for Chunk 256 of 470\n","Making phenotypes for Chunk 257 of 470\n","Making phenotypes for Chunk 258 of 470\n","Making phenotypes for Chunk 259 of 470\n","Making phenotypes for Chunk 260 of 470\n","Making phenotypes for Chunk 261 of 470\n","Making phenotypes for Chunk 262 of 470\n","Making phenotypes for Chunk 263 of 470\n","Making phenotypes for Chunk 264 of 470\n","Making phenotypes for Chunk 265 of 470\n","Making phenotypes for Chunk 266 of 470\n","Making phenotypes for Chunk 267 of 470\n","Making phenotypes for Chunk 268 of 470\n","Making phenotypes for Chunk 269 of 470\n","Making phenotypes for Chunk 270 of 470\n","Making phenotypes for Chunk 271 of 470\n","Making phenotypes for Chunk 272 of 470\n","Making phenotypes for Chunk 273 of 470\n","Making phenotypes for Chunk 274 of 470\n","Making phenotypes for Chunk 275 of 470\n","Making phenotypes for Chunk 276 of 470\n","Making phenotypes for Chunk 277 of 470\n","Making phenotypes for Chunk 278 of 470\n","Making phenotypes for Chunk 279 of 470\n","Making phenotypes for Chunk 280 of 470\n","Making phenotypes for Chunk 281 of 470\n","Making phenotypes for Chunk 282 of 470\n","Making phenotypes for Chunk 283 of 470\n","Making phenotypes for Chunk 284 of 470\n","Making phenotypes for Chunk 285 of 470\n","Making phenotypes for Chunk 286 of 470\n","Making phenotypes for Chunk 287 of 470\n","Making phenotypes for Chunk 288 of 470\n","Making phenotypes for Chunk 289 of 470\n","Making phenotypes for Chunk 290 of 470\n","Making phenotypes for Chunk 291 of 470\n","Making phenotypes for Chunk 292 of 470\n","Making phenotypes for Chunk 293 of 470\n","Making phenotypes for Chunk 294 of 470\n","Making phenotypes for Chunk 295 of 470\n","Making phenotypes for Chunk 296 of 470\n","Making phenotypes for Chunk 297 of 470\n","Making phenotypes for Chunk 298 of 470\n","Making phenotypes for Chunk 299 of 470\n","Making phenotypes for Chunk 300 of 470\n","Making phenotypes for Chunk 301 of 470\n","Making phenotypes for Chunk 302 of 470\n","Making phenotypes for Chunk 303 of 470\n","Making phenotypes for Chunk 304 of 470\n","Making phenotypes for Chunk 305 of 470\n","Making phenotypes for Chunk 306 of 470\n","Making phenotypes for Chunk 307 of 470\n","Making phenotypes for Chunk 308 of 470\n","Making phenotypes for Chunk 309 of 470\n","Making phenotypes for Chunk 310 of 470\n","Making phenotypes for Chunk 311 of 470\n","Making phenotypes for Chunk 312 of 470\n","Making phenotypes for Chunk 313 of 470\n","Making phenotypes for Chunk 314 of 470\n","Making phenotypes for Chunk 315 of 470\n","Making phenotypes for Chunk 316 of 470\n","Making phenotypes for Chunk 317 of 470\n","Making phenotypes for Chunk 318 of 470\n","Making phenotypes for Chunk 319 of 470\n","Making phenotypes for Chunk 320 of 470\n","Making phenotypes for Chunk 321 of 470\n","Making phenotypes for Chunk 322 of 470\n","Making phenotypes for Chunk 323 of 470\n","Making phenotypes for Chunk 324 of 470\n","Making phenotypes for Chunk 325 of 470\n","Making phenotypes for Chunk 326 of 470\n","Making phenotypes for Chunk 327 of 470\n","Making phenotypes for Chunk 328 of 470\n","Making phenotypes for Chunk 329 of 470\n","Making phenotypes for Chunk 330 of 470\n","Making phenotypes for Chunk 331 of 470\n","Making phenotypes for Chunk 332 of 470\n","Making phenotypes for Chunk 333 of 470\n","Making phenotypes for Chunk 334 of 470\n","Making phenotypes for Chunk 335 of 470\n","Making phenotypes for Chunk 336 of 470\n","Making phenotypes for Chunk 337 of 470\n","Making phenotypes for Chunk 338 of 470\n","Making phenotypes for Chunk 339 of 470\n","Making phenotypes for Chunk 340 of 470\n","Making phenotypes for Chunk 341 of 470\n","Making phenotypes for Chunk 342 of 470\n","Making phenotypes for Chunk 343 of 470\n","Making phenotypes for Chunk 344 of 470\n","Making phenotypes for Chunk 345 of 470\n","Making phenotypes for Chunk 346 of 470\n","Making phenotypes for Chunk 347 of 470\n","Making phenotypes for Chunk 348 of 470\n","Making phenotypes for Chunk 349 of 470\n","Making phenotypes for Chunk 350 of 470\n","Making phenotypes for Chunk 351 of 470\n","Making phenotypes for Chunk 352 of 470\n","Making phenotypes for Chunk 353 of 470\n","Making phenotypes for Chunk 354 of 470\n","Making phenotypes for Chunk 355 of 470\n","Making phenotypes for Chunk 356 of 470\n","Making phenotypes for Chunk 357 of 470\n","Making phenotypes for Chunk 358 of 470\n","Making phenotypes for Chunk 359 of 470\n","Making phenotypes for Chunk 360 of 470\n","Making phenotypes for Chunk 361 of 470\n","Making phenotypes for Chunk 362 of 470\n","Making phenotypes for Chunk 363 of 470\n","Making phenotypes for Chunk 364 of 470\n","Making phenotypes for Chunk 365 of 470\n","Making phenotypes for Chunk 366 of 470\n","Making phenotypes for Chunk 367 of 470\n","Making phenotypes for Chunk 368 of 470\n","Making phenotypes for Chunk 369 of 470\n","Making phenotypes for Chunk 370 of 470\n","Making phenotypes for Chunk 371 of 470\n","Making phenotypes for Chunk 372 of 470\n","Making phenotypes for Chunk 373 of 470\n","Making phenotypes for Chunk 374 of 470\n","Making phenotypes for Chunk 375 of 470\n","Making phenotypes for Chunk 376 of 470\n","Making phenotypes for Chunk 377 of 470\n","Making phenotypes for Chunk 378 of 470\n","Making phenotypes for Chunk 379 of 470\n","Making phenotypes for Chunk 380 of 470\n","Making phenotypes for Chunk 381 of 470\n","Making phenotypes for Chunk 382 of 470\n","Making phenotypes for Chunk 383 of 470\n","Making phenotypes for Chunk 384 of 470\n","Making phenotypes for Chunk 385 of 470\n","Making phenotypes for Chunk 386 of 470\n","Making phenotypes for Chunk 387 of 470\n","Making phenotypes for Chunk 388 of 470\n","Making phenotypes for Chunk 389 of 470\n","Making phenotypes for Chunk 390 of 470\n","Making phenotypes for Chunk 391 of 470\n","Making phenotypes for Chunk 392 of 470\n","Making phenotypes for Chunk 393 of 470\n","Making phenotypes for Chunk 394 of 470\n","Making phenotypes for Chunk 395 of 470\n","Making phenotypes for Chunk 396 of 470\n","Making phenotypes for Chunk 397 of 470\n","Making phenotypes for Chunk 398 of 470\n","Making phenotypes for Chunk 399 of 470\n","Making phenotypes for Chunk 400 of 470\n","Making phenotypes for Chunk 401 of 470\n","Making phenotypes for Chunk 402 of 470\n","Making phenotypes for Chunk 403 of 470\n","Making phenotypes for Chunk 404 of 470\n","Making phenotypes for Chunk 405 of 470\n","Making phenotypes for Chunk 406 of 470\n","Making phenotypes for Chunk 407 of 470\n","Making phenotypes for Chunk 408 of 470\n","Making phenotypes for Chunk 409 of 470\n","Making phenotypes for Chunk 410 of 470\n","Making phenotypes for Chunk 411 of 470\n","Making phenotypes for Chunk 412 of 470\n","Making phenotypes for Chunk 413 of 470\n","Making phenotypes for Chunk 414 of 470\n","Making phenotypes for Chunk 415 of 470\n","Making phenotypes for Chunk 416 of 470\n","Making phenotypes for Chunk 417 of 470\n","Making phenotypes for Chunk 418 of 470\n","Making phenotypes for Chunk 419 of 470\n","Making phenotypes for Chunk 420 of 470\n","Making phenotypes for Chunk 421 of 470\n","Making phenotypes for Chunk 422 of 470\n","Making phenotypes for Chunk 423 of 470\n","Making phenotypes for Chunk 424 of 470\n","Making phenotypes for Chunk 425 of 470\n","Making phenotypes for Chunk 426 of 470\n","Making phenotypes for Chunk 427 of 470\n","Making phenotypes for Chunk 428 of 470\n","Making phenotypes for Chunk 429 of 470\n","Making phenotypes for Chunk 430 of 470\n","Making phenotypes for Chunk 431 of 470\n","Making phenotypes for Chunk 432 of 470\n","Making phenotypes for Chunk 433 of 470\n","Making phenotypes for Chunk 434 of 470\n","Making phenotypes for Chunk 435 of 470\n","Making phenotypes for Chunk 436 of 470\n","Making phenotypes for Chunk 437 of 470\n","Making phenotypes for Chunk 438 of 470\n","Making phenotypes for Chunk 439 of 470\n","Making phenotypes for Chunk 440 of 470\n","Making phenotypes for Chunk 441 of 470\n","Making phenotypes for Chunk 442 of 470\n","Making phenotypes for Chunk 443 of 470\n","Making phenotypes for Chunk 444 of 470\n","Making phenotypes for Chunk 445 of 470\n","Making phenotypes for Chunk 446 of 470\n","Making phenotypes for Chunk 447 of 470\n","Making phenotypes for Chunk 448 of 470\n","Making phenotypes for Chunk 449 of 470\n","Making phenotypes for Chunk 450 of 470\n","Making phenotypes for Chunk 451 of 470\n","Making phenotypes for Chunk 452 of 470\n","Making phenotypes for Chunk 453 of 470\n","Making phenotypes for Chunk 454 of 470\n","Making phenotypes for Chunk 455 of 470\n","Making phenotypes for Chunk 456 of 470\n","Making phenotypes for Chunk 457 of 470\n","Making phenotypes for Chunk 458 of 470\n","Making phenotypes for Chunk 459 of 470\n","Making phenotypes for Chunk 460 of 470\n","Making phenotypes for Chunk 461 of 470\n","Making phenotypes for Chunk 462 of 470\n","Making phenotypes for Chunk 463 of 470\n","Making phenotypes for Chunk 464 of 470\n","Making phenotypes for Chunk 465 of 470\n","Making phenotypes for Chunk 466 of 470\n","Making phenotypes for Chunk 467 of 470\n","Making phenotypes for Chunk 468 of 470\n","Making phenotypes for Chunk 469 of 470\n","Making phenotypes for Chunk 470 of 470\n","\n","Phenotypes saved in GCTA_params={her=0.9,num-causals=10000}.pheno, with breeding values in GCTA_params={her=0.9,num-causals=10000}.breed and effect sizes in GCTA_params={her=0.9,num-causals=10000}.effects\n","\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n","Mission completed. All your basepair are belong to us :)\n","-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n"]}]},{"cell_type":"code","source":["! cp HumDef* GCTA* /content/drive/MyDrive/CSE-284-Final-Project/data/1000g_pheno"],"metadata":{"id":"gl9QM3-_Tt6_","executionInfo":{"status":"ok","timestamp":1709680885561,"user_tz":480,"elapsed":8071,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["%%bash\n","cd /content/drive/MyDrive/CSE-284-Final-Project/\n","mkdir data\n","cd data\n","mkdir vcf\n","mkdir pgen"],"metadata":{"id":"t236Y6jPC7Ka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install awscli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgoINjhvD37o","executionInfo":{"status":"ok","timestamp":1709431578736,"user_tz":480,"elapsed":17766,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"54e1ac2f-8e11-4d52-96cb-72296530b16a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting awscli\n","  Downloading awscli-1.32.54-py3-none-any.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore==1.34.54 (from awscli)\n","  Downloading botocore-1.34.54-py3-none-any.whl (12.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docutils<0.17,>=0.10 (from awscli)\n","  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting s3transfer<0.11.0,>=0.10.0 (from awscli)\n","  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.1)\n","Collecting colorama<0.4.5,>=0.2.5 (from awscli)\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting rsa<4.8,>=3.1.2 (from awscli)\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.34.54->awscli)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.54->awscli) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.54->awscli) (2.0.7)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.5.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.54->awscli) (1.16.0)\n","Installing collected packages: rsa, jmespath, docutils, colorama, botocore, s3transfer, awscli\n","  Attempting uninstall: rsa\n","    Found existing installation: rsa 4.9\n","    Uninstalling rsa-4.9:\n","      Successfully uninstalled rsa-4.9\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18.1\n","    Uninstalling docutils-0.18.1:\n","      Successfully uninstalled docutils-0.18.1\n","Successfully installed awscli-1.32.54 botocore-1.34.54 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.10.0\n"]}]},{"cell_type":"code","source":["!aws s3 ls --no-sign-request s3://1000genomes/release/20130502/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHMI9qjDD5JI","executionInfo":{"status":"ok","timestamp":1709431746214,"user_tz":480,"elapsed":2686,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"e7b8d7fa-9419-460f-e3d6-51d20d2afa8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                           PRE supporting/\n","2014-08-29 02:48:11       1168 20140625_related_individuals.txt\n","2015-06-03 19:43:52 1216886729 ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:29     224660 ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:45:05  773788987 ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:39     133086 ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:43:47  767084423 ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:51     133331 ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:43:49  740805962 ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:57     133171 ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:45:08  556832848 ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:32      96652 ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:44  506573037 ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:47      88321 ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:24  457900567 ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:35      81584 ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:43:46  495134005 ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:48      81026 ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:43:45  434623611 ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:45:01      79187 ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:45:19  436425683 ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:45:06      74610 ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:10  359519603 ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:45:33      55477 ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:03 1312735578 ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:36     238011 ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:43  341680844 ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:32      56516 ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:34  218612970 ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:39      35357 ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:24  214453750 ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:49      36078 ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:38 1105776520 ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:43:43     196236 ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:15 1117054318 ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-09-08 21:17:36     188993 ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:44:52  989263345 ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:02     176777 ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:45:11  999436830 ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:35     169549 ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:43:49  908031088 ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:53     158064 ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:43:49  861233457 ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-06-03 19:44:20     146204 ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-06-03 19:45:19  672879733 ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","2015-09-08 21:17:15     121082 ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","2015-08-20 19:31:50 1923680177 ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz\n","2015-08-21 01:11:46     148068 ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz.tbi\n","2015-08-20 20:29:02    5867368 ALL.chrY.phase3_integrated_v1b.20130502.genotypes.vcf.gz\n","2015-08-20 20:58:41       8061 ALL.chrY.phase3_integrated_v1b.20130502.genotypes.vcf.gz.tbi\n","2015-08-20 23:14:57 1980074620 ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz\n","2015-08-20 15:43:50    2463880 ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz.tbi\n","2015-09-03 13:05:15       3158 README_known_issues_20150813\n","2015-06-02 05:05:51       6555 README_phase3_callset_20150220\n","2014-11-28 11:12:29       5344 README_phase3_chrY_calls_20141104\n","2014-12-02 13:20:16       2914 README_vcf_info_annotation.20141104\n","2014-12-02 13:20:56      25923 integrated_call_male_samples_v3.20130502.ALL.panel\n","2014-09-03 01:32:45     179766 integrated_call_samples.20130502.ALL.ped\n","2014-12-02 13:22:35      55156 integrated_call_samples_v3.20130502.ALL.panel\n"]}]},{"cell_type":"code","source":["!aws s3 cp --no-sign-request s3://1000genomes/release/20130502/ /content/drive/MyDrive/CSE-284-Final-Project/data/vcf --recursive --exclude \"supporting/*\" --include \"*.vcf.gz\" --include \"*.vcf.gz.tbi\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqMrGilxD5xI","executionInfo":{"status":"ok","timestamp":1709432381970,"user_tz":480,"elapsed":393616,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"68dcc153-9505-467c-bf48-415bbbeb653b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Completed 256.0 KiB/~10.3 GiB (279.8 KiB/s) with ~34 file(s) remaining (calculating...)\rCompleted 475.4 KiB/~10.3 GiB (518.7 KiB/s) with ~34 file(s) remaining (calculating...)\rCompleted 731.4 KiB/~10.3 GiB (774.7 KiB/s) with ~34 file(s) remaining (calculating...)\rCompleted 987.4 KiB/~10.3 GiB (1.0 MiB/s) with ~34 file(s) remaining (calculating...)  \rCompleted 1.2 MiB/~10.3 GiB (1.3 MiB/s) with ~34 file(s) remaining (calculating...)    \rdownload: s3://1000genomes/release/20130502/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chrY.phase3_integrated_v1b.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chrY.phase3_integrated_v1b.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.chrY.phase3_integrated_v1b.20130502.genotypes.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chrY.phase3_integrated_v1b.20130502.genotypes.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr1.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr1.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr10.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr10.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr11.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr11.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr10.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr10.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr12.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr12.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr11.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr11.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr13.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr13.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr1.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr1.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr14.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr14.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr15.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr15.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr16.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr16.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr17.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr17.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr18.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr18.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr13.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr13.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr14.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr14.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr12.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr12.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr19.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr19.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr15.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr15.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr2.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr2.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr20.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr20.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr19.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr19.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr21.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr21.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr22.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr22.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz.tbi\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr17.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr17.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr18.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr18.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","download: s3://1000genomes/release/20130502/supporting/GRCh38_positions/ALL.chr16.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz to drive/MyDrive/cse-284-prs-comparison/data/vcf/supporting/GRCh38_positions/ALL.chr16.phase3_shapeit2_mvncall_integrated_v3plus_nounphased.rsID.genotypes.GRCh38_dbSNP_no_SVs.vcf.gz\n","cancelled: ctrl-c received                                                            \n"]}]},{"cell_type":"code","source":["!wget https://s3.amazonaws.com/plink2-assets/alpha5/plink2_linux_x86_64_20240105.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4P0YCKtLFhTJ","executionInfo":{"status":"ok","timestamp":1709433056430,"user_tz":480,"elapsed":1099,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"80f426e8-ef4f-4aa0-8ebf-acf0cc2ca291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-03 02:30:55--  https://s3.amazonaws.com/plink2-assets/alpha5/plink2_linux_x86_64_20240105.zip\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.169.16, 54.231.203.120, 16.182.99.232, ...\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.169.16|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9266484 (8.8M) [application/zip]\n","Saving to: ‘plink2_linux_x86_64_20240105.zip’\n","\n","plink2_linux_x86_64 100%[===================>]   8.84M  32.3MB/s    in 0.3s    \n","\n","2024-03-03 02:30:56 (32.3 MB/s) - ‘plink2_linux_x86_64_20240105.zip’ saved [9266484/9266484]\n","\n"]}]},{"cell_type":"code","source":["!unzip plink2_linux_x86_64_20240105.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z84_Z9LmJwNI","executionInfo":{"status":"ok","timestamp":1709433101460,"user_tz":480,"elapsed":557,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"bda5507f-ee1f-40fb-ce1d-cfb3373b06f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  plink2_linux_x86_64_20240105.zip\n","  inflating: plink2                  \n"]}]},{"cell_type":"code","source":["!./plink2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DomVoFTUJyd2","executionInfo":{"status":"ok","timestamp":1709433117106,"user_tz":480,"elapsed":163,"user":{"displayName":"Keng-Chi Chang","userId":"08877207485459642010"}},"outputId":"94ad0735-f829-4aca-c975-fcd96fe066d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PLINK v2.00a5.10LM 64-bit Intel (5 Jan 2024)   www.cog-genomics.org/plink/2.0/\n","(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n","\n","  plink2 <input flag(s)...> [command flag(s)...] [other flag(s)...]\n","  plink2 --help [flag name(s)...]\n","\n","Commands include --rm-dup list, --make-bpgen, --export, --freq, --geno-counts,\n","--sample-counts, --missing, --hardy, --het, --fst, --indep-pairwise, --ld,\n","--sample-diff, --make-king, --king-cutoff, --pmerge, --pgen-diff,\n","--write-samples, --write-snplist, --make-grm-list, --pca, --glm, --adjust-file,\n","--gwas-ssf, --clump, --score, --variant-score, --genotyping-rate, --pgen-info,\n","--validate, and --zst-decompress.\n","\n","\"plink2 --help | more\" describes all functions.\n"]}]}]}